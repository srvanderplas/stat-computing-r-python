{
  "hash": "54501314a895a632fb759438f129e22e",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Record-based Data and List Processing Strategies {#sec-record-data}\n\n@sec-data-web introduces how XML and HTML documents are constructed and demonstrates different techniques for scraping data from the web.  \n@sec-data-apis introduces Application Programming Interfaces (APIs) to get data from the web in a cleaner, more efficient way.\nWeb-based data often uses different formats, like JSON (JavaScript Object Notation), to provide data from requests in a structured way. \nBefore we can effectively use APIs, it helps to review some basic patterns and methods for working with record based data and converting it into the rectangular data that most statistical analyses are built around.\n\n## Prerequisites {-}\n\n- Working knowledge of data wrangling techniques (@sec-data-cleaning, @sec-strings, @sec-data-reshape)\n- Familiarity with table joins (@sec-data-join)\n- Familiarity with functional programming (@sec-lists) \n- Familiarity with XML file structures (@sec-data-web)\n\nThis chapter will assume that you've used (or at least seen) techniques like split-apply-combine or map-reduce, anonymous functions, and table joins (full, left, right, inner) and similar techniques before. \nHere, we will focus on how these strategies apply specifically to record-based, hierarchically formatted data that is often found in XML and JSON files. \n\n## Objectives {-}\n- Differentiate between tabular and record-based data structures\n  - Develop strategies to transform record-based data into tabular data\n  - Recognize situations where multiple linked tables or nested list-columns may be required to represent the data effectively in a tabular format\n- Transform data in record-based formats such as XML and JSON into single or multiple linked rectangular data tables.\n- Implement data cleaning and quality control measures to ensure that data is read in and transformed correctly and important information is not lost. \n\n\n## Data Models\n\nIf you are reading this book, chances are you're approaching programming from a more statistical or data-sciency point of view, rather than as a computer scientist. \nAs a result, you probably have a general expectation that data will be laid out in a rectangular form, with rows representing observations or individuals and columns representating variables, measurements, or other dimensions of data which are applicable to each observation or individual. \n\nThis is an assumption which is much more common (at least in my experience) in statistics than in computer science more generally, though of course there are statisticians working on all sorts of different data types, including those we will discuss here.\n\n### Relational Data\n\n**Relational** data is a particular type of data model that assumes table-based data storage. \nThat is, when we access data in spreadsheets, CSVs, and so on, we are working with relational data. \nIn computer science terms, a *relation* consists of a *heading* and a *body*. \n\n- The *heading* defines a set of *attributes* that have a name and a data type (mathematically, a domain).\n- The *body* is a set of **tuples** (a tuple is a collection of $n$ values, and is a formal data type in Python, but not in R), where there are as many values as are defined in the heading. \n\nThis is all an abstract way of describing the composition of a Data Frame, as this book did in @sec-data-frames, where a DataFrame is a heterogeneous list of columns where:\n\n-   Every entry in each column must have the same data type\n-   Every column must have the same number of rows\n\nIn a relational model, a record typically corresponds to a row of the data -- in statistical terms, an observation (especially if our relational table is in tidy form). \n\nNot every record-based system is relational, however. Let's examine a few other structures.\n\n### Record-based Data Models\nBefore the relational data model became popular, however, there was the **hierarchical** data model.\nIn the 1960s, computers began to be utilized for data storage, and this naturally led to record-based data models. \n\nIn a record-based data model, data are stored as **records** that are a collection of **fields**, where each field is a single value with an associated (usually fixed length/size) type. \nThe fields in a record determine the record's **type**. \n\n#### Hierarchical Data Models\n\nA generic **entity** or **class** can be defined as a collection of **fields** in a more formal object-oriented hierarchical representation. \n**Links** connect records with associated records, forming a tree. \n\nThis type of data structure is incredibly common, but it does not always (easily) reduce to tabular data. \nIn many cases, though, it is possible to represent hierarchical data as a set of tables that relate to each other through **keys**. \n\n::: demo\n##### Demo: Hierarchical Employee Data {-}\n\nWhen a company hires an employee, many different records may be generated:\n\n- employee information (name, address, phone number, ssn)\n- initial paperwork (background check, tax information)\n- training history\n- employment agreement details (position type - permanent/contract/intern, start date, benefits, pay amount, which position the employee reports to)\n\nIn the pre-computer days, you can imagine that each set of records might be kept alphabetized by the most important field (employee name, in many cases, position in others) in separate filing cabinets. \nWhen computers entered the picture, the most direct translation was to build a hierarchical set of records with a structure much like the file cabinets - each set of information was kept with other records of its type, and these records could be linked together -- usually, by following direct relational links between different forms. \nSAP, which is a very common enterprise data management system, still works this way - you pull up a record, and then click on linked records to navigate between different forms in the system.\n\n\n\n\n```{mermaid}\n%%| label: fig-employee-record-diag\n%%| fig-cap: This entity-relationship diagram contains information about corporate records relating to a single employee, such as employee details, supervisory relationships, employment agreement details, training records, tax information, and background checks. \n%%| file: ../images/advanced/employee-records.mmd\nerDiagram\n  EMPLOYEE {\n    int ID PK\n    string first\n    string last\n    string middle\n    string address\n    string phone\n    int ssn\n  }\n  BACKGROUND_CHECK {\n    int ID PK\n    int EMPLOYEE_ID FK\n    date date\n    string results\n  }\n  TAX_INFO {\n    int ID PK\n    int EMPLOYEE_ID FK\n    int year\n    float withholding\n  }\n  TRAINING {\n    int ID PK\n    int TRAINING_TYPE\n    int EMPLOYEE_ID FK\n    float score\n  }\n  EMP_AGREE {\n    int ID PK\n    int EMPLOYEE_ID FK\n    int POSITION_ID FK\n    int POSITION_TYPE\n    date START_DATE\n    date END_DATE\n    int benefits_class\n    float pay_hourly_equiv\n    float hours_wk\n    int pay_period\n  }\n  ORG_REL {\n    int ID PK\n    int EMPLOYEE_ID FK\n    int SUPERVISOR_ID FK\n  }\n  EMPLOYEE }|--|| EMP_AGREE : has\n  EMPLOYEE }|--|| ORG_REL : has\n  EMPLOYEE ||--|{ TAX_INFO : has\n  EMPLOYEE ||--|{ TRAINING : has\n  EMPLOYEE ||--|{ BACKGROUND_CHECK : has\n\n\n  accTitle: Sample Company Employee-related Records\n  accDescr {\n    This diagram contains information about corporate records relating to a single employee, such as employee details, supervisory relationships, employment agreement details, training records, tax information, and background checks.\n  }\n```\n\n\n\n\nIn record-based data models, it can be complicated to actually *do* anything with the set of records. \nIt might be relatively easy to e.g. list out all employees, but other related tasks, like determining how many people one individual is supervising, may require sifting through every ORG_REL record and could be complicated by how the records are stored (are they all text files in folders by employees?). \nRecord-based data models, whether hierarchical or not, were originally a digital extension of physical records (think rows of file cabinets in old movies). \n\nNote that it is a relatively simple step between a hierarchical data model and a relational data model with separate tables for each record type. \nThis isn't shocking, if only because the relational data model where tables are joined together is a direct descendant of the hierarchical form-based data model described here. \n\n:::\n\n:::: example\n\n##### Example: Hierarchical Employee Data {-}\n\n\n::: panel-tabset\n###### Problem Description {-}\n\nRead in [this XML file of sample employee data](../data/sample_employee_data.xml) and \n\n1. Assemble a table of all of the employee information in @fig-employee-record-diag (that is, ID, first, middle, and last name, address, phone number, and social security number). \n    - Can you do this using data processing functions like `map_dfr` and `as_list` in R or `read_xml` in pandas (you'll have to use chained operations in R and custom arguments in python)?\n    - Identify any employees with an invalid social security number using your tabular data representation.\n\n2. Identify the supervisor who has the most people reporting to them, without converting the data to tabular format, and then retrieve a list of all of that person's direct reports as employee IDs. \n\n3. Identify whether there are any employees who took the same training twice, without converting the data to tabular format. \n\nDo you prefer to work with tabular data or hierarchical data? Why?\n\n###### R (purrr) {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xml2)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(stringr)\n\ninfo <- read_xml(\"../data/sample_employee_data.xml\")\nrecords <- xml_find_all(info, \"//*/EMPLOYEE\")\ndf <- records |> \n  as_list() |>\n  map_dfr(~.x |> \n            unlist(recursive = T) |> \n            t() |> \n            as.data.frame() |> \n            set_names(\"id\", \"first\", \"last\", \"middle\", \n                      \"address\", \"phone\", \"ssn\")\n  ) |>\n  mutate(valid_ssn = str_count(ssn, \"\\\\d\")==9)\nhead(df)\n##     id   first      last middle\n## 1 2824 Michael  Phillips      E\n## 2 1409 William  Gonzalez      B\n## 3 5506  Donald     Watts      L\n## 4 5012   Erica   Johnson      C\n## 5 4657 William  Townsend      D\n## 6 3286    Mark Fernandez      J\n##                                                    address               phone\n## 1          341 Bonilla Extensions\\nLake Jacktown, VA 72058 +1-701-028-0259x700\n## 2       85759 Danielle Lights\\nLake Anthonymouth, SD 72346   540.044.8808x1629\n## 3                68711 Janet Wall\\nMcdonaldmouth, MT 77414     +1-059-051-0485\n## 4      755 Brandon Mill Suite 800\\nNorth Phillip, LA 12123  (680)650-9821x6860\n## 5 00624 Johnson Harbor Apt. 211\\nWoodwardchester, AK 03498        026-982-2613\n## 6       910 Mathew Mall Suite 805\\nSchwartzmouth, OK 23331    630.559.6490x275\n##         ssn valid_ssn\n## 1 821097324      TRUE\n## 2 394613566      TRUE\n## 3 367179644      TRUE\n## 4 330054170      TRUE\n## 5 164054528      TRUE\n## 6 297177301      TRUE\nfilter(df, !valid_ssn)\n##     id     first   last middle\n## 1 7873     Susan  Mason      K\n## 2 5552   Cameron Miller      C\n## 3 6635 Alexander  Marsh      A\n## 4 5333     Kayla Parker      M\n##                                                address                  phone\n## 1                     PSC 4488, Box 1248\\nAPO AE 96883      152.806.9336x6388\n## 2 0819 Douglas Drives Suite 857\\nDicksonfort, WY 67373 001-727-389-3454x96815\n## 3              94716 Karen Square\\nSmithside, WA 74182    +1-126-214-2102x641\n## 4               1921 David Spur\\nNorth Sarah, IA 01256     549-226-0959x23219\n##        ssn valid_ssn\n## 1 12078633     FALSE\n## 2  9361578     FALSE\n## 3 39197635     FALSE\n## 4 69647139     FALSE\n```\n:::\n\n\n\n\nThe `purrr::pluck()` function is a good way to pull out the information we need, once we convert the xml file to a list structure (which is still not a tabular form). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsupervisors <- xml_find_all(info, \"//*/ORG_REL/*\")|> \n  as_list() |>\n  map_chr(~purrr::pluck(., \"SUPERVISOR_ID\", 1)) \nemployees <- xml_find_all(info, \"//*/ORG_REL/*\")|> \n  as_list() |>\n  map_chr(~purrr::pluck(., \"EMPLOYEE_ID\", 1)) \n\nsupervisor_reports <- supervisors |>\n  table() |> sort(decreasing = T)\n\nemployees[which(supervisors == names(supervisor_reports)[1])]\n## [1] \"1434\" \"4611\" \"3547\" \"6925\"\n\n# Just for context\nfilter(df, id%in%employees[which(supervisors == names(supervisor_reports)[1])])\n##     id       first   last middle\n## 1 1434   Elizabeth Harris      B\n## 2 4611      Deanna  Doyle      C\n## 3 3547      Sherri Warner      T\n## 4 6925 Christopher  Jones      P\n##                                                      address\n## 1               720 James Passage\\nPort Justinfort, NC 55779\n## 2 328 Kelley Junctions Suite 782\\nNorth Jacqueline, PA 71278\n## 3           280 Allen Highway Apt. 700\\nSummerview, TX 62208\n## 4         26004 Kelly Rest Apt. 898\\nNew Katherine, OH 96504\n##                   phone       ssn valid_ssn\n## 1   +1-448-259-7632x679 531909398      TRUE\n## 2 001-272-144-5412x0950 226062294      TRUE\n## 3  001-011-455-7532x304 228640945      TRUE\n## 4     (195)612-9014x134 533899921      TRUE\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nids <- xml_find_all(info, \"//*/TRAINING/TRAININ/EMPLOYEE_ID\")|> xml_text()\n\nget_employee_training_type <- function(id) {\n  employee_training_xpath <- sprintf(\"//*/TRAINING/TRAININ/EMPLOYEE_ID[text()='%s']\", id)\n  employee_training_nodes <- xml_find_all(info, employee_training_xpath)\n  training_type <- employee_training_nodes |> \n    xml_parent() |>\n    xml_child(\"TRAINING_TYPE\") |> \n    xml_text() |> \n    unlist()\n}\n\nduplicates <- function(list) {\n  length(list) != length(unique(list))\n}\n\ndupe_employees <- map(unique(ids), get_employee_training_type) |>\n  map_lgl(duplicates)\n\nunique(ids)[dupe_employees] |> as.numeric() |> sort()\n## [1] 1106 2519 2584 2674 5506\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is how easy it is in tabular form... \ntraining_str <- xml_find_all(info, \"//*/TRAINING/TRAININ\")|> \n  as_list() |>\n  map_dfr(~.x |> \n            unlist(recursive = T) |> \n            t() |> \n            as.data.frame() |> \n            set_names(\"id\", \"type\", \"employee_id\", \"score\")\n  ) |> group_by(employee_id) |>\n  summarize(n = n(), n_unique = length(unique(type))) |>\n  filter(n != n_unique)\n```\n:::\n\n\n\n\n###### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndf = pd.read_xml(\"../data/sample_employee_data.xml\", \n                 iterparse={\"EMPLOYEE\": [\"id\", \"first\", \"last\", \"middle\", \n                                         \"address\", \"phone\", \"ssn\"]})\ndf.head()\n##      first      last  ...                phone        ssn\n## 0  Michael  Phillips  ...  +1-701-028-0259x700  821097324\n## 1  William  Gonzalez  ...    540.044.8808x1629  394613566\n## 2   Donald     Watts  ...      +1-059-051-0485  367179644\n## 3    Erica   Johnson  ...   (680)650-9821x6860  330054170\n## 4  William  Townsend  ...         026-982-2613  164054528\n## \n## [5 rows x 6 columns]\n\n# Invalid SSNs\ndf.query(\"~(ssn<=999999999 & ssn >= 100000000)\")\n##         first    last  ...                   phone       ssn\n## 19      Susan   Mason  ...       152.806.9336x6388  12078633\n## 27    Cameron  Miller  ...  001-727-389-3454x96815   9361578\n## 36  Alexander   Marsh  ...     +1-126-214-2102x641  39197635\n## 37      Kayla  Parker  ...      549-226-0959x23219  69647139\n## \n## [4 rows x 6 columns]\n```\n:::\n\n\n\n\nIn order to not convert things to a tabular format, we have to use the xml library directly. \nThis is annoying and a good vote in favor of using tabular formats instead of hierarchical stuff, particularly when pandas makes it easy to get the tabular format we need back out. \n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport xml.etree.ElementTree as ET\ndoc = ET.parse(r\"../data/sample_employee_data.xml\")\nroot = doc.getroot()\nrelationships = root.find(\"ORG_REL\")\nrelationships = relationships.findall(\"ORG_RE\")\n\n# These get the employee ID and supervisor ID for every relationship listed\nemployees = pd.Series([e[1].text for e in relationships])\nsupervisors = pd.Series([e[2].text for e in relationships])\n\n# Count # times supervisor ID appears in list\nsupervisors.groupby(supervisors).count().head()\n## 1409    1\n## 1434    1\n## 1520    3\n## 2139    1\n## 2291    2\n## dtype: int64\n\n# Supervisor with most employees\nbusiest_sup = supervisors.groupby(supervisors).count().sort_values(ascending=False).index[0]\nbusiest_sup\n## '3615'\n\n# List of those employees\nbusiest_sup_employees = employees.loc[supervisors==busiest_sup]\nbusiest_sup_employees\n## 16    1434\n## 20    4611\n## 28    3547\n## 45    6925\n## dtype: object\n```\n:::\n\n\n\n\nNow we tackle the training problem in a similar way, making use of the fact that we can group one series (training types) by another (employee ID) and the index of the grouped series will have the employee ID we want. \nThis is right on the border of tabular data, and yes, I'm intentionally blurring the lines even further. \nUltimately, what we want is to solve the problem.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntrainings = root.find(\"TRAINING\")\ntrainings = trainings.findall(\"TRAININ\")\n\ntraining_types = pd.Series([e[1].text for e in trainings])\ntraining_empl = pd.Series([e[2].text for e in trainings])\nmultiple_trainings = training_types.groupby(training_empl).agg(lambda x: len(x) != x.nunique())\n# Employees who took the same training multiple times\nmultiple_trainings.index[multiple_trainings.values]\n## Index(['1106', '2519', '2584', '2674', '5506'], dtype='object')\n```\n:::\n\n\n\n:::\n\n::::\n\n#### Network Data Models\n\nIn a hierarchical data model, each record has only one parent. \nThis is, as it turns out, a fairly restrictive constraint, as in the real world, there can be many-to-many relationships that are not strictly hierarchical - imagine trying to represent genealogical data with the restriction that each node can have only one parent!\n\nAnother form of record-based data model is a **network**. \nThis model allows many-to-many relationships between records and even reciprocal links between two or more records (a \"cycle\" in network terms). \n\nOften, it is convenient to separately model the individual entities (\"nodes\") in one table and the edges in another, when converting network data to something rectangular. \nIn the case that edges are not directional (and thus cycles are not possible), it is often useful to impose a constraint to ensure that there is only one proper link between two nodes. \nOne common constraint is a variant of \"the ID of the first node is greater than the ID of the second\". \nWhen edges are directional, the order of the two nodes is useful, and no such constraints are required. \n\nIn both cases, extra information about the link between the two nodes may be included in additional columns in the 'edge' table. \n\n:::: demo\n\n##### Demo: Relationship Data Networks\n\nIn an attempt to demonstrate how complex a network data model can get, [I asked ChatGPT to generate a data set of romantic relationships between Grey's Anatomy characters over the show's 21 seasons.](../data/greys-anatomy-gpt.txt) \n\n\n:::: column-margin\n\n![I have *no* desire to watch all 21 seasons to check the bot's work, so we're going to assume that AI is the authority here. Feel free to submit a pull request if you have corrections to offer.](../images/gifs/murderbot-content.gif){fig-alt=\"A gif from the AppleTV show Murderbot, showing a robot who says 'I watched 7532 hours of content'\"}\n::::\n\n\n\n\n```{mermaid}\n%%| label: fig-greys-anatomy-network\n%%| fig-cap: Romantic relationships between characters in Grey's Anatomy, aggregated over all 21 seasons.\n%%| file: ../images/advanced/greys-network.mmd\ngraph TD\n\n%% Meredith Grey\nMeredithGrey -- romantic --> DerekShepherd\nMeredithGrey -- romantic --> NathanRiggs\nMeredithGrey -- romantic --> AndrewDeLuca\nMeredithGrey -- romantic --> NickMarsh\nMeredithGrey -- one-night --> GeorgeOMalley\nMeredithGrey -- one-night --> SteveMurphy\nMeredithGrey -- one-night --> WilliamThorpe\nMeredithGrey -- one-night --> FinnDandridge\n\n%% Cristina Yang\nCristinaYang -- romantic --> OwenHunt\nCristinaYang -- romantic --> PrestonBurke\nCristinaYang -- one-night --> ShaneRoss\n\n%% Owen Hunt\nOwenHunt -- romantic --> CristinaYang\nOwenHunt -- romantic --> AmeliaShepherd\nOwenHunt -- romantic --> TeddyAltman\nOwenHunt -- flirtation --> EmmaMarling\n\n%% Alex Karev\nAlexKarev -- romantic --> IzzieStevens\nAlexKarev -- romantic --> JoWilson\nAlexKarev -- one-night --> LexieGrey\nAlexKarev -- one-night --> OliviaHarper\nAlexKarev -- one-night --> RebeccaPope\n\n%% Izzie Stevens\nIzzieStevens -- romantic --> AlexKarev\nIzzieStevens -- romantic --> DennyDuquette\nIzzieStevens -- romantic --> GeorgeOMalley\n\n%% George O'Malley\nGeorgeOMalley -- romantic --> CallieTorres\nGeorgeOMalley -- one-night --> MeredithGrey\nGeorgeOMalley -- romantic --> IzzieStevens\nGeorgeOMalley -- one-night --> OliviaHarper\n\n%% Callie Torres\nCallieTorres -- romantic --> GeorgeOMalley\nCallieTorres -- romantic --> EricaHahn\nCallieTorres -- romantic --> ArizonaRobbins\nCallieTorres -- one-night --> MarkSloan\nCallieTorres -- one-night --> PennyBlake\n\n%% Arizona Robbins\nArizonaRobbins -- romantic --> CallieTorres\nArizonaRobbins -- flirtation --> LaurenBoswell\nArizonaRobbins -- flirtation --> CarinaDeLuca\n\n%% Mark Sloan\nMarkSloan -- romantic --> LexieGrey\nMarkSloan -- flirtation --> AddisonMontgomery\nMarkSloan -- one-night --> CallieTorres\nMarkSloan -- one-night --> TeddyAltman\nMarkSloan -- one-night --> ReedAdamson\n\n%% Lexie Grey\nLexieGrey -- romantic --> MarkSloan\nLexieGrey -- romantic --> JacksonAvery\nLexieGrey -- one-night --> AlexKarev\n\n%% Jackson Avery\nJacksonAvery -- romantic --> LexieGrey\nJacksonAvery -- romantic --> AprilKepner\nJacksonAvery -- romantic --> MaggiePierce\nJacksonAvery -- one-night --> JoWilson\n\n%% April Kepner\nAprilKepner -- romantic --> JacksonAvery\nAprilKepner -- romantic --> MatthewTaylor\n\n%% Jo Wilson\nJoWilson -- romantic --> AlexKarev\nJoWilson -- romantic --> JasonMyers\nJoWilson -- one-night --> JacksonAvery\n\n%% Andrew DeLuca\nAndrewDeLuca -- romantic --> MaggiePierce\nAndrewDeLuca -- romantic --> MeredithGrey\n\n%% Amelia Shepherd\nAmeliaShepherd -- romantic --> OwenHunt\nAmeliaShepherd -- romantic --> AtticusLincoln\nAmeliaShepherd -- romantic --> KaiBartley\n\n%% Maggie Pierce\nMaggiePierce -- romantic --> AndrewDeLuca\nMaggiePierce -- romantic --> JacksonAvery\nMaggiePierce -- romantic --> WinstonNdugu\n\n%% Teddy Altman\nTeddyAltman -- romantic --> OwenHunt\nTeddyAltman -- romantic --> TomKoracick\nTeddyAltman -- one-night --> MarkSloan\n\n%% Erica Hahn\nEricaHahn -- romantic --> CallieTorres\n\n%% Preston Burke\nPrestonBurke -- romantic --> CristinaYang\n\n%% Nathan Riggs\nNathanRiggs -- romantic --> MeredithGrey\nNathanRiggs -- romantic --> MeganHunt\n\n%% Levi Schmitt\nLeviSchmitt -- romantic --> NicoKim\n\n%% Nico Kim\nNicoKim -- romantic --> LeviSchmitt\n\n%% Miranda Bailey\nMirandaBailey -- romantic --> BenWarren\n\n%% Ben Warren\nBenWarren -- romantic --> MirandaBailey\n\n%% Richard Webber\nRichardWebber -- romantic --> EllisGrey\nRichardWebber -- romantic --> CatherineFox\n\n%% Ellis Grey\nEllisGrey -- romantic --> RichardWebber\n\n%% Catherine Fox\nCatherineFox -- romantic --> RichardWebber\n\n%% Tom Koracick\nTomKoracick -- romantic --> TeddyAltman\n\n%% Atticus Lincoln\nAtticusLincoln -- romantic --> AmeliaShepherd\n\n%% Nick Marsh\nNickMarsh -- romantic --> MeredithGrey\n```\n\n\n\n\nThis is a directed graph -- the edges are arrows, starting from the person initiating the relationship (presumably) and ending at the person who is the target of the relationship. \nThere is an additional value on each edge that describes the type of relationship. \n\nWe can imagine describing this data in tabular form as follows, showing some of the nodes involving Meredith Grey to save space: \n\nPerson1 | Person2 | type\n---- | ---- | ----\nMeredithGrey | DerekShepherd | romantic\nMeredithGrey | NathanRiggs | romantic\nMeredithGrey | AndrewDeLuca | romantic\nMeredithGrey | NickMarsh | romantic\nMeredithGrey | GeorgeOMalley | one-night\nGeorgeOMalley | MeredithGrey | one-night\n... | ... | ...\n\nThen, if we have additional data on each person, such as an astrological sign, we could also have a person table containing that information. \nWe can then reshape and join these tables to create different tables that are suitable for different analyses.\n\nIf you'd like to play around with this data, there are two JSON files that contain all of the information you would need: [relationships](../data/greys-anatomy-data.json), and [astrological signs](../data/greys-anatomy-astrology.json) (not all characters have known or imputed astrological signs, so there will be some missing data).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(jsonlite)\n\nsign_order <- c(\"Aries\", \"Taurus\", \"Gemini\", \"Cancer\", \"Leo\", \"Virgo\", \"Libra\", \"Scorpio\", \"Sagittarius\", \"Capricorn\", \"Aquarius\", \"Pisces\")\n\nrelationships <- read_json(\"../data/greys-anatomy-data.json\") |>\n  map_df(as_tibble)\nastrology <- read_json(\"../data/greys-anatomy-astrology.json\")\nastrology <- tibble(Person = names(astrology), sign = unlist(astrology)) |>\n  mutate(sign = factor(sign, levels = sign_order, ordered = T))\n```\n:::\n\n\n\n\n\nSince I don't know anything about astrology, let's start by examining whether certain astrological signs are more likely to have a certain type of relationship. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_rels <- relationships |> \n  mutate(id = 1:n()) |> # <1>\n  pivot_longer(cols = 1:2) # <1>\n\nrels_signs <- long_rels |>\n  left_join(astrology, by = c(\"value\" = \"Person\")) # <2>\n\n# Data that is left out\nanti_join(long_rels, astrology, by = c(\"value\" = \"Person\")) # <3>\nanti_join(astrology, long_rels, by = c(\"Person\" = \"value\")) # <3>\n\ncontingency_table <- table(long_rels$relationship, long_rels$sign) # <4>\n## Error in table(long_rels$relationship, long_rels$sign): all arguments must have the same length\nknitr::kable(contingency_table, caption = \"Types of relationships, by astrological signs of the participants.\", label = \"tbl-grey-relationship-type-sign\")\n## Error: object 'contingency_table' not found\n## # A tibble: 16 × 4\n##    relationship    id name   value         \n##    <chr>        <int> <chr>  <chr>         \n##  1 one-night        6 target Steve Murphy  \n##  2 one-night        7 target William Thorpe\n##  3 one-night        8 target Finn Dandridge\n##  4 flirtation      14 target Emma Marling  \n##  5 one-night       18 target Olivia Harper \n##  6 one-night       19 target Rebecca Pope  \n##  7 one-night       23 target Olivia Harper \n##  8 one-night       27 target Penny Blake   \n##  9 flirtation      28 target Lauren Boswell\n## 10 flirtation      29 target Carina DeLuca \n## 11 one-night       33 target Reed Adamson  \n## 12 romantic        38 target Matthew Taylor\n## 13 romantic        39 target Jason Myers   \n## 14 romantic        42 target Kai Bartley   \n## 15 romantic        43 target Winston Ndugu \n## 16 romantic        45 target Nico Kim      \n## # A tibble: 0 × 2\n## # ℹ 2 variables: Person <chr>, sign <ord>\n```\n:::\n\n\n\n1. Keep relationships together by adding an ID variable (for tracking data backwards after the pivot operation), and then pivot the first two variables into a \"name\" (source or target) and \"value\" (Person's name) column, keeping relationship type and id as originally specified.\n2. Add in the person's astrological sign. This is expected to be a many-to-one relationship -- each person should have one astrological sign, but there may be many relationships specified for a single person in the table, as the show went on for 21 years. \n3. We do a sanity check to see what data was left out of the join step in 2. This requires checking both the forward and backwards joins -- the first shows the rows in `long_rels` that aren't in `astrology` (because the characters don't have astrological signs that are known), while the second shows the rows in `astrology` that don't have an equivalent in `long_rels` (there aren't any, in this case). Checking this ensures that you don't accidentally lose data. \n4. Create the contingency table showing relationship type in rows and astrological sign in columns. \n\nThis table has a *lot* of zeros, so I don't think we're going to be able to pull off a statistical analysis because the data is too sparse. \nPerhaps we could ask AI for similar data sets on the characters of House, ER, and other medical dramas, and then combine the data, if we wanted to proceed with a formal analysis.\n@holsterChapter7Network2022 provides demonstrations for how to analyze network data, if you are interested. \n\nWe can also just join both the source and the target in the same dataset to combine the information, as long as we are careful about renaming columns -- the resulting contingency table is shown under the code chunk below. \nThe sparsity of this data (we have 144 possible astrological combinations, and only 48 relationships) all but guarantees that we won't be able to do any meaningful data analysis -- Grey's Anatomy just didn't have enough relationships over 21 years for statistical purposes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrelationship_signs <- relationships |> \n  left_join(astrology, by = c(\"source\" = \"Person\")) |>\n  rename(source_sign = sign) |>\n  left_join(astrology, by = c(\"target\" = \"Person\")) |>\n  rename(target_sign = sign)\n\ntable(Source = relationship_signs$source_sign, Target = relationship_signs$target_sign) |>\n  knitr::kable(caption = \"Relationships in Grey's Anatomy, by astrological sign of the initiating individual (rows) and the target (columns). Not all relationships are included as not all characters have known or imputed (by the actor's sign) astrological sign.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Relationships in Grey's Anatomy, by astrological sign of the initiating individual (rows) and the target (columns). Not all relationships are included as not all characters have known or imputed (by the actor's sign) astrological sign.\n\n|            | Aries| Taurus| Gemini| Cancer| Leo| Virgo| Libra| Scorpio| Sagittarius| Capricorn| Aquarius| Pisces|\n|:-----------|-----:|------:|------:|------:|---:|-----:|-----:|-------:|-----------:|---------:|--------:|------:|\n|Aries       |     0|      0|      0|      0|   0|     0|     0|       0|           0|         0|        0|      0|\n|Taurus      |     0|      0|      1|      0|   0|     0|     0|       0|           0|         0|        0|      0|\n|Gemini      |     1|      1|      0|      0|   1|     0|     0|       0|           2|         0|        0|      0|\n|Cancer      |     1|      0|      0|      0|   0|     1|     0|       0|           0|         0|        0|      0|\n|Leo         |     1|      0|      0|      0|   0|     1|     0|       1|           0|         0|        0|      0|\n|Virgo       |     0|      1|      1|      0|   0|     1|     1|       1|           1|         0|        0|      1|\n|Libra       |     0|      0|      0|      0|   0|     0|     0|       0|           0|         0|        0|      0|\n|Scorpio     |     0|      0|      0|      1|   0|     2|     0|       1|           0|         0|        0|      1|\n|Sagittarius |     0|      0|      0|      0|   0|     1|     0|       0|           0|         0|        0|      0|\n|Capricorn   |     0|      0|      0|      0|   0|     0|     0|       1|           0|         0|        0|      0|\n|Aquarius    |     0|      0|      0|      1|   1|     0|     0|       0|           1|         0|        0|      0|\n|Pisces      |     0|      0|      2|      0|   0|     0|     1|       0|           0|         0|        0|      1|\n\n\n:::\n:::\n\n\n\n\n\n:::\n\nBefore converting relational tables describing a network into a joint tabular structure assessing what we want to know, it is important to think carefully about the size of the data you are working with, as well as the types of joins you plan to execute.\nThinking carefully about what dimension you expect your output to be will help you ensure that your join was executed as expected, and will also hopefully prevent you from doing a multiple-to-multiple join that outputs a behemoth of a dataset and potentially crashes your computer. \nEvery example is different, so think carefully about which columns you want to use to join, whether you expect a many-to-many relationship between tables, and what the output dimension should be. \n\n:::: example\n\n##### Example: Computer Language Influences {-}\n\nNew computer languages are often influenced by existing languages -- for instance, R is an open-source clone of S, which was a proprietary language used at IBM -- the function names are the same, but the methods are not necessarily identical underneath the hood. \n\nI [worked with ChatGPT](../data/language-inheritance-gpt.txt) to develop a \"family tree\" of programming languages, focusing primarily on those used for data analysis tasks. \nChatGPT was categorically wrong several times, so while I can vouch for the R/Julia/Python portions of the tree, it's harder to guarantee that the other portions of the tree are 100% correct, though they seem to mostly match up with my prior knowledge. \nIn this case, the goal is to provide you with a dataset that can be manipulated, so that's the critical part of this exercise. \n\n::: panel-tabset\n###### Problem Description {-}\n\nThe json file [`Language-Inheritance.json`](../data/Language-Inheritance.json) provides data on each programming language in the relationship diagram, including the release date and creator(s) credited with the language. \n\n\n\n\n```{mermaid}\n%%| label: fig-computer-language-inheritance\n%%| fig-cap: Relationships between computer languages. Direct influences are shown with solid lines, while indirect influences based on the larger ecosystem of programming languages at the time are shown with dotted lines. \n%%| file: ../images/advanced/Language-Network.mmd\n---\nconfig:\n  layout: elk\n---\nflowchart TD\n    Lisp[\"Lisp\"] --> Smalltalk[\"Smalltalk\"]\n    Algol[\"Algol\"] --> C[\"C\"] & Pascal[\"Pascal\"]\n    C --> C++[\"C++\"] & ObjectiveC[\"ObjectiveC\"] & Go[\"Go\"]\n    C++ --> Java[\"Java\"]\n    Java --> C#[\"C#\"] & Scala[\"Scala\"] & Kotlin[\"Kotlin\"]\n    Smalltalk --> ObjectiveC\n    Perl[\"Perl\"] --> Ruby[\"Ruby\"]\n    ML[\"ML\"] --> Haskell[\"Haskell\"]\n    Scheme[\"Scheme\"] --> JavaScript[\"JavaScript\"]\n    ObjectiveC --> Swift[\"Swift\"]\n    S[\"S\"] --> R[\"R\"]\n    Fortran[\"Fortran\"] -.-> Algol & SAS[\"SAS\"] & S\n    Smalltalk -.-> C++ & Java & Ruby\n    Perl -.-> Python[\"Python\"]\n    Lisp -.-> Python & R & Julia[\"Julia\"] & S\n    C -.-> Python\n    Haskell -.-> Scala\n    C++ -.-> Rust[\"Rust\"]\n    ML -.-> Rust\n    Rust -.-> Swift\n    Java -.-> JavaScript\n    SAS -.-> R\n    Python -.-> Julia\n    R -.-> Julia\n    UnixShell[\"UnixShell\"] -.-> S\n    GLIMSPSS[\"GLIMSPSS\"] -.-> S\n```\n\n\n\n\nRead this JSON data in, and convert the information to two tables - a language table and a relationship table. \nEnsure that ChatGPT at least did not claim that a language (A) inherits from a language (B) released after the release of language A. \n(One draft of this data claimed that Matlab inherited from Julia, which was released well after Matlab). \n\n\nIn the case of equal release years, this would indicate rapid language development. \nOtherwise, this would indicate one of several possibilities: time travel, evolution of the language to incorporate new influences, or ChatGPT is wrong. \nIn any of these cases, more research would be necessary to determine what happened and whether the link is reasonably included in the dataset. \n\n###### R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\n\nproglang <- read_json(\"../data/Language-Inheritance.json\") # <1>\n# str(proglang) # long set of output\n\nproglang$nodes[[1]]\n\nfix_nodes <- function(i) { # <2>\n  tibble(id = i$id, year = i$year, creators = list(i$creators)) # <2>\n} # <2>\n\nproglangnodes <- map_dfr(proglang$nodes, fix_nodes)  # <3>\nhead(proglangnodes)\n\nproglang$edges[[1]]\n\nproglangedges <- map_dfr(proglang$edges, as_tibble)  # <4>\nhead(proglangedges)\n\nproglangrels <- left_join(proglangedges, proglangnodes, by = c(\"source\"=\"id\")) |>   # <5>\n  rename(year_source=year) |>  # <6>\n  select(-creators) |>  # <6>\n  left_join(proglangnodes, by = c(\"target\" = \"id\")) |>  # <7>\n  rename(year_target = year) |>  # <8>\n  select(-creators)  # <8>\n\nfilter(proglangrels, year_source >= year_target)   # <9>\n## $id\n## [1] \"Fortran\"\n## \n## $year\n## [1] 1957\n## \n## $creators\n## $creators[[1]]\n## [1] \"John Backus\"\n## \n## $creators[[2]]\n## [1] \"IBM\"\n## \n## \n## # A tibble: 6 × 3\n##   id         year creators  \n##   <chr>     <int> <list>    \n## 1 Fortran    1957 <list [2]>\n## 2 Lisp       1958 <list [1]>\n## 3 Algol      1958 <list [1]>\n## 4 C          1972 <list [1]>\n## 5 Smalltalk  1972 <list [3]>\n## 6 C++        1983 <list [1]>\n## $source\n## [1] \"Fortran\"\n## \n## $target\n## [1] \"Algol\"\n## \n## $relationship\n## [1] \"ecosystem\"\n## \n## # A tibble: 6 × 3\n##   source    target    relationship\n##   <chr>     <chr>     <chr>       \n## 1 Fortran   Algol     ecosystem   \n## 2 Lisp      Smalltalk inheritance \n## 3 Algol     C         inheritance \n## 4 Algol     Pascal    inheritance \n## 5 C         C++       inheritance \n## 6 Smalltalk C++       ecosystem   \n## # A tibble: 1 × 5\n##   source target     relationship year_source year_target\n##   <chr>  <chr>      <chr>              <int>       <int>\n## 1 Java   JavaScript ecosystem           1995        1995\n```\n:::\n\n\n\n1. Read in the data\n2. Create a tibble row from the data, using a list-column for the creators. This approach is a direct result of seeing the structure of the first node in the nodes sub-list, because it can't be easily rectangularized without list-columns. \n3. For each language, apply the `fix_nodes` function, combining results rowwise into a tibble.\n4. Create a tibble row from the edge data. We can use `as_tibble` here because the data only has 3 components and there aren't any list-columns needed. \n5. Left join the edges and nodes to get information on the source language. \n6. Rename the year to be clearer that this is the year of the source language, and remove creators because we don't need them right now. \n7. Left join the edges and nodes again, adding information on the target language.\n8. Rename the year to be clearer - target language, and remove creators again because they're not important to answer our quesiton.\n9. Determine whether any source languages have a year that's greater than or equal to the target language. \n\n\n\n###### Python\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport json\nimport pandas as pd\n\nwith open('../data/Language-Inheritance.json') as f: # <1> \n  data = json.load(f) # <1> \n\nproglangnodes = pd.DataFrame(data['nodes']) # <2> \nproglangyears = proglangnodes.drop('creators', axis = 1).set_index('id') # <3> \n\nproglangedges = pd.DataFrame(data['edges']) # <4> \n\nres = proglangedges.join(proglangyears, on = \"source\", how = 'left') # <5> \nres = res.rename(columns = {'year':'year_source'}) # <6> \nres.head()\n\nres = res.join(proglangyears, on = \"target\", how = 'left') # <7> \nres = res.rename(columns = {'year':'year_target'}) # <8> \nres.head()\n\nres.query('year_source>=year_target') # <9> \n##     source     target relationship  year_source\n## 0  Fortran      Algol    ecosystem         1957\n## 1     Lisp  Smalltalk  inheritance         1958\n## 2    Algol          C  inheritance         1958\n## 3    Algol     Pascal  inheritance         1958\n## 4        C        C++  inheritance         1972\n##     source     target relationship  year_source  year_target\n## 0  Fortran      Algol    ecosystem         1957       1958.0\n## 1     Lisp  Smalltalk  inheritance         1958       1972.0\n## 2    Algol          C  inheritance         1958       1972.0\n## 3    Algol     Pascal  inheritance         1958          NaN\n## 4        C        C++  inheritance         1972       1983.0\n##    source      target relationship  year_source  year_target\n## 25   Java  JavaScript    ecosystem         1995       1995.0\n```\n:::\n\n\n\n1. Read in the data\n2. Create a DataFrame from the nodes (pandas automatically uses list-columns here)\n3. Define a DataFrame with just the language and year, and set the language ('id') as the index to prepare for joining this to the edge dataset. \n4. Create a DataFrame from the edge data. \n5. Left join the edges and nodes to get information on the source language. \n6. Rename the year to be clearer that this is the year of the source language.\n7. Left join the edges and nodes again, adding information on the target language.\n8. Rename the year to be clearer - target language.\n9. Determine whether any source languages have a year that's greater than or equal to the target language. \n\n:::\n\nThe Wikipedia page for [JavaScript](https://en.wikipedia.org/wiki/JavaScript#History) suggests that JavaScript was influenced by Java, and that JavaScript appeared in December 1995 while Java appeared in May 1995. \nSo, I suppose we can conclude at this point that the stated link is reasonable. \n::::\n\n## Developing A Conversion Strategy\n\nWhen you have an XML or JSON data file that is record based, it can be tricky to determine the best way to convert this into a tabular data structure. \n\nA general strategy will look something like this:\n\n1. What types of records do you have? Are there multiple  types? How do they relate to each other?\n    - Identify linking variables (keys)\n    - Identify problematic attributes -- things that may be missing in some records, or may need to be list-columns or even nested data frames. \n2. What data do you need? Sometimes, you don't have to convert the entire dataset into a tabular structure -- you can be selective about it, and save yourself a ton of work.\n3. What do you plan to do with the data? Sketch out the form of your target data (rows, columns, data types) so that you can plan a strategy of how to get from A to B. \n4. Write functions to convert records into rows of a table (if step 1 has problematic attributes) or use a list-to-table conversion function (if step 1 doesn't have problematic attributes). \n5. Double-check several records to ensure all data is accounted for and that keys match as expected.\n\n:::: demo\n\n### Demo: Book/TV Show Characters\n\nI have assembled a JSON file of all of the characters in A Song of Ice and Fire by George R. R. Martin using [An API of Ice and Fire](https://anapioficeandfire.com/) (I'll show how to do this in the next chapter). \nThe series has been used to create several TV Shows (Game of Thrones, House of the Dragon, and A Knight of the Seven Kingdoms).\n\nThe JSON file has more than 50k rows, but it's clear that there is a structure to the data, along with a lot of missing information. \n\nThe tabs below work through the five steps listed immediately above this section.\n\n::: panel-tabset\n\n#### 1. Examine the record structure\n\nThere is only one type of record in the file -- data corresponding to each character in the series. \n\n::: {.callout  collapse=true}\n##### Selection of 4 records\n\n```\n{\n\t\t\"url\": \"https://anapioficeandfire.com/api/characters/1\",\n\t\t\"name\": \"\",\n\t\t\"gender\": \"Female\",\n\t\t\"culture\": \"Braavosi\",\n\t\t\"born\": \"\",\n\t\t\"died\": \"\",\n\t\t\"titles\": [],\n\t\t\"aliases\": [\n\t\t\t\"The Daughter of the Dusk\"\n\t\t],\n\t\t\"father\": \"\",\n\t\t\"mother\": \"\",\n\t\t\"spouse\": \"\",\n\t\t\"allegiances\": [],\n\t\t\"books\": [\n\t\t\t\"https://anapioficeandfire.com/api/books/5\"\n\t\t],\n\t\t\"povBooks\": [],\n\t\t\"tvSeries\": [],\n\t\t\"playedBy\": []\n\t},\t\n\t{\n\t\t\"url\": \"https://anapioficeandfire.com/api/characters/238\",\n\t\t\"name\": \"Cersei Lannister\",\n\t\t\"gender\": \"Female\",\n\t\t\"culture\": \"Westerman\",\n\t\t\"born\": \"In 266 AC, at Casterly Rock\",\n\t\t\"died\": \"\",\n\t\t\"titles\": [\n\t\t\t\"Light of the West\",\n\t\t\t\"Queen Dowager\",\n\t\t\t\"Protector of the Realm\",\n\t\t\t\"Lady of Casterly Rock\",\n\t\t\t\"Queen Regent\"\n\t\t],\n\t\t\"aliases\": [\n\t\t\t\"Brotherfucker\",\n\t\t\t\"The bitch queen\"\n\t\t],\n\t\t\"father\": \"\",\n\t\t\"mother\": \"\",\n\t\t\"spouse\": \"https://anapioficeandfire.com/api/characters/901\",\n\t\t\"allegiances\": [\n\t\t\t\"https://anapioficeandfire.com/api/houses/229\"\n\t\t],\n\t\t\"books\": [\n\t\t\t\"https://anapioficeandfire.com/api/books/1\",\n\t\t\t\"https://anapioficeandfire.com/api/books/2\",\n\t\t\t\"https://anapioficeandfire.com/api/books/3\"\n\t\t],\n\t\t\"povBooks\": [\n\t\t\t\"https://anapioficeandfire.com/api/books/5\",\n\t\t\t\"https://anapioficeandfire.com/api/books/8\"\n\t\t],\n\t\t\"tvSeries\": [\n\t\t\t\"Season 1\",\n\t\t\t\"Season 2\",\n\t\t\t\"Season 3\",\n\t\t\t\"Season 4\",\n\t\t\t\"Season 5\",\n\t\t\t\"Season 6\"\n\t\t],\n\t\t\"playedBy\": [\n\t\t\t\"Lena Headey\"\n\t\t]\n\t},\n\t{\n\t\t\"url\": \"https://anapioficeandfire.com/api/characters/2\",\n\t\t\"name\": \"Walder\",\n\t\t\"gender\": \"Male\",\n\t\t\"culture\": \"\",\n\t\t\"born\": \"\",\n\t\t\"died\": \"\",\n\t\t\"titles\": [],\n\t\t\"aliases\": [\n\t\t\t\"Hodor\"\n\t\t],\n\t\t\"father\": \"\",\n\t\t\"mother\": \"\",\n\t\t\"spouse\": \"\",\n\t\t\"allegiances\": [\n\t\t\t\"https://anapioficeandfire.com/api/houses/362\"\n\t\t],\n\t\t\"books\": [\n\t\t\t\"https://anapioficeandfire.com/api/books/1\",\n\t\t\t\"https://anapioficeandfire.com/api/books/2\",\n\t\t\t\"https://anapioficeandfire.com/api/books/3\",\n\t\t\t\"https://anapioficeandfire.com/api/books/5\",\n\t\t\t\"https://anapioficeandfire.com/api/books/8\"\n\t\t],\n\t\t\"povBooks\": [],\n\t\t\"tvSeries\": [\n\t\t\t\"Season 1\",\n\t\t\t\"Season 2\",\n\t\t\t\"Season 3\",\n\t\t\t\"Season 4\",\n\t\t\t\"Season 6\"\n\t\t],\n\t\t\"playedBy\": [\n\t\t\t\"Kristian Nairn\"\n\t\t]\n\t},\n  {\n  \t\t\"url\": \"https://anapioficeandfire.com/api/characters/208\",\n  \t\t\"name\": \"Brandon Stark\",\n  \t\t\"gender\": \"Male\",\n  \t\t\"culture\": \"Northmen\",\n  \t\t\"born\": \"In 290 AC, at Winterfell\",\n  \t\t\"died\": \"\",\n  \t\t\"titles\": [\n  \t\t\t\"Prince of Winterfell\"\n  \t\t],\n  \t\t\"aliases\": [\n  \t\t\t\"Bran\",\n  \t\t\t\"Bran the Broken\",\n  \t\t\t\"The Winged Wolf\"\n  \t\t],\n  \t\t\"father\": \"\",\n  \t\t\"mother\": \"\",\n  \t\t\"spouse\": \"\",\n  \t\t\"allegiances\": [\n  \t\t\t\"https://anapioficeandfire.com/api/houses/362\"\n  \t\t],\n  \t\t\"books\": [\n  \t\t\t\"https://anapioficeandfire.com/api/books/5\"\n  \t\t],\n  \t\t\"povBooks\": [\n  \t\t\t\"https://anapioficeandfire.com/api/books/1\",\n  \t\t\t\"https://anapioficeandfire.com/api/books/2\",\n  \t\t\t\"https://anapioficeandfire.com/api/books/3\",\n  \t\t\t\"https://anapioficeandfire.com/api/books/8\"\n  \t\t],\n  \t\t\"tvSeries\": [\n  \t\t\t\"Season 1\",\n  \t\t\t\"Season 2\",\n  \t\t\t\"Season 3\",\n  \t\t\t\"Season 4\",\n  \t\t\t\"Season 6\"\n  \t\t],\n  \t\t\"playedBy\": [\n  \t\t\t\"Isaac Hempstead-Wright\"\n  \t\t]\n  \t}\n```\n:::\n\nAny entry that includes a URL is a linking variable (by definition, as well as in practice -- it is not this easy to figure out linking variables in every dataset). \n\nWe can also see that 'books' does not include 'povBooks' - that is, if the character has a point-of-view chapter in a book, it is included in 'povBooks' instead of 'books'. \nWe might want to do a bit of cleaning here, and create a table that has books and a logical variable indicating if the character has a POV chapter in that book. \n\nWhat isn't clear is whether multiple actors could play a single character -- for instance, if there was a young version and an old version of a character in a flashback. \nThat occurrence doesn't seem to happen here (there's only one playedBy value for any character, as far as I can tell), but it could. \nOf course, if this did occur, the JSON data structure should be different as well -- perhaps with series and playedBy nested under a single variable and constrained to be the same length, so that it's clear which actor played in each series. \n\n#### 2. Identify Needed Data\n\nIn this case, we don't know what data we need (because I haven't specified an analysis) so we need to keep all of the data.\n\n#### 3. Sketch Form of the Data\n\n\nRight away, it is possible to conceptualize this data in a number of different ways. \nWe can store links within a single table, using list-columns, or we could store some of the relational information in different tables, and keep our main table very simple in structure. \n\n![Only 3 tables, with lots of list-columns in personal information.](../images/advanced/list-proc-asoiaf-org1.svg){fig-alt=\"A sketch of a set of 3 data tables, with ID as a linking key between them. The first table is labeled Personal Information and has columns ID, URL, Name, Gender, Culture, Born, Died, Titles (list-col), Aliases (list-col), Father, Mother, Spouse (list-col), Allegiances (list-col). The second table has Book information, with columns ID, Book, and pov (point of view). The third is labeled TV Show Information and has columns ID, TVSeries, and playedBy.\"}\n![Four Tables, moving father, mother, and spouse relationships to a general 'Relationship Information' table where the type of relationship is described along with a link to the other individual's ID.](../images/advanced/list-proc-asoiaf-org2.svg){fig-alt=\"A sketch of a set of 4 data tables, with ID as a linking key between them. The first table is labeled Personal Information and has columns ID, URL, Name, Gender, Culture, Born, Died, Titles (list-col), Aliases (list-col), Allegiances (list-col). The second is labeled Relationship Information and has columns ID, URL, RelationshipType, and RelativeID. The third table has Book information, with columns ID, Book, and pov (point of view). The fourth is labeled TV Show Information and has columns ID, TVSeries, and playedBy.\"}\n\n![A structure with no list-columns. Any list-column could be moved to its own table using the ID variable as a link, if this is preferable to work with.](../images/advanced/list-proc-asoiaf-org3.svg){fig-alt=\"A sketch of a set of 7 data tables, with ID as a linking key between them. The first table is labeled Personal Information and has columns ID, URL, Name, Gender, Culture, Born, Died. The second is labeled Relationship Information and has columns ID, URL, RelationshipType, and RelativeID. The third table has Book information, with columns ID, Book, and pov (point of view). The fourth is labeled TV Show Information and has columns ID, TVSeries, and playedBy. The fifth is labeled Titles and has columns ID and Title. The sixth is labeled Aliases and has columns ID and Alias. The seventh is labeled Allegiances and has columns ID and Allegiance.\"}\nWe must generally assume that almost any field other than ID/URL can be blank, and fields like Titles, Aliases, Allegiances, Spouse, Book, pov (point of view), and TVSeries can contain multiple values. \n\n\nOf these strategies, the second strategy seems like it's the easiest to work with for most general problems -- it strikes a balance between number of tables (which will require joins to get into an analysis form, most likely) and the complexities of having to deal with list-columns. \n\n#### 4. Write Functions to Format Data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(jsonlite)\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(stringr)\n\ndata <- read_json(\"../data/asoiaf_characters.json\") # <1>\n\nblank_to_na <- function(j) {  # <2>\n  if (is.null(j)) {  # <3>\n    return(NA)  # <3>\n  }  # <3>\n  if (length(j) == 0) {  # <3>\n    return(NA)  # <3>\n  }  # <3>\n  if (length(j) > 1) {  # <4>\n    return(list(unlist(j)))  # <4>\n  }  # <4>\n  if (j == \"\") {  # <5>\n    return(NA)  # <5>\n  }  # <5>\n  return(j)  # <6>\n}\n\nfix_char_data <- function(i) {  # <7>\n  ifix <- map(i, blank_to_na)  # <8>\n  ifixtbl <- as_tibble(ifix) |>  # <9>\n    mutate(id = str_remove(url, \"https://anapioficeandfire.com/api/characters/\"))  # <9>\n  \n  personalInfo <- ifixtbl |>  # <10>\n    select(id, url, name, gender, culture, born, died, titles, aliases, allegiances)  # <10>\n  \n  relationships <- ifixtbl |>  # <11>\n    select(id, father, mother, spouse) |>  # <11>\n    pivot_longer(-id, names_to = \"relationship_type\", values_to = \"relative_ID\") |>  # <11>\n    unnest(relative_ID) |>  # <11>\n    mutate(relationship_type = as.character(relationship_type),   # <11>\n           relative_ID = as.character(relative_ID)) |>  # <11>\n    filter(!is.na(relative_ID))  # <11>\n  \n  book <- ifixtbl |>  # <12>\n    select(id, books, povBooks) |>  # <12>\n    pivot_longer(-id) |>  # <12>\n    unnest(value) |>  # <12>\n    mutate(pov = name == \"povBooks\") |>  # <12>\n    select(id, book = value, pov) |>  # <12>\n    mutate(book = as.character(book), pov = as.character(pov)) |>  # <12>\n    filter(!is.na(book))  # <12>\n  \n  tv_show <- ifixtbl |>  # <13>\n    select(id, tvSeries, playedBy) |>  # <13>\n    unnest(tvSeries) |>  # <13>\n    unnest(playedBy) |>  # <13>\n    mutate(tvSeries = as.character(tvSeries), playedBy = as.character(playedBy)) |>  # <13>\n    filter(!is.na(tvSeries))  # <13>\n  \n  return(tibble(personal = list(personalInfo),   # <14>\n                relationships = list(relationships),    # <14>\n                book = list(book),    # <14>\n                tv = list(tv_show)))   # <14>\n}\n\ndatatbl <- map_dfr(data, fix_char_data)   # <15>\n\npersonalInfo <- bind_rows(datatbl$personal)   # <16>\nrelationships <- bind_rows(datatbl$relationships)   # <16>\nbook <- bind_rows(datatbl$book)   # <16>\ntv_show <- bind_rows(datatbl$tv)   # <16>\n```\n:::\n\n\n\n1. Read in the data\n2. Write a function to handle different types of 'missingness' and replace with NA. \n3. If the object is null or has length 0, return NA. \n4. If the object is a list, return the list, but ensure it has only one level of hierarchy. This *could* get us in trouble if we used this same function on a different dataset, but the character variables don't have multiple levels of nesting, so it's ok in this case. This addition ensures we don't accidentally add another level of nesting, but also that we can handle an unnested list appropriately. \n5. Another option for a 'blank' value is to have an empty string. We want to also replace that with NA. 6. If none of the empty options is true, then just return the value.\n7. Now, we write a function to create data table rows for each individual's data, for the 4 tables we decided to create. Creating each row of the 4 tables and using nested data frames allows us to only run the fixit function once, and then slice the data into sub-tables as we want. \n8. Fix the data.\n9. Convert the fixed data to a table so it's easily manipulated with dplyr/tidyr\n10. Select the personal information into a separate table.\n11. Select the relationship information into a separate table. Then, pivot the relationships into relationshipType and relative_ID. Once that's done, we can unnest, which allows for multiple values of mother, father, and spouse. The mutate() statement just ensures that all variables are typed correctly - otherwise, we might have the default NA_logical_ instead of NA_character_ and get an error when we bind all the rows together. \n12. Select the book information into a separate table. Then, pivot the relationships into book and pov, unnest, and create the pov variable as a logical indicating whether the book came from povBooks or books. The mutate() statement just ensures that all variables are typed correctly - otherwise, we might have the default NA_logical_ instead of NA_character_ and get an error when we bind all the rows together. \n13. Select the tv information into a separate table and unnest each variable. This could lead to a many-to-many relationship in the case that someone played a character in one series but another actor played the character in the next series. A more rational structure would be to have tvSeries and playedBy nested together, so that it would be possible to indicate this conclusively, but this is an issue with the original data structure that we just respond to. The mutate() statement just ensures that all variables are typed correctly - otherwise, we might have the default NA_logical_ instead of NA_character_ and get an error when we bind all the rows together. \n14. We return a nested tibble with each of the 4 tables we've created for our character. \n15. Apply the full function to each record in data.\n16. Extract each nested tibble out and bind the rows together to get the 4 tables we wanted.\n\n\n\n\n\n\n\n\n\n#### 5. Double-check Records for Accuracy\n\nWhen double-checking records, I like to use a combination of strategies - random spot-checking, as well as checking values I know are likely to be challenging in one way or another.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3420934)\ntests <- sample(size = 3, x = 1:length(data))\ntests\n## [1]  408 2000 1161\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Random individual with ID=`r .QuartoInlineRender(tests[1])`\"}\ni <- tests[1]\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/408\"\n## \n## $name\n## [1] \"Garth Tyrell\"\n## \n## $gender\n## [1] \"Male\"\n## \n## $culture\n## [1] \"\"\n## \n## $born\n## [1] \"\"\n## \n## $died\n## [1] \"\"\n## \n## $titles\n## $titles[[1]]\n## [1] \"Lord Seneschal\"\n## \n## \n## $aliases\n## $aliases[[1]]\n## [1] \"Garth the Gross\"\n## \n## \n## $allegiances\n## $allegiances[[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/398\"\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 408   https://ana… Gart… Male   <NA>    <NA>  <NA>  <chr>  <chr>   <chr [1]>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## [1] \"Lord Seneschal\"\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## [1] \"Garth the Gross\"\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/398\"\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/1\"\n## \n## $books[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $books[[3]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## $books[[4]]\n## [1] \"https://anapioficeandfire.com/api/books/5\"\n## \n## $books[[5]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\n## \n## \n## $povBooks\n## list()\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 5 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 408   https://anapioficeandfire.com/api/books/1 FALSE\n## 2 408   https://anapioficeandfire.com/api/books/2 FALSE\n## 3 408   https://anapioficeandfire.com/api/books/3 FALSE\n## 4 408   https://anapioficeandfire.com/api/books/5 FALSE\n## 5 408   https://anapioficeandfire.com/api/books/8 FALSE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, relationship_type <chr>, relative_ID <chr>\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## list()\n## \n## $playedBy\n## list()\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, tvSeries <chr>, playedBy <chr>\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Random individual with ID=`r .QuartoInlineRender(tests[2])`\"}\ni <- tests[2]\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/2000\"\n## \n## $name\n## [1] \"Thistle\"\n## \n## $gender\n## [1] \"Female\"\n## \n## $culture\n## [1] \"Free Folk\"\n## \n## $born\n## [1] \"\"\n## \n## $died\n## [1] \"In 300 AC, at Beyond the Wall\"\n## \n## $titles\n## list()\n## \n## $aliases\n## list()\n## \n## $allegiances\n## list()\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 2000  https://ana… This… Female Free F… <NA>  In 3… <NULL> <NULL>  <NULL>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## NULL\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## NULL\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## NULL\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\n## \n## \n## $povBooks\n## list()\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 1 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 2000  https://anapioficeandfire.com/api/books/8 FALSE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, relationship_type <chr>, relative_ID <chr>\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## list()\n## \n## $playedBy\n## list()\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, tvSeries <chr>, playedBy <chr>\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Random individual with ID=`r .QuartoInlineRender(tests[3])`\"}\ni <- tests[3]\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/1161\"\n## \n## $name\n## [1] \"Amabel\"\n## \n## $gender\n## [1] \"Female\"\n## \n## $culture\n## [1] \"\"\n## \n## $born\n## [1] \"\"\n## \n## $died\n## [1] \"\"\n## \n## $titles\n## list()\n## \n## $aliases\n## list()\n## \n## $allegiances\n## $allegiances[[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/427\"\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 1161  https://ana… Amab… Female <NA>    <NA>  <NA>  <NULL> <NULL>  <chr [1]>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## NULL\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## NULL\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/427\"\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $books[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## \n## $povBooks\n## list()\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 2 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 1161  https://anapioficeandfire.com/api/books/2 FALSE\n## 2 1161  https://anapioficeandfire.com/api/books/3 FALSE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, relationship_type <chr>, relative_ID <chr>\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## list()\n## \n## $playedBy\n## list()\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, tvSeries <chr>, playedBy <chr>\n```\n:::\n\n\n\n\nThen, we move on to the nonrandom sample, picking people we know and can verify, as  well as those who might reasonably have significant missing data or excessively long nested lists of attributes. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Arya Stark\"}\ni <- 148\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/148\"\n## \n## $name\n## [1] \"Arya Stark\"\n## \n## $gender\n## [1] \"Female\"\n## \n## $culture\n## [1] \"Northmen\"\n## \n## $born\n## [1] \"In 289 AC, at Winterfell\"\n## \n## $died\n## [1] \"\"\n## \n## $titles\n## $titles[[1]]\n## [1] \"Princess\"\n## \n## \n## $aliases\n## $aliases[[1]]\n## [1] \"Arya Horseface\"\n## \n## $aliases[[2]]\n## [1] \"Arya Underfoot\"\n## \n## $aliases[[3]]\n## [1] \"Arry\"\n## \n## $aliases[[4]]\n## [1] \"Lumpyface\"\n## \n## $aliases[[5]]\n## [1] \"Lumpyhead\"\n## \n## $aliases[[6]]\n## [1] \"Stickboy\"\n## \n## $aliases[[7]]\n## [1] \"Weasel\"\n## \n## $aliases[[8]]\n## [1] \"Nymeria\"\n## \n## $aliases[[9]]\n## [1] \"Squan\"\n## \n## $aliases[[10]]\n## [1] \"Saltb\"\n## \n## $aliases[[11]]\n## [1] \"Cat of the Canaly\"\n## \n## $aliases[[12]]\n## [1] \"Bets\"\n## \n## $aliases[[13]]\n## [1] \"The Blind Girh\"\n## \n## $aliases[[14]]\n## [1] \"The Ugly Little Girl\"\n## \n## $aliases[[15]]\n## [1] \"Mercedenl\"\n## \n## $aliases[[16]]\n## [1] \"Mercye\"\n## \n## \n## $allegiances\n## $allegiances[[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/362\"\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 148   https://ana… Arya… Female Northm… In 2… <NA>  <chr>  <chr>   <chr [1]>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## [1] \"Princess\"\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n##  [1] \"Arya Horseface\"       \"Arya Underfoot\"       \"Arry\"                \n##  [4] \"Lumpyface\"            \"Lumpyhead\"            \"Stickboy\"            \n##  [7] \"Weasel\"               \"Nymeria\"              \"Squan\"               \n## [10] \"Saltb\"                \"Cat of the Canaly\"    \"Bets\"                \n## [13] \"The Blind Girh\"       \"The Ugly Little Girl\" \"Mercedenl\"           \n## [16] \"Mercye\"\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/362\"\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## list()\n## \n## $povBooks\n## $povBooks[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/1\"\n## \n## $povBooks[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $povBooks[[3]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## $povBooks[[4]]\n## [1] \"https://anapioficeandfire.com/api/books/5\"\n## \n## $povBooks[[5]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 5 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 148   https://anapioficeandfire.com/api/books/1 TRUE \n## 2 148   https://anapioficeandfire.com/api/books/2 TRUE \n## 3 148   https://anapioficeandfire.com/api/books/3 TRUE \n## 4 148   https://anapioficeandfire.com/api/books/5 TRUE \n## 5 148   https://anapioficeandfire.com/api/books/8 TRUE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, relationship_type <chr>, relative_ID <chr>\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## $tvSeries[[1]]\n## [1] \"Season 1\"\n## \n## $tvSeries[[2]]\n## [1] \"Season 2\"\n## \n## $tvSeries[[3]]\n## [1] \"Season 3\"\n## \n## $tvSeries[[4]]\n## [1] \"Season 4\"\n## \n## $tvSeries[[5]]\n## [1] \"Season 5\"\n## \n## $tvSeries[[6]]\n## [1] \"Season 6\"\n## \n## \n## $playedBy\n## $playedBy[[1]]\n## [1] \"Maisie Williams\"\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 6 × 3\n##   id    tvSeries playedBy       \n##   <chr> <chr>    <chr>          \n## 1 148   Season 1 Maisie Williams\n## 2 148   Season 2 Maisie Williams\n## 3 148   Season 3 Maisie Williams\n## 4 148   Season 4 Maisie Williams\n## 5 148   Season 5 Maisie Williams\n## 6 148   Season 6 Maisie Williams\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Jon Snow\"}\ni <- 583\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/583\"\n## \n## $name\n## [1] \"Jon Snow\"\n## \n## $gender\n## [1] \"Male\"\n## \n## $culture\n## [1] \"Northmen\"\n## \n## $born\n## [1] \"In 283 AC\"\n## \n## $died\n## [1] \"\"\n## \n## $titles\n## $titles[[1]]\n## [1] \"Lord Commander of the Night's Watch\"\n## \n## \n## $aliases\n## $aliases[[1]]\n## [1] \"Lord Snow\"\n## \n## $aliases[[2]]\n## [1] \"Ned Stark's Bastard\"\n## \n## $aliases[[3]]\n## [1] \"The Snow of Winterfell\"\n## \n## $aliases[[4]]\n## [1] \"The Crow-Come-Over\"\n## \n## $aliases[[5]]\n## [1] \"The 998th Lord Commander of the Night's Watch\"\n## \n## $aliases[[6]]\n## [1] \"The Bastard of Winterfell\"\n## \n## $aliases[[7]]\n## [1] \"The Black Bastard of the Wall\"\n## \n## $aliases[[8]]\n## [1] \"Lord Crow\"\n## \n## \n## $allegiances\n## $allegiances[[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/362\"\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 583   https://ana… Jon … Male   Northm… In 2… <NA>  <chr>  <chr>   <chr [1]>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## [1] \"Lord Commander of the Night's Watch\"\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## [1] \"Lord Snow\"                                    \n## [2] \"Ned Stark's Bastard\"                          \n## [3] \"The Snow of Winterfell\"                       \n## [4] \"The Crow-Come-Over\"                           \n## [5] \"The 998th Lord Commander of the Night's Watch\"\n## [6] \"The Bastard of Winterfell\"                    \n## [7] \"The Black Bastard of the Wall\"                \n## [8] \"Lord Crow\"\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/362\"\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/5\"\n## \n## \n## $povBooks\n## $povBooks[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/1\"\n## \n## $povBooks[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $povBooks[[3]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## $povBooks[[4]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 5 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 583   https://anapioficeandfire.com/api/books/5 FALSE\n## 2 583   https://anapioficeandfire.com/api/books/1 TRUE \n## 3 583   https://anapioficeandfire.com/api/books/2 TRUE \n## 4 583   https://anapioficeandfire.com/api/books/3 TRUE \n## 5 583   https://anapioficeandfire.com/api/books/8 TRUE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 0 × 3\n## # ℹ 3 variables: id <chr>, relationship_type <chr>, relative_ID <chr>\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## $tvSeries[[1]]\n## [1] \"Season 1\"\n## \n## $tvSeries[[2]]\n## [1] \"Season 2\"\n## \n## $tvSeries[[3]]\n## [1] \"Season 3\"\n## \n## $tvSeries[[4]]\n## [1] \"Season 4\"\n## \n## $tvSeries[[5]]\n## [1] \"Season 5\"\n## \n## $tvSeries[[6]]\n## [1] \"Season 6\"\n## \n## \n## $playedBy\n## $playedBy[[1]]\n## [1] \"Kit Harington\"\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 6 × 3\n##   id    tvSeries playedBy     \n##   <chr> <chr>    <chr>        \n## 1 583   Season 1 Kit Harington\n## 2 583   Season 2 Kit Harington\n## 3 583   Season 3 Kit Harington\n## 4 583   Season 4 Kit Harington\n## 5 583   Season 5 Kit Harington\n## 6 583   Season 6 Kit Harington\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Cersei Lannister\"}\ni <- 238\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/238\"\n## \n## $name\n## [1] \"Cersei Lannister\"\n## \n## $gender\n## [1] \"Female\"\n## \n## $culture\n## [1] \"Westerman\"\n## \n## $born\n## [1] \"In 266 AC, at Casterly Rock\"\n## \n## $died\n## [1] \"\"\n## \n## $titles\n## $titles[[1]]\n## [1] \"Light of the West\"\n## \n## $titles[[2]]\n## [1] \"Queen Dowager\"\n## \n## $titles[[3]]\n## [1] \"Protector of the Realm\"\n## \n## $titles[[4]]\n## [1] \"Lady of Casterly Rock\"\n## \n## $titles[[5]]\n## [1] \"Queen Regent\"\n## \n## \n## $aliases\n## $aliases[[1]]\n## [1] \"Brotherfucker\"\n## \n## $aliases[[2]]\n## [1] \"The bitch queen\"\n## \n## \n## $allegiances\n## $allegiances[[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/229\"\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 238   https://ana… Cers… Female Wester… In 2… <NA>  <chr>  <chr>   <chr [1]>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## [1] \"Light of the West\"      \"Queen Dowager\"          \"Protector of the Realm\"\n## [4] \"Lady of Casterly Rock\"  \"Queen Regent\"\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## [1] \"Brotherfucker\"   \"The bitch queen\"\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## [1] \"https://anapioficeandfire.com/api/houses/229\"\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/1\"\n## \n## $books[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $books[[3]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## \n## $povBooks\n## $povBooks[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/5\"\n## \n## $povBooks[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 5 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 238   https://anapioficeandfire.com/api/books/1 FALSE\n## 2 238   https://anapioficeandfire.com/api/books/2 FALSE\n## 3 238   https://anapioficeandfire.com/api/books/3 FALSE\n## 4 238   https://anapioficeandfire.com/api/books/5 TRUE \n## 5 238   https://anapioficeandfire.com/api/books/8 TRUE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"https://anapioficeandfire.com/api/characters/901\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 1 × 3\n##   id    relationship_type relative_ID                                     \n##   <chr> <chr>             <chr>                                           \n## 1 238   spouse            https://anapioficeandfire.com/api/characters/901\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## $tvSeries[[1]]\n## [1] \"Season 1\"\n## \n## $tvSeries[[2]]\n## [1] \"Season 2\"\n## \n## $tvSeries[[3]]\n## [1] \"Season 3\"\n## \n## $tvSeries[[4]]\n## [1] \"Season 4\"\n## \n## $tvSeries[[5]]\n## [1] \"Season 5\"\n## \n## $tvSeries[[6]]\n## [1] \"Season 6\"\n## \n## \n## $playedBy\n## $playedBy[[1]]\n## [1] \"Lena Headey\"\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 6 × 3\n##   id    tvSeries playedBy   \n##   <chr> <chr>    <chr>      \n## 1 238   Season 1 Lena Headey\n## 2 238   Season 2 Lena Headey\n## 3 238   Season 3 Lena Headey\n## 4 238   Season 4 Lena Headey\n## 5 238   Season 5 Lena Headey\n## 6 238   Season 6 Lena Headey\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Drogo\"}\ni <- 1346\ndata[[i]][c(\"url\", \"name\", \"gender\", \"culture\", \"born\", \"died\", \"titles\", \"aliases\", \"allegiances\")] |> print()\n## $url\n## [1] \"https://anapioficeandfire.com/api/characters/1346\"\n## \n## $name\n## [1] \"Drogo\"\n## \n## $gender\n## [1] \"Male\"\n## \n## $culture\n## [1] \"Dothraki\"\n## \n## $born\n## [1] \"In or around 267 AC\"\n## \n## $died\n## [1] \"In 298 AC, at Dothraki sea\"\n## \n## $titles\n## $titles[[1]]\n## [1] \"Khal\"\n## \n## \n## $aliases\n## $aliases[[1]]\n## [1] \"Great Rider\"\n## \n## $aliases[[2]]\n## [1] \"Great Khal\"\n## \n## \n## $allegiances\n## list()\nfilter(personalInfo, id==as.character(i)) |> print()\n## # A tibble: 1 × 10\n##   id    url          name  gender culture born  died  titles aliases allegiances\n##   <chr> <chr>        <chr> <chr>  <chr>   <chr> <chr> <list> <list>  <list>     \n## 1 1346  https://ana… Drogo Male   Dothra… In o… In 2… <chr>  <chr>   <NULL>\nfilter(personalInfo, id==as.character(i))$titles |> print()\n## [[1]]\n## [1] \"Khal\"\nfilter(personalInfo, id==as.character(i))$aliases |> print()\n## [[1]]\n## [1] \"Great Rider\" \"Great Khal\"\nfilter(personalInfo, id==as.character(i))$allegiances |> print()\n## [[1]]\n## NULL\ndata[[i]][c(\"books\", \"povBooks\")] |> print()\n## $books\n## $books[[1]]\n## [1] \"https://anapioficeandfire.com/api/books/1\"\n## \n## $books[[2]]\n## [1] \"https://anapioficeandfire.com/api/books/2\"\n## \n## $books[[3]]\n## [1] \"https://anapioficeandfire.com/api/books/3\"\n## \n## $books[[4]]\n## [1] \"https://anapioficeandfire.com/api/books/8\"\n## \n## \n## $povBooks\n## list()\nfilter(book, id == as.character(i)) |> print()\n## # A tibble: 4 × 3\n##   id    book                                      pov  \n##   <chr> <chr>                                     <chr>\n## 1 1346  https://anapioficeandfire.com/api/books/1 FALSE\n## 2 1346  https://anapioficeandfire.com/api/books/2 FALSE\n## 3 1346  https://anapioficeandfire.com/api/books/3 FALSE\n## 4 1346  https://anapioficeandfire.com/api/books/8 FALSE\ndata[[i]][c(\"mother\", \"father\", \"spouse\")] |> print()\n## $mother\n## [1] \"\"\n## \n## $father\n## [1] \"\"\n## \n## $spouse\n## [1] \"https://anapioficeandfire.com/api/characters/1303\"\nfilter(relationships, id == as.character(i)) |> print()\n## # A tibble: 1 × 3\n##   id    relationship_type relative_ID                                      \n##   <chr> <chr>             <chr>                                            \n## 1 1346  spouse            https://anapioficeandfire.com/api/characters/1303\ndata[[i]][c(\"tvSeries\", \"playedBy\")] |> print()\n## $tvSeries\n## $tvSeries[[1]]\n## [1] \"Season 1\"\n## \n## $tvSeries[[2]]\n## [1] \"Season 2\"\n## \n## \n## $playedBy\n## $playedBy[[1]]\n## [1] \"Jason Momoa\"\nfilter(tv_show, id == as.character(i)) |> print()\n## # A tibble: 2 × 3\n##   id    tvSeries playedBy   \n##   <chr> <chr>    <chr>      \n## 1 1346  Season 1 Jason Momoa\n## 2 1346  Season 2 Jason Momoa\n```\n:::\n\n\n\n\n:::\n\n\n::::\n\n@bryanManipulateXMLPurrr2024 and @bryanAnalyzeGithubStuff2025 contain additional worked examples in R, and @westTabulateJSONData2022 contains an example in python for how to convert JSON/XML/API values to tabular data. \n\n::: learnmore\n\n- [R for Data Science chapter on Hierarchical Data](https://r4ds.hadley.nz/rectangling.html)\n\n:::\n\n## Conclusions\n\nConverting from record-based data models to relational data models is complex, in part because it depends on the structure of the data and the keys which link different tables/forms/nodes. \nIn general, your best bet is to carefully look at the data, investigate any values you don't understand (or values that you think may be keys to another table, but you aren't sure), and then design a correpsonding relational table structure that makes sense for the data you have in front of you.\n\nWhile you're considering how to do this, it is also important to sanity check for possible many-to-many relationships that may arise and ruin your data analysis.\nIt's common to make assumptions about the absence of many-to-many relationships (for instance, I did that at least twice in the demo above), but they're usually hidden within the code and not obvious.\nWhen the data are updated, if those assumptions don't still hold, you could end up with an analysis that doesn't make any sense, so be careful and explicit about your assumptions with the data.\n\n## References {-}\n\n\n<!-- https://github.com/jennybc/manipulate-xml-with-purrr-dplyr-tidyr -->\n<!-- https://github.com/jennybc/analyze-github-stuff-with-r -->\n",
    "supporting": [
      "04-xml-json-list-processing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}