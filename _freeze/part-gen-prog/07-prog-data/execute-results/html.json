{
  "hash": "a4fead197f2c0ffb06a9e6ad2f9d268a",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Programming With Data {#sec-programming-data}\n\nAt this point, you've learned how to write functions. You know the basics of how to create new variables, how data frames and lists work, and how to use markdown.\n\nAnd yet... these are skills that take some practice when applied to new data. We're going to take a break from the fire-hose of syntax you've learned and focus on applying what you've learned to problems related to data. The goal is to **reinforce the skills you've already learned** and help you find your feet a bit as you work through data analysis. \n\nI'll provide sample code for tasks like basic plots and tables that we haven't covered yet - you should feel free to modify and tinker with these chunks as you go along.\nThis chapter will also provide a preview of some of the packages we're going to work with in the next few sections (because I'm going to show you some code for e.g. summarizing a dataset and plot a few things, even without having covered that material). \n\n\n![It's 100% expected that you would be oscillating between just maybe understanding something and feeling completely lost again during this chapter. Hopefully, that feeling will get better over the next few weeks... but for now, just stick with it.](https://cdn.myportfolio.com/45214904-6a61-4e23-98d6-b140f8654a40/d65eb83f-66e4-4760-8c1f-29d336d1d6df_rw_3840.png?h=ece3b7c448f38a10cd71866e2cbb2b4d){fig-alt='An illustrated cartoon graph with \"How much I think I know\" on the y-axis, with axis labels at \"I know nothing\" and \"I know lots\", versus time on the x-axis. The line varies widely between the two. Above the line are emoji-like faces, showing uncertainty and hope early on. A box is provided spanning an initial first peak, valley, and ascent to the highest peak, with a label that says \"you should be about here\".'}\n\nAs you've probably guessed by now, this  section will primarily be focused on examples.\n\n## Objectives {-}\n\n- Write functions to create simple plots and data summaries\n\n- Apply syntax knowledge to reference variables and observations in common data structures\n\n- Create new variables and columns or reformat existing columns in provided data structures\n\n\n\n\n\n\n\n\n\n## Artwork Dimensions\n\nThe Tate Art Museum assembled a collection of 70,000 artworks (last updated in 2014). They cataloged information including accession number, artwork dimensions, units, title, date, medium, inscription, and even URLs for images of the art. \n\n### Reading in the Data\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nartwork <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-12/artwork.csv')\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nartwork = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-12/artwork.csv')\n```\n:::\n\n\n\n\n:::\n\n### Basic Summaries\n\nWhen you first access a new dataset, it's fun to explore it a bit. I've shown a summary of the variables (character variables summarized with completion rates and # unique values, numeric variables summarized with quantiles and mean/sd) generated using the R `skimr` and Python `skimpy` packages (which we'll talk about in the next chapter). \n\n::: panel-tabset\n\n#### R {-}\n\nYou may need to run `install.packages(\"skimr\")` in the R terminal if you have not used the package before.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(skimr)\nskim(artwork)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |artwork |\n|Number of rows           |69201   |\n|Number of columns        |20      |\n|_______________________  |        |\n|Column type frequency:   |        |\n|character                |12      |\n|logical                  |1       |\n|numeric                  |7       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: character**\n\n|skim_variable    | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:----------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|accession_number |         0|          1.00|   6|   7|     0|    69201|          0|\n|artist           |         0|          1.00|   4| 120|     0|     3336|          0|\n|artistRole       |         0|          1.00|   5|  24|     0|       19|          0|\n|title            |         0|          1.00|   1| 320|     0|    43529|          0|\n|dateText         |         0|          1.00|   4|  75|     0|     2736|          0|\n|medium           |      6384|          0.91|   3| 120|     0|     3401|          0|\n|creditLine       |         3|          1.00|  14| 820|     0|     3209|          0|\n|dimensions       |      2433|          0.96|   4| 248|     0|    25575|          0|\n|units            |      3341|          0.95|   2|   2|     0|        1|          0|\n|inscription      |     62895|          0.09|  14|  14|     0|        1|          0|\n|thumbnailUrl     |     10786|          0.84|  55|  57|     0|    58415|          0|\n|url              |         0|          1.00|  48| 134|     0|    69201|          0|\n\n\n**Variable type: logical**\n\n|skim_variable      | n_missing| complete_rate| mean|count |\n|:------------------|---------:|-------------:|----:|:-----|\n|thumbnailCopyright |     69201|             0|  NaN|:     |\n\n\n**Variable type: numeric**\n\n|skim_variable   | n_missing| complete_rate|     mean|       sd|   p0|      p25|   p50|   p75|   p100|hist  |\n|:---------------|---------:|-------------:|--------:|--------:|----:|--------:|-----:|-----:|------:|:-----|\n|id              |         0|          1.00| 39148.03| 25980.47|    3| 19096.00| 37339| 54712| 129068|▇▇▅▁▁ |\n|artistId        |         0|          1.00|  1201.06|  2019.42|    0|   558.00|   558|  1137|  19232|▇▁▁▁▁ |\n|year            |      5397|          0.92|  1867.23|    72.01| 1545|  1817.00|  1831|  1953|   2012|▁▁▇▆▆ |\n|acquisitionYear |        45|          1.00|  1910.65|    64.20| 1823|  1856.00|  1856|  1982|   2013|▇▁▁▁▅ |\n|width           |      3367|          0.95|   323.47|   408.81|    3|   118.00|   175|   345|  11960|▇▁▁▁▁ |\n|height          |      3342|          0.95|   346.44|   538.04|    6|   117.00|   190|   359|  37500|▇▁▁▁▁ |\n|depth           |     66687|          0.04|   479.20|  1051.14|    1|    48.25|   190|   450|  18290|▇▁▁▁▁ |\n\n\n:::\n:::\n\n\n\n\n#### Python (pandas) {-}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Base pandas\nartwork.describe()\n##                   id      artistId  ...         depth  thumbnailCopyright\n## count   69201.000000  69201.000000  ...   2514.000000                 0.0\n## mean    39148.026213   1201.063251  ...    479.197772                 NaN\n## std     25980.468687   2019.422535  ...   1051.141734                 NaN\n## min         3.000000      0.000000  ...      1.000000                 NaN\n## 25%     19096.000000    558.000000  ...     48.250000                 NaN\n## 50%     37339.000000    558.000000  ...    190.000000                 NaN\n## 75%     54712.000000   1137.000000  ...    450.000000                 NaN\n## max    129068.000000  19232.000000  ...  18290.000000                 NaN\n## \n## [8 rows x 8 columns]\n```\n:::\n\n\n\n\n#### Python (skimpy) {-}\n\nYou may need to run `pip install skimpy` in the terminal if you have not used the package before.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Skimpy package - like skimr\nfrom skimpy import skim\nskim(artwork)\n## ╭─────────────────────────────── skimpy summary ───────────────────────────────╮\n## │          Data Summary                Data Types                              │\n## │ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                       │\n## │ ┃ Dataframe         ┃ Values ┃ ┃ Column Type ┃ Count ┃                       │\n## │ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                       │\n## │ │ Number of rows    │ 69201  │ │ string      │ 12    │                       │\n## │ │ Number of columns │ 20     │ │ float64     │ 6     │                       │\n## │ └───────────────────┴────────┘ │ int64       │ 2     │                       │\n## │                                └─────────────┴───────┘                       │\n## │                                  All null                                    │\n## │ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓  │\n## │ ┃ column                                     ┃ NA            ┃ NA %       ┃  │\n## │ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩  │\n## │ │ thumbnailCopyright                         │         69201 │        100 │  │\n## │ └────────────────────────────────────────────┴───────────────┴────────────┘  │\n## │                                   number                                     │\n## │ ┏━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┳━━━━━━┳━━━━━┓  │\n## │ ┃ colu ┃      ┃      ┃      ┃      ┃      ┃     ┃      ┃     ┃      ┃ his ┃  │\n## │ ┃ mn   ┃ NA   ┃ NA % ┃ mean ┃ sd   ┃ p0   ┃ p25 ┃ p50  ┃ p75 ┃ p100 ┃ t   ┃  │\n## │ ┡━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━╇━━━━━━╇━━━━━┩  │\n## │ │ id   │    0 │    0 │ 3915 │ 2598 │    3 │ 191 │ 3734 │ 547 │ 1291 │ ▇██ │  │\n## │ │      │      │      │    0 │    0 │      │  00 │    0 │  10 │   00 │ ▁▁▁ │  │\n## │ │ arti │    0 │    0 │ 1201 │ 2019 │    0 │ 558 │  558 │ 113 │ 1923 │  █  │  │\n## │ │ stId │      │      │      │      │      │     │      │   7 │    0 │     │  │\n## │ │ year │ 5397 │ 7.79 │ 1867 │ 72.0 │ 1545 │ 181 │ 1831 │ 195 │ 2012 │     │  │\n## │ │      │      │ 9020 │      │    1 │      │   7 │      │   3 │      │ █▁▃ │  │\n## │ │      │      │ 2453 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │ 7217 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │    6 │      │      │      │     │      │     │      │     │  │\n## │ │ acqu │   45 │ 0.06 │ 1911 │ 64.2 │ 1823 │ 185 │ 1856 │ 198 │ 2013 │  █  │  │\n## │ │ isit │      │ 5027 │      │      │      │   6 │      │   2 │      │ ▁▂▄ │  │\n## │ │ ionY │      │ 9620 │      │      │      │     │      │     │      │     │  │\n## │ │ ear  │      │ 2367 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │  017 │      │      │      │     │      │     │      │     │  │\n## │ │ widt │ 3367 │ 4.86 │ 323. │ 408. │    3 │ 118 │  175 │ 345 │ 1196 │  █  │  │\n## │ │ h    │      │ 5536 │    5 │    8 │      │     │      │     │    0 │     │  │\n## │ │      │      │ 6251 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │ 9327 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │    7 │      │      │      │     │      │     │      │     │  │\n## │ │ heig │ 3342 │ 4.82 │ 346. │  538 │    6 │ 117 │  190 │ 359 │ 3750 │  █  │  │\n## │ │ ht   │      │ 9409 │    4 │      │      │     │      │     │    0 │     │  │\n## │ │      │      │ 9796 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │ 2457 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │    2 │      │      │      │     │      │     │      │     │  │\n## │ │ dept │ 6668 │ 96.3 │ 479. │ 1051 │    1 │ 48. │  190 │ 450 │ 1829 │  █  │  │\n## │ │ h    │    7 │ 6710 │    2 │      │      │  25 │      │     │    0 │     │  │\n## │ │      │      │ 4521 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │ 6109 │      │      │      │     │      │     │      │     │  │\n## │ │      │      │    5 │      │      │      │     │      │     │      │     │  │\n## │ └──────┴──────┴──────┴──────┴──────┴──────┴─────┴──────┴─────┴──────┴─────┘  │\n## │                                   string                                     │\n## │ ┏━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━┓  │\n## │ ┃      ┃      ┃       ┃      ┃       ┃      ┃       ┃ char ┃       ┃ tota ┃  │\n## │ ┃      ┃      ┃       ┃      ┃       ┃      ┃       ┃ s    ┃ words ┃ l    ┃  │\n## │ ┃ colu ┃      ┃       ┃ shor ┃ longe ┃      ┃       ┃ per  ┃ per   ┃ word ┃  │\n## │ ┃ mn   ┃ NA   ┃ NA %  ┃ test ┃ st    ┃ min  ┃ max   ┃ row  ┃ row   ┃ s    ┃  │\n## │ ┡━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━┩  │\n## │ │ acce │    0 │     0 │ A000 │ AR000 │ A000 │ T1386 │ 6.02 │     1 │ 6920 │  │\n## │ │ ssio │      │       │ 01   │ 01    │ 01   │ 9     │      │       │    1 │  │\n## │ │ n_nu │      │       │      │       │      │       │      │       │      │  │\n## │ │ mber │      │       │      │       │      │       │      │       │      │  │\n## │ │ arti │    0 │     0 │ Erté │ Art & │ ?Bri │ Štyrs │ 23.9 │   3.3 │ 2265 │  │\n## │ │ st   │      │       │      │ Langu │ tish │ ký,   │      │       │   31 │  │\n## │ │      │      │       │      │ age   │      │ Jindr │      │       │      │  │\n## │ │      │      │       │      │ (Terr │ Scho │ ich   │      │       │      │  │\n## │ │      │      │       │      │ y     │ ol   │       │      │       │      │  │\n## │ │      │      │       │      │ Atkin │      │       │      │       │      │  │\n## │ │      │      │       │      │ son,  │      │       │      │       │      │  │\n## │ │      │      │       │      │ born  │      │       │      │       │      │  │\n## │ │      │      │       │      │ 1939; │      │       │      │       │      │  │\n## │ │      │      │       │      │ David │      │       │      │       │      │  │\n## │ │      │      │       │      │ Bainb │      │       │      │       │      │  │\n## │ │      │      │       │      │ ridge │      │       │      │       │      │  │\n## │ │      │      │       │      │ ,     │      │       │      │       │      │  │\n## │ │      │      │       │      │ born  │      │       │      │       │      │  │\n## │ │      │      │       │      │ 1941; │      │       │      │       │      │  │\n## │ │      │      │       │      │ Micha │      │       │      │       │      │  │\n## │ │      │      │       │      │ el    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Baldw │      │       │      │       │      │  │\n## │ │      │      │       │      │ in,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ born  │      │       │      │       │      │  │\n## │ │      │      │       │      │ 1945; │      │       │      │       │      │  │\n## │ │      │      │       │      │ Harol │      │       │      │       │      │  │\n## │ │      │      │       │      │ d     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Hurre │      │       │      │       │      │  │\n## │ │      │      │       │      │ ll,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ born  │      │       │      │       │      │  │\n## │ │ arti │    0 │     0 │ afte │ doubt │ afte │ style │    6 │     1 │ 6950 │  │\n## │ │ stRo │      │       │ r    │ fully │ r    │ of    │      │       │    4 │  │\n## │ │ le   │      │       │      │       │      │       │      │       │      │  │\n## │ │      │      │       │      │ attri │      │       │      │       │      │  │\n## │ │      │      │       │      │ buted │      │       │      │       │      │  │\n## │ │      │      │       │      │  to   │      │       │      │       │      │  │\n## │ │ titl │    0 │     0 │ I    │ Dans  │ !    │ “What │ 29.9 │     5 │ 3460 │  │\n## │ │ e    │      │       │      │ plusi │ 1971 │ is to │      │       │   84 │  │\n## │ │      │      │       │      │ eurs  │      │ be    │      │       │      │  │\n## │ │      │      │       │      │ de    │      │ done? │      │       │      │  │\n## │ │      │      │       │      │ ces   │      │ ”     │      │       │      │  │\n## │ │      │      │       │      │ forêt │      │ 1984. │      │       │      │  │\n## │ │      │      │       │      │ s et  │      │ Alter │      │       │      │  │\n## │ │      │      │       │      │ de    │      │ nativ │      │       │      │  │\n## │ │      │      │       │      │ ces   │      │ e     │      │       │      │  │\n## │ │      │      │       │      │ bois, │      │ Techn │      │       │      │  │\n## │ │      │      │       │      │ il    │      │ ology │      │       │      │  │\n## │ │      │      │       │      │ n’y   │      │       │      │       │      │  │\n## │ │      │      │       │      │ avait │      │ Versu │      │       │      │  │\n## │ │      │      │       │      │ pas   │      │ s     │      │       │      │  │\n## │ │      │      │       │      │ seule │      │ Nucle │      │       │      │  │\n## │ │      │      │       │      │ ment  │      │ ar    │      │       │      │  │\n## │ │      │      │       │      │ des   │      │ Power │      │       │      │  │\n## │ │      │      │       │      │ villa │      │       │      │       │      │  │\n## │ │      │      │       │      │ ges   │      │       │      │       │      │  │\n## │ │      │      │       │      │ soute │      │       │      │       │      │  │\n## │ │      │      │       │      │ rrain │      │       │      │       │      │  │\n## │ │      │      │       │      │ s     │      │       │      │       │      │  │\n## │ │      │      │       │      │ group │      │       │      │       │      │  │\n## │ │      │      │       │      │ és    │      │       │      │       │      │  │\n## │ │      │      │       │      │ autou │      │       │      │       │      │  │\n## │ │      │      │       │      │ rs du │      │       │      │       │      │  │\n## │ │      │      │       │      │ terri │      │       │      │       │      │  │\n## │ │      │      │       │      │ er du │      │       │      │       │      │  │\n## │ │      │      │       │      │ chef  │      │       │      │       │      │  │\n## │ │      │      │       │      │ mais  │      │       │      │       │      │  │\n## │ │      │      │       │      │ il y  │      │       │      │       │      │  │\n## │ │      │      │       │      │ avait │      │       │      │       │      │  │\n## │ │      │      │       │      │ encor │      │       │      │       │      │  │\n## │ │      │      │       │      │ e de  │      │       │      │       │      │  │\n## │ │      │      │       │      │ vérit │      │       │      │       │      │  │\n## │ │      │      │       │      │ ables │      │       │      │       │      │  │\n## │ │      │      │       │      │       │      │       │      │       │      │  │\n## │ │      │      │       │      │ hamea │      │       │      │       │      │  │\n## │ │      │      │       │      │ ux de │      │       │      │       │      │  │\n## │ │      │      │       │      │ hutte │      │       │      │       │      │  │\n## │ │      │      │       │      │ s     │      │       │      │       │      │  │\n## │ │      │      │       │      │ basse │      │       │      │       │      │  │\n## │ │      │      │       │      │ s     │      │       │      │       │      │  │\n## │ │      │      │       │      │ caché │      │       │      │       │      │  │\n## │ │      │      │       │      │ s     │      │       │      │       │      │  │\n## │ │      │      │       │      │ sous  │      │       │      │       │      │  │\n## │ │      │      │       │      │ les   │      │       │      │       │      │  │\n## │ │      │      │       │      │ arbre │      │       │      │       │      │  │\n## │ │      │      │       │      │ s, et │      │       │      │       │      │  │\n## │ │      │      │       │      │ si    │      │       │      │       │      │  │\n## │ │      │      │       │      │ nombr │      │       │      │       │      │  │\n## │ │      │      │       │      │ eaux  │      │       │      │       │      │  │\n## │ │      │      │       │      │ que   │      │       │      │       │      │  │\n## │ │      │      │       │      │ parfo │      │       │      │       │      │  │\n## │ │      │      │       │      │ is la │      │       │      │       │      │  │\n## │ │      │      │       │      │ forêt │      │       │      │       │      │  │\n## │ │      │      │       │      │ en    │      │       │      │       │      │  │\n## │ │      │      │       │      │ était │      │       │      │       │      │  │\n## │ │      │      │       │      │ rempl │      │       │      │       │      │  │\n## │ │      │      │       │      │ ie.   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Souve │      │       │      │       │      │  │\n## │ │      │      │       │      │ nt    │      │       │      │       │      │  │\n## │ │      │      │       │      │ les   │      │       │      │       │      │  │\n## │ │      │      │       │      │ fumée │      │       │      │       │      │  │\n## │ │      │      │       │      │ s les │      │       │      │       │      │  │\n## │ │      │      │       │      │ trahi │      │       │      │       │      │  │\n## │ │      │      │       │      │ ssaie │      │       │      │       │      │  │\n## │ │      │      │       │      │ nt.   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Deux  │      │       │      │       │      │  │\n## │ │      │      │       │      │ de... │      │       │      │       │      │  │\n## │ │ date │    0 │     0 │ 1870 │ 1915– │ 1545 │ publi │ 6.27 │   1.2 │ 8528 │  │\n## │ │ Text │      │       │      │ 23,   │      │ shed  │      │       │    8 │  │\n## │ │      │      │       │      │ recon │      │ c.186 │      │       │      │  │\n## │ │      │      │       │      │ struc │      │ 0     │      │       │      │  │\n## │ │      │      │       │      │ tion  │      │       │      │       │      │  │\n## │ │      │      │       │      │ by    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Richa │      │       │      │       │      │  │\n## │ │      │      │       │      │ rd    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Hamil │      │       │      │       │      │  │\n## │ │      │      │       │      │ ton   │      │       │      │       │      │  │\n## │ │      │      │       │      │ 1965– │      │       │      │       │      │  │\n## │ │      │      │       │      │ 6,    │      │       │      │       │      │  │\n## │ │      │      │       │      │ lower │      │       │      │       │      │  │\n## │ │      │      │       │      │ panel │      │       │      │       │      │  │\n## │ │      │      │       │      │ remad │      │       │      │       │      │  │\n## │ │      │      │       │      │ e     │      │       │      │       │      │  │\n## │ │      │      │       │      │ 1985  │      │       │      │       │      │  │\n## │ │ medi │ 6384 │ 9.225 │ Wax  │ Acryl │ 10   │ ink   │ 21.7 │   3.4 │ 2351 │  │\n## │ │ um   │      │ 30021 │      │ ic    │ phot │ and   │      │       │   15 │  │\n## │ │      │      │ 24246 │      │ paint │ o-et │ gouac │      │       │      │  │\n## │ │      │      │    76 │      │ , oil │ chin │ he on │      │       │      │  │\n## │ │      │      │       │      │ paint │ gs   │ paper │      │       │      │  │\n## │ │      │      │       │      │ ,     │ on   │       │      │       │      │  │\n## │ │      │      │       │      │ shell │ pape │       │      │       │      │  │\n## │ │      │      │       │      │ ac,   │ r    │       │      │       │      │  │\n## │ │      │      │       │      │ earth │      │       │      │       │      │  │\n## │ │      │      │       │      │ ,     │      │       │      │       │      │  │\n## │ │      │      │       │      │ sand, │      │       │      │       │      │  │\n## │ │      │      │       │      │ wood, │      │       │      │       │      │  │\n## │ │      │      │       │      │ paper │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ glass │      │       │      │       │      │  │\n## │ │      │      │       │      │ on 2  │      │       │      │       │      │  │\n## │ │      │      │       │      │ canva │      │       │      │       │      │  │\n## │ │      │      │       │      │ ses,  │      │       │      │       │      │  │\n## │ │      │      │       │      │ lead, │      │       │      │       │      │  │\n## │ │      │      │       │      │ iron, │      │       │      │       │      │  │\n## │ │      │      │       │      │ books │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ other │      │       │      │       │      │  │\n## │ │      │      │       │      │ mater │      │       │      │       │      │  │\n## │ │      │      │       │      │ ia    │      │       │      │       │      │  │\n## │ │ cred │    3 │ 0.004 │ Purc │ Purch │ ARTI │ [unco │ 57.1 │    10 │ 6984 │  │\n## │ │ itLi │      │ 33519 │ hase │ ased  │ ST   │ vered │      │       │   69 │  │\n## │ │ ne   │      │ 74682 │ d    │ joint │ ROOM │       │      │       │      │  │\n## │ │      │      │ 44679 │ 1912 │ ly by │ S    │ durin │      │       │      │  │\n## │ │      │      │       │      │ Tate, │ Acqu │ g     │      │       │      │  │\n## │ │      │      │       │      │ with  │ ired │ remou │      │       │      │  │\n## │ │      │      │       │      │ assis │      │ nting │      │       │      │  │\n## │ │      │      │       │      │ tance │ join │  of   │      │       │      │  │\n## │ │      │      │       │      │  from │ tly  │ T0304 │      │       │      │  │\n## │ │      │      │       │      │ the   │ with │ 8]    │      │       │      │  │\n## │ │      │      │       │      │ Ameri │ the  │ 1980  │      │       │      │  │\n## │ │      │      │       │      │ can   │ Nati │       │      │       │      │  │\n## │ │      │      │       │      │ Patro │ onal │       │      │       │      │  │\n## │ │      │      │       │      │ ns    │      │       │      │       │      │  │\n## │ │      │      │       │      │ for   │ Gall │       │      │       │      │  │\n## │ │      │      │       │      │ Tate  │ erie │       │      │       │      │  │\n## │ │      │      │       │      │ and   │ s of │       │      │       │      │  │\n## │ │      │      │       │      │ the   │ Scot │       │      │       │      │  │\n## │ │      │      │       │      │ Latin │ land │       │      │       │      │  │\n## │ │      │      │       │      │ Ameri │      │       │      │       │      │  │\n## │ │      │      │       │      │ can   │ thro │       │      │       │      │  │\n## │ │      │      │       │      │ Acqui │ ugh  │       │      │       │      │  │\n## │ │      │      │       │      │ sitio │ The  │       │      │       │      │  │\n## │ │      │      │       │      │ ns    │ d'Of │       │      │       │      │  │\n## │ │      │      │       │      │ Commi │ fay  │       │      │       │      │  │\n## │ │      │      │       │      │ ttee; │ Dona │       │      │       │      │  │\n## │ │      │      │       │      │  and  │ tion │       │      │       │      │  │\n## │ │      │      │       │      │ Albri │      │       │      │       │      │  │\n## │ │      │      │       │      │ ght-K │ with │       │      │       │      │  │\n## │ │      │      │       │      │ nox   │ assi │       │      │       │      │  │\n## │ │      │      │       │      │ Art   │ stan │       │      │       │      │  │\n## │ │      │      │       │      │ Galle │ ce   │       │      │       │      │  │\n## │ │      │      │       │      │ ry,   │ from │       │      │       │      │  │\n## │ │      │      │       │      │ Buffa │ the  │       │      │       │      │  │\n## │ │      │      │       │      │ lo,   │ Nati │       │      │       │      │  │\n## │ │      │      │       │      │ with  │ onal │       │      │       │      │  │\n## │ │      │      │       │      │ funds │      │       │      │       │      │  │\n## │ │      │      │       │      │ from  │ Heri │       │      │       │      │  │\n## │ │      │      │       │      │ Charl │ tage │       │      │       │      │  │\n## │ │      │      │       │      │ es    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Clift │ Memo │       │      │       │      │  │\n## │ │      │      │       │      │ on,   │ rial │       │      │       │      │  │\n## │ │      │      │       │      │ James │      │       │      │       │      │  │\n## │ │      │      │       │      │ S.    │ Fund │       │      │       │      │  │\n## │ │      │      │       │      │ Ely,  │ and  │       │      │       │      │  │\n## │ │      │      │       │      │ Charl │ the  │       │      │       │      │  │\n## │ │      │      │       │      │ es W. │ Art  │       │      │       │      │  │\n## │ │      │      │       │      │ Goody │ Fund │       │      │       │      │  │\n## │ │      │      │       │      │ ear,  │ 2008 │       │      │       │      │  │\n## │ │      │      │       │      │ Sarah │      │       │      │       │      │  │\n## │ │      │      │       │      │ Norto │      │       │      │       │      │  │\n## │ │      │      │       │      │ n     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Goody │      │       │      │       │      │  │\n## │ │      │      │       │      │ ear,  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Dr.   │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mrs.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Clayt │      │       │      │       │      │  │\n## │ │      │      │       │      │ on    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Pieme │      │       │      │       │      │  │\n## │ │      │      │       │      │ r,    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Georg │      │       │      │       │      │  │\n## │ │      │      │       │      │ e     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Bello │      │       │      │       │      │  │\n## │ │      │      │       │      │ ws    │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Irene │      │       │      │       │      │  │\n## │ │      │      │       │      │ Pirso │      │       │      │       │      │  │\n## │ │      │      │       │      │ n     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Macdo │      │       │      │       │      │  │\n## │ │      │      │       │      │ nald  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Funds │      │       │      │       │      │  │\n## │ │      │      │       │      │ ; by  │      │       │      │       │      │  │\n## │ │      │      │       │      │ excha │      │       │      │       │      │  │\n## │ │      │      │       │      │ nge:  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Seymo │      │       │      │       │      │  │\n## │ │      │      │       │      │ ur H. │      │       │      │       │      │  │\n## │ │      │      │       │      │ Knox, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Jr.   │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ the   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Steve │      │       │      │       │      │  │\n## │ │      │      │       │      │ nson  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Famil │      │       │      │       │      │  │\n## │ │      │      │       │      │ y,    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fello │      │       │      │       │      │  │\n## │ │      │      │       │      │ ws    │      │       │      │       │      │  │\n## │ │      │      │       │      │ for   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Life  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mrs.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Georg │      │       │      │       │      │  │\n## │ │      │      │       │      │ e A.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Forma │      │       │      │       │      │  │\n## │ │      │      │       │      │ n,    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mrs.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Georg │      │       │      │       │      │  │\n## │ │      │      │       │      │ ia    │      │       │      │       │      │  │\n## │ │      │      │       │      │ M.G.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Forma │      │       │      │       │      │  │\n## │ │      │      │       │      │ n,    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Elisa │      │       │      │       │      │  │\n## │ │      │      │       │      │ beth  │      │       │      │       │      │  │\n## │ │      │      │       │      │ H.    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gates │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Charl │      │       │      │       │      │  │\n## │ │      │      │       │      │ es W. │      │       │      │       │      │  │\n## │ │      │      │       │      │ Goody │      │       │      │       │      │  │\n## │ │      │      │       │      │ ear   │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mrs.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Georg │      │       │      │       │      │  │\n## │ │      │      │       │      │ ia    │      │       │      │       │      │  │\n## │ │      │      │       │      │ M.G.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Forma │      │       │      │       │      │  │\n## │ │      │      │       │      │ n     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Edmun │      │       │      │       │      │  │\n## │ │      │      │       │      │ d     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Hayes │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Sherm │      │       │      │       │      │  │\n## │ │      │      │       │      │ an S. │      │       │      │       │      │  │\n## │ │      │      │       │      │ Jewet │      │       │      │       │      │  │\n## │ │      │      │       │      │ t     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Georg │      │       │      │       │      │  │\n## │ │      │      │       │      │ e B.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Jenny │      │       │      │       │      │  │\n## │ │      │      │       │      │ R.    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mathe │      │       │      │       │      │  │\n## │ │      │      │       │      │ ws    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Beque │      │       │      │       │      │  │\n## │ │      │      │       │      │ st of │      │       │      │       │      │  │\n## │ │      │      │       │      │ Arthu │      │       │      │       │      │  │\n## │ │      │      │       │      │ r B.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Micha │      │       │      │       │      │  │\n## │ │      │      │       │      │ el,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Mrs.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Seymo │      │       │      │       │      │  │\n## │ │      │      │       │      │ ur H. │      │       │      │       │      │  │\n## │ │      │      │       │      │ Knox, │      │       │      │       │      │  │\n## │ │      │      │       │      │ Sr.,  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Baron │      │       │      │       │      │  │\n## │ │      │      │       │      │ ess   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Alpho │      │       │      │       │      │  │\n## │ │      │      │       │      │ nse   │      │       │      │       │      │  │\n## │ │      │      │       │      │ de    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Roths │      │       │      │       │      │  │\n## │ │      │      │       │      │ child │      │       │      │       │      │  │\n## │ │      │      │       │      │ ,     │      │       │      │       │      │  │\n## │ │      │      │       │      │ Phili │      │       │      │       │      │  │\n## │ │      │      │       │      │ p J.  │      │       │      │       │      │  │\n## │ │      │      │       │      │ Wicks │      │       │      │       │      │  │\n## │ │      │      │       │      │ er    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Fund  │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Gift  │      │       │      │       │      │  │\n## │ │      │      │       │      │ of    │      │       │      │       │      │  │\n## │ │      │      │       │      │ the   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Winfi │      │       │      │       │      │  │\n## │ │      │      │       │      │ eld   │      │       │      │       │      │  │\n## │ │      │      │       │      │ Found │      │       │      │       │      │  │\n## │ │      │      │       │      │ ation │      │       │      │       │      │  │\n## │ │      │      │       │      │ ,     │      │       │      │       │      │  │\n## │ │      │      │       │      │ 2010  │      │       │      │       │      │  │\n## │ │ dime │ 2433 │ 3.515 │ 7min │ Six   │ 10.5 │ varia │ 22.3 │   5.3 │ 3639 │  │\n## │ │ nsio │      │ 84514 │      │ eleme │ ft x │ ble   │      │       │   37 │  │\n## │ │ ns   │      │ 67464 │      │ nts:  │ 20 x │       │      │       │      │  │\n## │ │      │      │   342 │      │ squar │ 10   │       │      │       │      │  │\n## │ │      │      │       │      │ e     │ -ove │       │      │       │      │  │\n## │ │      │      │       │      │ tube: │ rall │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │ disp │       │      │       │      │  │\n## │ │      │      │       │      │ 920   │ lay  │       │      │       │      │  │\n## │ │      │      │       │      │ mm;   │ dime │       │      │       │      │  │\n## │ │      │      │       │      │ recta │ nsio │       │      │       │      │  │\n## │ │      │      │       │      │ ngula │ ns   │       │      │       │      │  │\n## │ │      │      │       │      │ r     │ -var │       │      │       │      │  │\n## │ │      │      │       │      │ tube: │ iabl │       │      │       │      │  │\n## │ │      │      │       │      │ 230 x │ e    │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 920   │      │       │      │       │      │  │\n## │ │      │      │       │      │ mm;   │      │       │      │       │      │  │\n## │ │      │      │       │      │ cubic │      │       │      │       │      │  │\n## │ │      │      │       │      │ tube, │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460   │      │       │      │       │      │  │\n## │ │      │      │       │      │ mm;   │      │       │      │       │      │  │\n## │ │      │      │       │      │ angul │      │       │      │       │      │  │\n## │ │      │      │       │      │ ar    │      │       │      │       │      │  │\n## │ │      │      │       │      │ eleme │      │       │      │       │      │  │\n## │ │      │      │       │      │ nt,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ openi │      │       │      │       │      │  │\n## │ │      │      │       │      │ ng:   │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460   │      │       │      │       │      │  │\n## │ │      │      │       │      │ mm;   │      │       │      │       │      │  │\n## │ │      │      │       │      │ trans │      │       │      │       │      │  │\n## │ │      │      │       │      │ ition │      │       │      │       │      │  │\n## │ │      │      │       │      │       │      │       │      │       │      │  │\n## │ │      │      │       │      │ eleme │      │       │      │       │      │  │\n## │ │      │      │       │      │ nt,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ openi │      │       │      │       │      │  │\n## │ │      │      │       │      │ ngs:  │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460   │      │       │      │       │      │  │\n## │ │      │      │       │      │ and   │      │       │      │       │      │  │\n## │ │      │      │       │      │ T-pie │      │       │      │       │      │  │\n## │ │      │      │       │      │ ce,   │      │       │      │       │      │  │\n## │ │      │      │       │      │ openi │      │       │      │       │      │  │\n## │ │      │      │       │      │ ngs:  │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460 x │      │       │      │       │      │  │\n## │ │      │      │       │      │ 460   │      │       │      │       │      │  │\n## │ │      │      │       │      │ mm    │      │       │      │       │      │  │\n## │ │      │      │       │      │ Overa │      │       │      │       │      │  │\n## │ │      │      │       │      │ ll    │      │       │      │       │      │  │\n## │ │      │      │       │      │ displ │      │       │      │       │      │  │\n## │ │      │      │       │      │ ay    │      │       │      │       │      │  │\n## │ │ unit │ 3341 │ 4.827 │ mm   │ mm    │ mm   │ mm    │    2 │  0.95 │ 6586 │  │\n## │ │ s    │      │ 96491 │      │       │      │       │      │       │    0 │  │\n## │ │      │      │ 38018 │      │       │      │       │      │       │      │  │\n## │ │      │      │    23 │      │       │      │       │      │       │      │  │\n## │ │ insc │ 6289 │ 90.88 │ date │ date  │ date │ date  │   14 │  0.18 │ 1261 │  │\n## │ │ ript │    5 │ 74149 │ insc │ inscr │ insc │ inscr │      │       │    2 │  │\n## │ │ ion  │      │ 21749 │ ribe │ ibed  │ ribe │ ibed  │      │       │      │  │\n## │ │      │      │    68 │ d    │       │ d    │       │      │       │      │  │\n## │ │ thum │ 1078 │ 15.58 │ http │ http: │ http │ http: │   57 │  0.84 │ 5841 │  │\n## │ │ bnai │    6 │ 64799 │ ://w │ //www │ ://w │ //www │      │       │    5 │  │\n## │ │ lUrl │      │ 64162 │ ww.t │ .tate │ ww.t │ .tate │      │       │      │  │\n## │ │      │      │   368 │ ate. │ .org. │ ate. │ .org. │      │       │      │  │\n## │ │      │      │       │ org. │ uk/ar │ org. │ uk/ar │      │       │      │  │\n## │ │      │      │       │ uk/a │ t/ima │ uk/a │ t/ima │      │       │      │  │\n## │ │      │      │       │ rt/i │ ges/w │ rt/i │ ges/w │      │       │      │  │\n## │ │      │      │       │ mage │ ork/A │ mage │ ork/T │      │       │      │  │\n## │ │      │      │       │ s/wo │ /A00/ │ s/wo │ /T13/ │      │       │      │  │\n## │ │      │      │       │ rk/A │ A0000 │ rk/A │ T1386 │      │       │      │  │\n## │ │      │      │       │ R/AR │ 1_8.j │ /A00 │ 9_8.j │      │       │      │  │\n## │ │      │      │       │ 0000 │ pg    │ /A00 │ pg    │      │       │      │  │\n## │ │      │      │       │ 1_8. │       │ 001_ │       │      │       │      │  │\n## │ │      │      │       │ jpg  │       │ 8.jp │       │      │       │      │  │\n## │ │      │      │       │      │       │ g    │       │      │       │      │  │\n## │ │ url  │    0 │     0 │ http │ http: │ http │ http: │ 77.9 │     1 │ 6920 │  │\n## │ │      │      │       │ ://w │ //www │ ://w │ //www │      │       │    1 │  │\n## │ │      │      │       │ ww.t │ .tate │ ww.t │ .tate │      │       │      │  │\n## │ │      │      │       │ ate. │ .org. │ ate. │ .org. │      │       │      │  │\n## │ │      │      │       │ org. │ uk/ar │ org. │ uk/ar │      │       │      │  │\n## │ │      │      │       │ uk/a │ t/art │ uk/a │ t/art │      │       │      │  │\n## │ │      │      │       │ rt/a │ works │ rt/a │ works │      │       │      │  │\n## │ │      │      │       │ rtwo │ /naum │ rtwo │ /zyw- │      │       │      │  │\n## │ │      │      │       │ rks/ │ an-ra │ rks/ │ light │      │       │      │  │\n## │ │      │      │       │ lim- │ w-mat │ abak │ -t005 │      │       │      │  │\n## │ │      │      │       │ a-p1 │ erial │ anow │ 34    │      │       │      │  │\n## │ │      │      │       │ 1588 │ -wash │ icz- │       │      │       │      │  │\n## │ │      │      │       │      │ ing-h │ abak │       │      │       │      │  │\n## │ │      │      │       │      │ ands- │ an-o │       │      │       │      │  │\n## │ │      │      │       │      │ norma │ rang │       │      │       │      │  │\n## │ │      │      │       │      │ l-a-o │ e-t1 │       │      │       │      │  │\n## │ │      │      │       │      │ f-ab- │ 2980 │       │      │       │      │  │\n## │ │      │      │       │      │ raw-m │      │       │      │       │      │  │\n## │ │      │      │       │      │ ateri │      │       │      │       │      │  │\n## │ │      │      │       │      │ al-wa │      │       │      │       │      │  │\n## │ │      │      │       │      │ shing │      │       │      │       │      │  │\n## │ │      │      │       │      │ -hand │      │       │      │       │      │  │\n## │ │      │      │       │      │ s-nor │      │       │      │       │      │  │\n## │ │      │      │       │      │ mal-b │      │       │      │       │      │  │\n## │ │      │      │       │      │ -of-a │      │       │      │       │      │  │\n## │ │      │      │       │      │ b-ar0 │      │       │      │       │      │  │\n## │ │      │      │       │      │ 0579  │      │       │      │       │      │  │\n## │ └──────┴──────┴───────┴──────┴───────┴──────┴───────┴──────┴───────┴──────┘  │\n## ╰──────────────────────────────────── End ─────────────────────────────────────╯\n```\n:::\n\n\n\n:::\n\n### Accessing one column\n\nFirst, let's pull out the year for each piece of artwork in the dataset and see what we can do with it...\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(artwork$year)\n## [1]   NA   NA 1785   NA 1826 1826\n```\n:::\n\n\n\n\nWe reference a column of the dataset by name using `dataset_name$column_name`, and since our data is stored in `artwork`, and we want the column named `year`, we use `artwork$year` to get access to the data we want.\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nartwork.year.head()\n## 0       NaN\n## 1       NaN\n## 2    1785.0\n## 3       NaN\n## 4    1826.0\n## Name: year, dtype: float64\n```\n:::\n\n\n\n\nWe reference a column of the dataset by name using `dataset_name.column_name` or `dataset_name['column_name']`, and since our data is stored in `artwork` and we want the column `year`, we use `artwork.year` or `artwork['year']` to access the data we want.\n\n:::\n\n\nI've used the `head` command to show only the first few values (so that the output isn't overwhelming). \n\n### Variable Summary\n\nWhen we have output like this, it is useful to summarize the output in some way:\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(artwork$year)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    1545    1817    1831    1867    1953    2012    5397\n```\n:::\n\n\n\n\nThat's much less output, but we might want to instead make a chart:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(artwork$year, breaks = 30)\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-data-col-1.png){width=2100}\n:::\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nartwork.year.describe()\n## count    63804.000000\n## mean      1867.227823\n## std         72.012718\n## min       1545.000000\n## 25%       1817.000000\n## 50%       1831.000000\n## 75%       1953.000000\n## max       2012.000000\n## Name: year, dtype: float64\n```\n:::\n\n\n\n\nThe `df.describe()` command provides us with a 5-number summary and then some additional statistics. \n\nWe can also create a chart:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nartwork.year.hist(bins = 30)\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-data-col-py-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\nPersonally, I much prefer the graphical version. It's informative (though it does leave out NA values) and shows that there are pieces going back to the 1500s, but that most pieces were made in the early 1800s or late 1900s. \n\n### Create a Histogram (base graphics/matplotlib)\n\nWe might be interested in the aspect ratio of the artwork - let's take a look at the input variables and define new variables related to aspect ratio(s).\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1, 3)) # 3 plots on one row\nhist(artwork$width, main = \"width\", breaks = 30)\nhist(artwork$depth, main = \"depth\", breaks = 30)\nhist(artwork$height, main = \"height\", breaks = 30)\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-dims-art-3.png){width=3600}\n:::\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(nrows=1, ncols=3) # 3 subplots\n\nartwork.width.hist(bins = 30, ax = axes[0])\nartwork.depth.hist(bins = 30, ax = axes[1])\nartwork.height.hist(bins = 30, ax= axes[2])\n\n# Set subplot titles\naxes[0].title.set_text(\"width\")\naxes[1].title.set_text(\"depth\")\naxes[2].title.set_text(\"height\")\n\nplt.show()\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-dims-art-py-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\nSo all of our variables are skewed quite a bit, and we know from the existence of the `units` column that they may not be in the same unit, either.\n\n### Summary Tables\n\nLet's make a table of the units column so that we can see what the frequency of various units are in the dataset.\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(artwork$units, useNA = 'ifany')\n## \n##    mm  <NA> \n## 65860  3341\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nartwork.units.value_counts(dropna=False)\n## units\n## mm     65860\n## NaN     3341\n## Name: count, dtype: int64\n```\n:::\n\n\n\n\n:::\n\nEverything that has specified units is in mm. That makes things easier.\n\n### Defining a new variable\n\n::: panel-tabset\n\n#### R {-}\n\nTo define a new variable that exists on its own, we might do something like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naspect_hw <- artwork$height/artwork$width\npar(mfrow = c(1, 2))\nhist(aspect_hw, breaks = 30)\nhist(log(aspect_hw), breaks = 30)\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-aspect-ratio-calc-1.png){width=2100}\n:::\n:::\n\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n\nfig, axes = plt.subplots(nrows=1, ncols=2) # 2 subplots\n\naspect_hw = artwork.height/artwork.width\naspect_hw.hist(bins = 30, ax = axes[0])\nnp.log(aspect_hw).hist(bins = 30, ax = axes[1])\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/hist-aspect-ratio-calc-py-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\nMost things are pretty square-ish, but there are obviously quite a few exceptions in both directions.\n\nThe one problem with how we've done this is that we now have a data frame with all of our data in it, and a separate variable `aspect_hw`, that is not attached to our data frame. That's not ideal - it's easy to lose track of the variable, it's easy to accidentally \"sort\" the variable so that the row order isn't the same as in the original data frame... there are all sorts of potential issues.\n\n### Adding a new column\n\nThe better way to define a new variable is to add a new **column** to the data frame:\n\n::: panel-tabset\n\n#### R {-}\n\nTo define a new variable that exists on its own, we might do something like this:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nartwork$aspect_hw <- artwork$height/artwork$width\n```\n:::\n\n\n\n\n\n#### Python {-}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nartwork['aspect_hw'] = artwork.height/artwork.width\n```\n:::\n\n\n\n\nNote that when you create a new column in a pandas dataframe, you have to use `df['colname']` on the left hand side, even if you use `df.colname` syntax on the right hand side.\n\n:::\n\n\n(We'll learn a shorter way to do this later, but this is functional, if not pretty, for now).\n\nThe downside to this is that we have to write out `artwork$aspect_hw` or `artwork.aspect_hw` each time we want to reference the variable. That is a pain, but one that's relatively temporary (we'll get to a better way to do this in a couple of weeks). A little bit of extra typing is definitely worth it if you don't lose data you want to keep.\n\n:::{.callout-important}\n### Assign your calculations to a variable or column!\n\nOne mistake I see people make frequently is to calculate `height/width`, but then not assign that value to a variable. \n\n**If you're not using `<-` in R^[(or `=`, or `->` if you're a total heathen)] or `=` in Python, then you're not saving that information** to be referenced later - you're just calculating values temporarily and possibly printing them as output. \n\n:::\n\n### Conclusions\n\nIt's important to keep track of where you're putting the pieces you create during an analysis - just as important as keeping track of the different sub-components when you're putting a lego set together or making a complex recipe in the kitchen. Forgetting to assign your calculation to a variable is like dumping your glaze down the sink or throwing that small lego component into the trash.\n\n\n## Dogs of NYC\n\nNew York City provides a whole host of open-data resources, including a [dataset of dogs licensed in the city on an annual basis](https://data.cityofnewyork.us/Health/NYC-Dog-Licensing-Dataset/nu7n-tubp) (link is to the NYC Open Data Page). \n\n[CSV link](https://data.cityofnewyork.us/api/views/nu7n-tubp/rows.csv?accessType=DOWNLOAD) (this data is ~23 MB)\n\n###  Read in data\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\n\nif (!file.exists(\"../data/NYC_dogs.csv\")) {\n  # if the file doesn't exist, download it!\n  download.file(\n    \"https://data.cityofnewyork.us/api/views/nu7n-tubp/rows.csv?accessType=DOWNLOAD\", # url for download\n    destfile = \"../data/NYC_dogs.csv\", # location to store the file\n    mode = \"wb\" # need this to get downloads to work on windows\n  )\n}\n\ndogs <- read_csv(\"../data/NYC_dogs.csv\")\nhead(dogs)\n## # A tibble: 6 × 8\n##   AnimalName AnimalGender AnimalBirthYear BreedName    ZipCode LicenseIssuedDate\n##   <chr>      <chr>                  <dbl> <chr>          <dbl> <chr>            \n## 1 PAIGE      F                       2014 American Pi…   10035 09/12/2014       \n## 2 YOGI       M                       2010 Boxer          10465 09/12/2014       \n## 3 ALI        M                       2014 Basenji        10013 09/12/2014       \n## 4 QUEEN      F                       2013 Akita Cross…   10013 09/12/2014       \n## 5 LOLA       F                       2009 Maltese        10028 09/12/2014       \n## 6 IAN        M                       2006 Unknown        10013 09/12/2014       \n## # ℹ 2 more variables: LicenseExpiredDate <chr>, `Extract Year` <dbl>\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom os.path import exists # to test whether files exist\nimport pandas as pd\nimport requests # to download a file\n\nif ~exists(\"../data/NYC_dogs.csv\"):\n  response = requests.get(\"https://data.cityofnewyork.us/api/views/nu7n-tubp/rows.csv?accessType=DOWNLOAD\")\n  open(\"../data/NYC_dogs.csv\", \"wb\").write(response.content)\n## 45416500\n\ndogs = pd.read_csv(\"../data/NYC_dogs.csv\")\ndogs.head()\n##   AnimalName AnimalGender  ... LicenseExpiredDate Extract Year\n## 0      PAIGE            F  ...         09/12/2017         2016\n## 1       YOGI            M  ...         10/02/2017         2016\n## 2        ALI            M  ...         09/12/2019         2016\n## 3      QUEEN            F  ...         09/12/2017         2016\n## 4       LOLA            F  ...         10/09/2017         2016\n## \n## [5 rows x 8 columns]\n```\n:::\n\n\n\n\n:::\n\n\n### Work with Dates\n\nOne thing we might want to do first is to transform the license dates (`LicenseIssuedDate`, `LicenseExpiredDate`) into actual dates instead of characters. \n\n::: panel-tabset\n\n#### R {-}\n\nWe will use the `lubridate` package to do this, because it is designed to make working with dates and times very easy.\n\nYou may need to run `install.packages(\"lubridate\")` in the R console if you have not used the package before.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nhead(dogs$LicenseExpiredDate) # Dates are in month-day-year format\n## [1] \"09/12/2017\" \"10/02/2017\" \"09/12/2019\" \"09/12/2017\" \"10/09/2017\"\n## [6] \"10/30/2019\"\n\ndogs$LicenseExpiredDate <- mdy(dogs$LicenseExpiredDate)\ndogs$LicenseIssuedDate <- mdy(dogs$LicenseIssuedDate)\n\nhead(dogs$LicenseExpiredDate)\n## [1] \"2017-09-12\" \"2017-10-02\" \"2019-09-12\" \"2017-09-12\" \"2017-10-09\"\n## [6] \"2019-10-30\"\n```\n:::\n\n\n\n\n#### Python {-}\n\nYou may need to run `pip install datetime` in the terminal if you have not used the package before. \n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom datetime import date\n\ndogs[['LicenseExpiredDate','LicenseIssuedDate']].head() # Before\n##   LicenseExpiredDate LicenseIssuedDate\n## 0         09/12/2017        09/12/2014\n## 1         10/02/2017        09/12/2014\n## 2         09/12/2019        09/12/2014\n## 3         09/12/2017        09/12/2014\n## 4         10/09/2017        09/12/2014\n\nformat_str = \"%m/%d/%Y\" # date format in the dataset\n\ndogs['LicenseExpiredDate'] = pd.to_datetime(dogs.LicenseExpiredDate, format = format_str)\ndogs['LicenseIssuedDate'] = pd.to_datetime(dogs.LicenseIssuedDate, format = format_str)\n\ndogs[['LicenseExpiredDate','LicenseIssuedDate']].head() # After\n##   LicenseExpiredDate LicenseIssuedDate\n## 0         2017-09-12        2014-09-12\n## 1         2017-10-02        2014-09-12\n## 2         2019-09-12        2014-09-12\n## 3         2017-09-12        2014-09-12\n## 4         2017-10-09        2014-09-12\n```\n:::\n\n\n\n\n:::\n\nIt might be interesting to see when licenses have been issued over time, so let's make a histogram. This time, I'm going to use ggplot graphics with the `ggplot2` package in R and the `plotnine` package in python (which is the python version of the R package). \n\n### Create a Histogram (ggplot2/plotnine)\n\n::: panel-tabset\n\n#### R {-}\n\nYou may need to run `install.packages(\"ggplot2\")` in the R console if you have not used ggplot2 before.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(\n  data = dogs, \n  aes(x = LicenseIssuedDate) # Specify we want LicenseIssueDate on the x-axis\n) + \n  geom_histogram() # Create a histogram\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/dog-license-hist-1.png){width=2100}\n:::\n:::\n\n\n\n\n#### Python {-}\n\nYou may need to run `pip install plotnine` in the terminal if you have not used the package before. \n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n(\n  ggplot(mapping = aes(x = 'LicenseIssuedDate'), data = dogs) + \n  geom_histogram() # Create a histogram\n)\n## <plotnine.ggplot.ggplot object at 0x7f90937a1cd0>\n```\n:::\n\n\n\n\n:::\n\nThere is an interesting periodicity to the license issue dates. \n\n### Compute License Length\n\nI'm also curious about how long a license tends to be held for - we can get this information by subtracting the issue date from the expiration date.\n\n::: panel-tabset\n\n#### R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndogs$LicenseLength <- dogs$LicenseExpiredDate - dogs$LicenseIssuedDate\nsummary(dogs$LicenseLength)\n## Time differences in days\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##     1.0   365.0   366.0   541.7   415.0  7913.0      82\nhead(dogs$LicenseLength)\n## Time differences in days\n## [1] 1096 1116 1826 1096 1123 1874\n```\n:::\n\n\n\n\nWe can see that directly subtracting date-times gives us a license length in days. That's useful enough, I guess, but it might be more useful in years... unfortunately, that's not an option for `difftime()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ndogs$LicenseLength <- difftime(dogs$LicenseExpiredDate, dogs$LicenseIssuedDate, units = \"weeks\")\n\n# 52 weeks in a year so we'll just convert as we plot\nggplot(data = dogs, aes(x = LicenseLength / 52 )) + geom_histogram() + \n  scale_x_continuous(limits = c(0,10))\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/dog-license-length-2-1.png){width=2100}\n:::\n:::\n\n\n\n\n#### Python\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndogs[\"License_length\"] = dogs.LicenseExpiredDate - dogs.LicenseIssuedDate\n\ndogs.License_length.describe()\n## count                         722782\n## mean     541 days 15:49:38.083018136\n## std      423 days 20:41:36.018659752\n## min                  1 days 00:00:00\n## 25%                365 days 00:00:00\n## 50%                366 days 00:00:00\n## 75%                415 days 00:00:00\n## max               7913 days 00:00:00\n## Name: License_length, dtype: object\ndogs.License_length.head()\n## 0   1096 days\n## 1   1116 days\n## 2   1826 days\n## 3   1096 days\n## 4   1123 days\n## Name: License_length, dtype: timedelta64[ns]\n\ndogs[\"License_length_yr\"] = dogs.License_length.dt.days/365.25\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n(\n  ggplot(mapping = aes(x = \"License_length_yr\"), data = dogs) + \n  geom_histogram(bins = 30)+\n  scale_x_continuous(limits = (0,10))\n)\n## <plotnine.ggplot.ggplot object at 0x7f9069204f10>\n```\n:::\n\n\n\n\nIn python, we have to first access the \"days\" attribute of the `timedelta64` data type (this gives us a number) using `dogs.Licence_length.dt.days` and then divide by 365.25 (number of days in a year, on average). \n:::\n\n### Explore Boroughs\n\nAnother question that I have when looking at this dataset is a bit more superficial - are the characteristics of different areas different? The `dogs` data frame has a Borough column, but it's not actually filled in, so we'll need to get rid of it and then add Borough back in by zip code. \n\nTo look at this, we'll need a bit more data. I found a list of NYC zip codes by borough, which we can merge in with the data we already have to get puppy registrations by borough. Then, we can see if e.g. the top 10 breeds are different for different boroughs. To simplify this, I'm going to link to a file to merge in, and not show you the specifics of how I read the table from [this site](https://www.nycbynatives.com/nyc_info/new_york_city_zip_codes.php).\n\n\n\n\n\n\n\n\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nborough_zip <- read_csv(\"https://raw.githubusercontent.com/srvanderplas/stat-computing-r-python/main/data/nyc_zip_borough.csv\")\n\n# Remove the Borough column from dogs\ndogs <- dogs[, which(names(dogs) != \"Borough\")]\ndogs <- merge(dogs, borough_zip, by = \"ZipCode\")\nhead(dogs)\n##   ZipCode AnimalName AnimalGender AnimalBirthYear                BreedName\n## 1   10001      BARAK            M            2013                  Unknown\n## 2   10001       ESME            F            2020 Border Collie Crossbreed\n## 3   10001      ROCKY            M            2014               Rottweiler\n## 4   10001    UNKNOWN            M            2022                   Poodle\n## 5   10001      LOUIE            M            2020        Yorkshire Terrier\n## 6   10001       ABBY            F            2008       Labrador Retriever\n##   LicenseIssuedDate LicenseExpiredDate Extract Year   LicenseLength   Borough\n## 1        2016-12-28         2018-01-02         2016  52.85714 weeks Manhattan\n## 2        2021-07-31         2026-07-31         2024 260.85714 weeks Manhattan\n## 3        2018-10-16         2019-10-16         2018  52.14286 weeks Manhattan\n## 4        2022-08-21         2023-08-21         2023  52.14286 weeks Manhattan\n## 5        2020-07-08         2021-07-08         2022  52.14286 weeks Manhattan\n## 6        2016-08-01         2021-09-24         2016 268.57143 weeks Manhattan\n```\n:::\n\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nborough_zip = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/stat-computing-r-python/main/data/nyc_zip_borough.csv\")\ndogs = dogs.drop('Borough', axis = 1) # drop borough column\n## KeyError: \"['Borough'] not found in axis\"\ndogs = pd.merge(dogs, borough_zip, on = 'ZipCode')\ndogs.head()\n##   AnimalName AnimalGender  ... License_length_yr    Borough\n## 0      PAIGE            F  ...          3.000684  Manhattan\n## 1       YOGI            M  ...          3.055441      Bronx\n## 2        ALI            M  ...          4.999316  Manhattan\n## 3      QUEEN            F  ...          3.000684  Manhattan\n## 4       LOLA            F  ...          3.074606  Manhattan\n## \n## [5 rows x 11 columns]\n```\n:::\n\n\n\n\n:::\n\nNow that we have borough, let's write a function that will take a dataset and spit out a list of the top 5 dog breeds registered in that area.\n\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_5_breeds <- function(data) {\n  # Inside the function, our dataset is called data, not dogs\n  tmp <- table(data$BreedName) \n  return(sort(tmp, decreasing = T)[1:5]) # top 5 breeds with counts\n}\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef top_5_breeds(data):\n  tmp = pd.value_counts(data.BreedName)\n  return tmp.iloc[0:5]\n```\n:::\n\n\n\n\n:::\n\n\nNow, using that function, lets write a for loop that loops through the 5 boroughs and spits out the top 5 breeds in each borough:\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboroughs <- unique(borough_zip$Borough) # get a list of the 5 boroughs\nfor (i in boroughs) {\n  # Get subset of data frame corresponding to the Borough\n  dogs_sub <- dogs[dogs$Borough == i,]\n  # Get top 5 dog breeds\n  result <- as.data.frame(top_5_breeds(dogs_sub))\n  # set names\n  names(result) <- c(\"Breed\", \"Freq\")\n  # Add Borough as a new column\n  result$Borough <- i\n  # Add rank as a new column\n  result$rank <- 1:5\n  \n  print(result)\n}\n##                Breed  Freq   Borough rank\n## 1            Unknown 18784 Manhattan    1\n## 2  Yorkshire Terrier  9196 Manhattan    2\n## 3          Chihuahua  9112 Manhattan    3\n## 4           Shih Tzu  8038 Manhattan    4\n## 5 Labrador Retriever  7873 Manhattan    5\n##                Breed Freq Borough rank\n## 1            Unknown 6722  Staten    1\n## 2           Shih Tzu 4051  Staten    2\n## 3  Yorkshire Terrier 3893  Staten    3\n## 4 Labrador Retriever 2713  Staten    4\n## 5            Maltese 2067  Staten    5\n##                                  Breed Freq Borough rank\n## 1                    Yorkshire Terrier 6814   Bronx    1\n## 2                              Unknown 6284   Bronx    2\n## 3                             Shih Tzu 5756   Bronx    3\n## 4                            Chihuahua 3675   Bronx    4\n## 5 American Pit Bull Mix / Pit Bull Mix 2845   Bronx    5\n##               Breed  Freq Borough rank\n## 1           Unknown 13622  Queens    1\n## 2 Yorkshire Terrier  9109  Queens    2\n## 3          Shih Tzu  8343  Queens    3\n## 4         Chihuahua  5638  Queens    4\n## 5           Maltese  5613  Queens    5\n##                           Breed  Freq  Borough rank\n## 1                       Unknown 17149 Brooklyn    1\n## 2             Yorkshire Terrier 10628 Brooklyn    2\n## 3                      Shih Tzu 10316 Brooklyn    3\n## 4                     Chihuahua  7480 Brooklyn    4\n## 5 Labrador Retriever Crossbreed  6311 Brooklyn    5\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nboroughs = borough_zip.Borough.unique()\nfor i in boroughs:\n  # get subset of data frame corresponding to the borough\n  dogs_sub = dogs.query(\"Borough == @i\")\n  # Get top 5 breeds\n  result = top_5_breeds(dogs_sub)\n  # Convert to DataFrame and make the index another column\n  result = result.to_frame().reset_index()\n  # Rename columns\n  result.rename(columns = {'index':'BreedName','BreedName':'count'})\n  # Add Borough column\n  result[\"Borough\"] = i\n  # Add rank column\n  result[\"rank\"] = range(1, 6)\n\n  print(result)\n##                 count  count\n## 0             Unknown  18784\n## 1   Yorkshire Terrier   9196\n## 2           Chihuahua   9112\n## 3            Shih Tzu   8038\n## 4  Labrador Retriever   7873\n##             BreedName  count    Borough  rank\n## 0             Unknown  18784  Manhattan     1\n## 1   Yorkshire Terrier   9196  Manhattan     2\n## 2           Chihuahua   9112  Manhattan     3\n## 3            Shih Tzu   8038  Manhattan     4\n## 4  Labrador Retriever   7873  Manhattan     5\n##                 count  count\n## 0             Unknown   6722\n## 1            Shih Tzu   4051\n## 2   Yorkshire Terrier   3893\n## 3  Labrador Retriever   2713\n## 4             Maltese   2067\n##             BreedName  count Borough  rank\n## 0             Unknown   6722  Staten     1\n## 1            Shih Tzu   4051  Staten     2\n## 2   Yorkshire Terrier   3893  Staten     3\n## 3  Labrador Retriever   2713  Staten     4\n## 4             Maltese   2067  Staten     5\n##                                   count  count\n## 0                     Yorkshire Terrier   6814\n## 1                               Unknown   6284\n## 2                              Shih Tzu   5756\n## 3                             Chihuahua   3675\n## 4  American Pit Bull Mix / Pit Bull Mix   2845\n##                               BreedName  count Borough  rank\n## 0                     Yorkshire Terrier   6814   Bronx     1\n## 1                               Unknown   6284   Bronx     2\n## 2                              Shih Tzu   5756   Bronx     3\n## 3                             Chihuahua   3675   Bronx     4\n## 4  American Pit Bull Mix / Pit Bull Mix   2845   Bronx     5\n##                count  count\n## 0            Unknown  13622\n## 1  Yorkshire Terrier   9109\n## 2           Shih Tzu   8343\n## 3          Chihuahua   5638\n## 4            Maltese   5613\n##            BreedName  count Borough  rank\n## 0            Unknown  13622  Queens     1\n## 1  Yorkshire Terrier   9109  Queens     2\n## 2           Shih Tzu   8343  Queens     3\n## 3          Chihuahua   5638  Queens     4\n## 4            Maltese   5613  Queens     5\n##                            count  count\n## 0                        Unknown  17149\n## 1              Yorkshire Terrier  10628\n## 2                       Shih Tzu  10316\n## 3                      Chihuahua   7480\n## 4  Labrador Retriever Crossbreed   6311\n##                        BreedName  count   Borough  rank\n## 0                        Unknown  17149  Brooklyn     1\n## 1              Yorkshire Terrier  10628  Brooklyn     2\n## 2                       Shih Tzu  10316  Brooklyn     3\n## 3                      Chihuahua   7480  Brooklyn     4\n## 4  Labrador Retriever Crossbreed   6311  Brooklyn     5\n```\n:::\n\n\n\n\n\n[More information on pandas `query` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) (use `\\@varname` to use a variable in a query).\n\n:::\n\n\nIf we wanted to save these results as a summary data frame, we could totally do that!\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbreeds_by_borough <- data.frame() # create a blank data frame\n\nfor (i in boroughs) {\n  # Get subset of data frame corresponding to the Borough\n  dogs_sub <- subset(dogs, Borough == i)\n  # Get top 5 dog breeds\n  result <- as.data.frame(top_5_breeds(dogs_sub))\n  # set names\n  names(result) <- c(\"Breed\", \"Freq\")\n  # Add Borough as a new column\n  result$Borough <- i\n  # Add rank as a new column\n  result$rank <- 1:5\n  \n  breeds_by_borough <- rbind(breeds_by_borough, result)\n}\n\nbreeds_by_borough\n##                                   Breed  Freq   Borough rank\n## 1                               Unknown 18784 Manhattan    1\n## 2                     Yorkshire Terrier  9196 Manhattan    2\n## 3                             Chihuahua  9112 Manhattan    3\n## 4                              Shih Tzu  8038 Manhattan    4\n## 5                    Labrador Retriever  7873 Manhattan    5\n## 6                               Unknown  6722    Staten    1\n## 7                              Shih Tzu  4051    Staten    2\n## 8                     Yorkshire Terrier  3893    Staten    3\n## 9                    Labrador Retriever  2713    Staten    4\n## 10                              Maltese  2067    Staten    5\n## 11                    Yorkshire Terrier  6814     Bronx    1\n## 12                              Unknown  6284     Bronx    2\n## 13                             Shih Tzu  5756     Bronx    3\n## 14                            Chihuahua  3675     Bronx    4\n## 15 American Pit Bull Mix / Pit Bull Mix  2845     Bronx    5\n## 16                              Unknown 13622    Queens    1\n## 17                    Yorkshire Terrier  9109    Queens    2\n## 18                             Shih Tzu  8343    Queens    3\n## 19                            Chihuahua  5638    Queens    4\n## 20                              Maltese  5613    Queens    5\n## 21                              Unknown 17149  Brooklyn    1\n## 22                    Yorkshire Terrier 10628  Brooklyn    2\n## 23                             Shih Tzu 10316  Brooklyn    3\n## 24                            Chihuahua  7480  Brooklyn    4\n## 25        Labrador Retriever Crossbreed  6311  Brooklyn    5\n```\n:::\n\n\n\n\nWe could even sort our data by the rank and Borough for easier comparisons:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbreeds_by_borough[order(breeds_by_borough$rank, \n                        breeds_by_borough$Borough),]\n##                                   Breed  Freq   Borough rank\n## 11                    Yorkshire Terrier  6814     Bronx    1\n## 21                              Unknown 17149  Brooklyn    1\n## 1                               Unknown 18784 Manhattan    1\n## 16                              Unknown 13622    Queens    1\n## 6                               Unknown  6722    Staten    1\n## 12                              Unknown  6284     Bronx    2\n## 22                    Yorkshire Terrier 10628  Brooklyn    2\n## 2                     Yorkshire Terrier  9196 Manhattan    2\n## 17                    Yorkshire Terrier  9109    Queens    2\n## 7                              Shih Tzu  4051    Staten    2\n## 13                             Shih Tzu  5756     Bronx    3\n## 23                             Shih Tzu 10316  Brooklyn    3\n## 3                             Chihuahua  9112 Manhattan    3\n## 18                             Shih Tzu  8343    Queens    3\n## 8                     Yorkshire Terrier  3893    Staten    3\n## 14                            Chihuahua  3675     Bronx    4\n## 24                            Chihuahua  7480  Brooklyn    4\n## 4                              Shih Tzu  8038 Manhattan    4\n## 19                            Chihuahua  5638    Queens    4\n## 9                    Labrador Retriever  2713    Staten    4\n## 15 American Pit Bull Mix / Pit Bull Mix  2845     Bronx    5\n## 25        Labrador Retriever Crossbreed  6311  Brooklyn    5\n## 5                    Labrador Retriever  7873 Manhattan    5\n## 20                              Maltese  5613    Queens    5\n## 10                              Maltese  2067    Staten    5\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbreeds_by_borough = pd.DataFrame() # Create a blank dataframe\n\nfor i in boroughs:\n  print(i)\n  # get subset of data frame corresponding to the borough\n  dogs_sub = dogs.query(\"Borough== @i\")\n  # Get top 5 breeds\n  result = top_5_breeds(dogs_sub)\n  # Convert to DataFrame and make the index another column\n  result = result.to_frame().reset_index()\n  # Rename columns\n  result.rename(columns = {'index':'BreedName','BreedName':'count'})\n  # Add Borough column\n  result[\"Borough\"] = i\n  # Add rank column\n  result[\"rank\"] = range(1, 6)\n  # Append to blank dataframe\n  breeds_by_borough = breeds_by_borough.append(result)\n## AttributeError: 'DataFrame' object has no attribute 'append'\n\nbreeds_by_borough.head()\n## Empty DataFrame\n## Columns: []\n## Index: []\nbreeds_by_borough.tail()\n## Empty DataFrame\n## Columns: []\n## Index: []\n```\n:::\n\n\n\n\n\nWe could even sort our data by the rank and Borough for easier comparisons:\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbreeds_by_borough.sort_values(['rank', 'Borough'])\n## KeyError: 'rank'\n```\n:::\n\n\n\n\n:::\n\n\nSoon we'll learn a much shorter set of commands to get these types of summaries, but it's important to know how a for loop connects to the concept of summarizing data by a factor (in this case, by borough).\n\n::: {.callout-tip}\n### Try it out: NYC dogs {-}\n\nLook at the name, age, or gender of dogs registered in NYC and see if you can come up with a similar function and way of summarizing the data in a for-loop. You may want to calculate the mean or quantiles (for numeric variables), or list the most common dog names/genders in each borough.\n\n:::\n\n## Swearing in Tarantino Films\n\n**Content warning:** This section contains analysis of swear words and deaths. I will not censor the words used in these movies, as they are legitimate data and could lead to an interesting analysis. Feel free to skip this example if it makes you uncomfortable.\n\n> Quentin Jerome Tarantino (/ˌtærənˈtiːnoʊ/; born March 27, 1963) is an American film director, screenwriter, producer, actor, and author. His films are characterized by stylized violence, extended dialogue including a pervasive use of profanity, and references to popular culture. [@wikipediacontributorsQuentinTarantino2023]\n\n\n###  Read in data\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\n\ntarantino <- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/tarantino/tarantino.csv\")\nhead(tarantino)\n## # A tibble: 6 × 4\n##   movie          type  word     minutes_in\n##   <chr>          <chr> <chr>         <dbl>\n## 1 Reservoir Dogs word  dick           0.4 \n## 2 Reservoir Dogs word  dicks          0.43\n## 3 Reservoir Dogs word  fucked         0.55\n## 4 Reservoir Dogs word  fucking        0.61\n## 5 Reservoir Dogs word  bullshit       0.61\n## 6 Reservoir Dogs word  fuck           0.66\n```\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\ntarantino = pd.read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/tarantino/tarantino.csv\")\ntarantino.head()\n##             movie  type      word  minutes_in\n## 0  Reservoir Dogs  word      dick        0.40\n## 1  Reservoir Dogs  word     dicks        0.43\n## 2  Reservoir Dogs  word    fucked        0.55\n## 3  Reservoir Dogs  word   fucking        0.61\n## 4  Reservoir Dogs  word  bullshit        0.61\n```\n:::\n\n\n\n\n:::\n\n\n### Create a Density Plot (ggplot2/plotnine)\n\n::: panel-tabset\n\n#### R {-}\n\nYou may need to run `install.packages(\"ggplot2\")` in the R console if you have not used ggplot2 before.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(\n  data = tarantino, \n  aes(x = minutes_in, color = type)\n) + \n  geom_density() + \n  scale_color_manual(values = c(\"black\", \"grey\")) +\n  facet_wrap(~movie)\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/tarantino-hist-1.png){width=2100}\n:::\n:::\n\n\n\n\n#### Python {-}\n\nYou may need to run `pip install plotnine` in the terminal if you have not used the package before. \n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\nplot = ggplot(data = tarantino, mapping = aes(x = 'minutes_in', color = \"type\")) \nplot = plot + geom_density()\nplot = plot + scale_color_manual(values = [\"black\", \"grey\"]) \nplot = plot + facet_wrap(\"movie\")\nplot.show()\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/tarantino-hist-py-1.png){width=614}\n:::\n:::\n\n\n\n\n:::\n\nSo, from these plots, we can see that in at least two movies, there are high spikes in deaths about 1/3 and 2/3 of the way in; in another movie, most of the deaths occur in the first 25 minutes. Swearing, on the other hand, seems to be fairly evenly distributed throughout the movies. \n\n### Compare Swear Words Used by Movie\n\nAs there are a very large number of swear words and variants in Tarantino movies, let's work with only the 6 most common swear words in the data set. \nTo do this, we have to: \n\n1. Select only rows that have words (as opposed to deaths)\n2. Assemble a list of the 6 most common words\n3. Select only rows with those words\n\n\n::: panel-tabset\n\n#### R {-}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n# Step 1\ntarantino_words <- tarantino[tarantino$type == \"word\",]\n\n# Step 2\nword_freq <- sort(table(tarantino_words$word), decreasing = T)\n# word_freq has the counts of how many times the words appear\n# we need the names that are above those counts\nswear6 <- names(word_freq)[1:6]\n\n# Step 3\nword_6 <- tarantino_words[tarantino_words$word %in% swear6,]\n\n\n\nggplot(\n  data = word_6, \n  aes(x = movie, fill = word)\n) + \n  geom_bar() + \n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/tarantino-stacked-bar-3.png){width=2100}\n:::\n:::\n\n\n\n\n#### Python {-}\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n# Step 1 - remove deaths\ntarantino_words = tarantino.query(\"type == 'word'\")\n\n# Step 2 - 6 most common words\n\nplot = ggplot(tarantino, aes(x = 'minutes_in', color = 'movie'))\nplot = plot + geom_density() \nplot = plot + facet_wrap(\"type\")\n\nplot.show()\n```\n\n::: {.cell-output-display}\n![](07-prog-data_files/figure-html/tarantino-stacked-bar-py-1.png){width=614}\n:::\n:::\n\n\n\n\n:::\n\nXXX Under construction - I will add more as I get time. \n",
    "supporting": [
      "07-prog-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}