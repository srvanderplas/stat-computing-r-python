{
  "hash": "5a52b88a70b2c2516d676736f636cc3b",
  "result": {
    "engine": "knitr",
    "markdown": "# Creating Good Charts {#sec-good-graphics}\n\n## Objectives {-}\n\n- Understand what features make graphics effective\n- Evaluate existing charts for accessibility and readability\n- Make improvements to charts to increase comprehension and accessibility\n\n## Introduction\n\nA chart is **good** if it allows the user to draw *useful conclusions that are supported by data*. \nObviously, this definition depends on the purpose of the chart.\nA simple and disposable chart created during an exploratory data analysis process may be useful even if it is not nicely formatted and publication ready, because its purpose is to guide an interactive process. \nThis is very different than a chart created for communicating with the public -- for instance, a forecast map showing possible paths and intensities of a hurricane that would inform resident decisions about storm preparation and/or evacuation. \n\nComprehensive advice on creating good charts is difficult, too, because what works for one dataset may not work for another, even if the variable types are similar. \nWe have some established conventions that should usually be followed (for instance, time usually is placed on the x-axis, with a dependent variable on the y-axis), but there are usually situations where it is reasonable to break those conventions. \n\nFinally, what makes a chart \"good\" requires some additional knowledge beyond statistics and programming.\nTo make good charts, we have to understand how those charts will be interpreted, which means we need at least some basic information about human perception and cognition. \nThe human visual system is incredibly powerful - it has a bandwidth that would make even modern computers jealous, and many computations are performed instantaneously and without requiring any process management (e.g. the calculations happen so fast and so automatically that you aren't really aware that they're happening). \nThis comes with some tradeoffs, though - evolutionary optimizations that ensure that you can spot predators quickly weren't as concerned with your ability to accurately determine the height of a two-dimensional drawing of a three-dimensional object. \nSo, while the visual system has some amazing strengths and is a very useful medium to communicate about data, it is important to understand the limitations of the visual system's sensors, software, short-term and long term memory, and attention. \n\nWe'll start with a short exploration of some foundational concepts related to perception in @sec-cognition-perception. \n@sec-design-process will discuss the design process and how to leverage the grammar of graphics to provide both the full data and visual summaries that highlight key features. \nWhere available, this section incorporates conclusions from empirical studies of charts and graphs to guide design decisions.  \n@sec-annotation expands on this discussion, demonstrating effective use of annotations to provide contextual information that can assist viewers with the interpretation of the data.\nFinally, @sec-checklist provides a guide to evaluating graphics for clarity, effectiveness, accessibility, and common design pitfalls. \n\n\n## Cognitive and Perceptual Foundations {#sec-cognition-perception}\n\nBefore we discuss how to create good charts, there is a certain amount of background information that must be considered.\nCharts make use of the visual system within the human brain, which means we need to understand some basic attributes of human perception and cognition in order to make the best use of this \"wetware\" [@wikipediacontributorsWetwareBrain2025] processing power. \n\n\n<!-- Basic overview of components of the visual system - eye, optic nerve, processing centers of the brain, visual cortex (hardware) and software -->\n\nFirst, let's set the stage. \nInformation in the form of light bounces off objects in the world and lands on our retina (there are lenses and focusing mechanisms that we'll skip). \nThere are four types of light detectors in the retina: three types of cones that respond to red, green, and blue light wavelengths, and rods, which respond to light intensity across wavelengths. Cones are concentrated in one area, while rods are spread across the surface of the retina. \nThe rods and cones turn light into neural impulses, which are transmitted along the optic nerve to the **visual cortex** located in the back of the brain (roughly where your head would hit the floor when you are lying down).\nThe visual cortex contains special neurons called feature detectors which organize the information from the retina and reconstruct this information into a mental representation of the world. \nSome feature detectors respond to specific angles, signals from specific parts of the retina corresponding to specific parts of the outside world, and many other low-level features. \nSignals from these feature detectors are then aggregated into higher-level concepts that form our visual experience of the world.\n\nThe initial light signals and lower-level information are sometimes called \"sensation\", and the ability to detect higher-level concepts is called \"perception\". We can also think of \"top-down\" perception, where our experience shapes what we perceive and how we experience the world, compared to \"bottom-up\" perception, where we construct higher-level concepts solely from lower-level signals. \n\nPerception tends to require a few other mental resources beyond the visual detection and processing equipment (eyes, visual cortex, etc.): attention and memory (short and long-term) are vital for processing the visual input and making sense out of it.\nThe next few subsections provide specific examples of why it's important to understand the basics of the visual system when thinking about how to construct charts and graphs. \n\n\n### Color\n\nOur eyes are optimized for perceiving the yellow/green region of the color spectrum, as shown in @fig-sensitivity. \nWhy? Well, our sun produces yellow light, and plants tend to be green. \nIt's pretty important to be able to distinguish different shades of green (evolutionarily speaking) because it impacts your ability to feed yourself. \nThere aren't that many purple or blue predators, so there is less selection pressure to improve perception of that part of the visual spectrum.\n\n![Sensitivity of the human eye to different wavelengths of visual light (Image from [Wikimedia commons](https://upload.wikimedia.org/wikipedia/commons/c/c0/Eyesensitivity.svg))](../images/wrangling/Eyesensitivity.png){#fig-sensitivity fig-alt=\"The image is a graph illustrating eye color sensitivity in relation to the visible light spectrum, from around 400 to 700 nanometers. It features a large, smooth bell curve with a peak in the green wavelength range, indicating maximum sensitivity. The spectrum is displayed as a gradient, transitioning smoothly from violet on the left to red on the right. The vertical axis shows percentage sensitivity from 0 to 100, marked at intervals of 10.\" width=\"50%\"}\n\n\nNot everyone perceives color in the same way. Some individuals are [colorblind or color deficient](https://en.wikipedia.org/wiki/Color_blindness) [@wikipediacontributors23c]. \nWe have 3 cones used for color detection, as well as cells called rods, which detect light intensity (brightness/darkness). \nIn about 5% of the population (10% of XY individuals, 0.2% of XX individuals), one or more of the cones may be missing or malformed, leading to color blindness - a reduced ability to perceive different shades. \nThe rods, however, function normally in almost all of the population, which means that light/dark contrasts are extremely safe, while contrasts based on the hue of the color are problematic in some instances.\n\n:::: {.callout collapse=true}\n#### Demo: Types of Colorblindness {-}\n\nSimulations of the same rainbow color scheme map under different types of colorblindness, generated using [CoBliS](https://www.color-blindness.com/coblis-color-blindness-simulator/). While colorblindness simulations can be useful, as colorblindness is a result of one of many different mutations, simulators do not cover all of the different color vision mutations which exist. \n\n::: {layout=\"[[-.25, 1, -0.25],[1,1,1],[1,1,1]]\"}\n\n![Original (Normal Color Vision)](../images/wrangling/evapotranspiration-map.jpg){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-normal}\n\n![Protanomaly (Weak red vision)](../images/wrangling/evapotranspiration-map-protanomaly.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-protanomaly}\n\n\n![Deuteranomaly (Weak green vision)](../images/wrangling/evapotranspiration-map-deuteranomaly.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-deuteranomaly}\n\n![Tritanomaly (Weak blue vision)](../images/wrangling/evapotranspiration-map-tritanomaly.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-tritanomaly}\n\n\n![Protanopia (No red cone)](../images/wrangling/evapotranspiration-map-protanopia.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-protanopia}\n\n![Deuteranopia (No green cone)](../images/wrangling/evapotranspiration-map-deuteranopia.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-deuteranopia}\n\n![Tritanopia (No blue cone)](../images/wrangling/evapotranspiration-map-tritanopia.png){fig-alt=\"The image is a detailed map of the contiguous United States highlighting the estimated fraction of precipitation lost to evapotranspiration from 1971 to 2000. The map is divided into multicolored geographic blocks representing different evapotranspiration ratios. Colors range from purple, signifying a ratio of 0.0 to 0.09, to red, representing a ratio of 1.2 to 1.29. The western part of the country predominantly features warmer colors like yellow and orange, indicating higher evapotranspiration ratios, whereas the eastern part is depicted mostly in cooler colors such as blue and green, showing lower ratios. The map includes a legend on the bottom left, providing a key for understanding the color-coded ratios.\" #fig-colorblind-map-tritanopia}\n\n:::\n\n::::\n\n::: {.callout-note collapse=true}\n\n#### Colorblindness Testing\nYou can take a test designed to screen for colorblindness [here](https://eyeque.com/color-blind-test/). \nYour monitor may affect how you score on these tests - I am colorblind, but on some monitors, I can pass the test, and on some, I perform worse than normal. \nA different test is available [here](https://www.color-blindness.com/farnsworth-munsell-100-hue-color-vision-test/).\n\n::: {layout-ncol=3}\n![My results on one monitor](../images/wrangling/colorblindness_monitorLG.png){.lightbox fig-alt=\"Colorblindness test results: Various color deficiencies. Reports low deuteranopia/anomaly, no protanopia/anomaly and low tritanopia/anomaly.\"} \n\n![My results on a monitor that has a different tech and supposedly higher color fidelity](../images/wrangling/colorblindness_monitorDell.png){.lightbox fig-alt=\"Colorblindness test results: Various color deficiencies. Reports no deuteranopia/anomaly, and low protanopia/anomaly and tritanopia/anomaly.\"}\n\n![The Munsell colorblindness test](../images/wrangling/colorblind_munsell.png){.lightbox fig-alt=\"The image shows an interface of the Farnsworth-Munsell 100 Hue Color Vision Test. At the top are navigation tabs labeled: Introduction, Instructions, Test Score, Interpretation, and Comparison Group. Below the tabs, on the left, is a circular graph called the Personal Error Score Diagram. It features a central circle with grid lines radiating outward. The circle is surrounded by a ring of smaller colored circles, forming a gradient that transitions through various hues. A thick black line traces the perimeter of the central circle, indicating score errors in different segments. The colors range from red, yellow, green, and blue. Significant error points are highlighted on the chart, and a large section in purple is shaded to indicate potential color confusion. To the right, explanatory text describes the test results, with sections titled: Personal Error Score Diagram, Your Total Error Score (TES): 72, and Typical Confusion Areas. Below this, there is a multiple-choice section with options to indicate different types of color blindness, including Red-Blind (protan), Green-Blind (deutan), and Blue-Blind (tritan), with the Blue-Blind option selected.\"}\n:::\n\n\nIn reality, I know that I have issues with perceiving some shades of red, green, and brown. I have particular trouble with very dark or very light colors, especially when they are close to grey or brown.\n\n:::\n\n\nIn addition to colorblindness, there are other factors than the actual color value which are important in how we experience color, such as context.\n\n\n\n\n\n\n\n::: {#fig-checker-shadow .cell layout=\"[[-10, 30, -20, 20, -10]]\"}\n::: {.cell-output-display}\n![The original illusion](../images/wrangling/CheckerShadow.png){#fig-checker-shadow-1 width=100%}\n:::\n\n::: {.cell-output-display}\n![The illusion with the checkerboard and shadow removed](../images/wrangling/CheckerShadow2.png){#fig-checker-shadow-2 width=100%}\n:::\n\nThe color constancy illusion. The squares marked A and B are actually the same color.\n:::\n\n\n\n\n\nOur brains are extremely dependent on context and make excellent use of the large amounts of experience we have with the real world. \nAs a result, we implicitly \"remove\" the effect of things like shadows as we make sense of the input to the visual system. \nThis can result in odd things, like the checkerboard and shadow shown in @fig-checker-shadow - because the brain automatically corrects for the shadow, B looks lighter than A, even though when the context is removed they are clearly the same shade.\n\n#### Takeaways {-}\n\n- Do not use rainbow color gradient schemes \n    - because of the unequal perception of different wavelengths, these schemes are *misleading* - the color distance does not match the perceptual distance.\n- Avoid any scheme that uses green-yellow-red signaling if you have a target audience that may include colorblind people.\n- To \"colorblind-proof\" a graphic:\n    - double encoding - where you use color, use another aesthetic (line type, shape) as well to help your colorblind readers out\n    - If you can print your chart out in black and white and still read it, it will be safe for colorblind users. This is the only foolproof way to do it!\n    - If you are using a color gradient, use a **monochromatic color scheme** where possible. This is perceived as light -\\> dark by colorblind people, so it will be correctly perceived no matter what color you use.\n    - If you have a **bidirectional scale** (e.g. showing positive and negative values), the safest scheme to use is purple - white - orange. In any color scale that is multi-hue, it is important to transition through white, instead of from one color to another directly.\n\n- Be conscious of what certain colors \"mean\"\n    - Leveraging common associations can make it easier to read a color scale and remember what it stands for\n        - blue for cold, orange/red for hot is a natural scale\n        - red = Republican and blue = Democrat in the US (since ~1980)\n        - white -\\> blue gradients for showing rainfall totals\n    - Some colors can can provoke emotional responses that may not be desirable.[^10-graphics-2]\n    - Consider the social baggage that certain color schemes may have\n        - pink/blue color scheme often used for gender may be polarizing\n        - Consider using a cooler color (blue or purple) for men and a warmer color (yellow, orange, lighter green) for women[^10-graphics-3].\n        \n- There are packages such as `RColorBrewer` and `dichromat` that have color palettes which are aesthetically pleasing, and, in many cases, colorblind friendly (`dichromat` is better for that than `RColorBrewer`). You can also take a look at other [ways to find nice color palettes](https://lisacharlotterost.de/2016/04/22/Colors-for-DataVis/).\n\n[^10-graphics-2]: When the COVID-19 outbreak started, many maps were using white-to-red gradients to show case counts and/or deaths. [The emotional association between red and blood, danger, and death may have caused people to become more frightened than what was reasonable given the available information.](https://www.esri.com/arcgis-blog/products/product/mapping/mapping-coronavirus-responsibly/)\n\n[^10-graphics-3]: Lisa Charlotte Rost. [What to consider when choosing colors for data visualization.](https://www.dataquest.io/blog/what-to-consider-when-choosing-colors-for-data-visualization/)\n\n### Preattentive Features\n\nYou've almost certainly noticed that some graphical tasks are easier than others. \nPart of the reason for this is that certain tasks require active engagement and attention to search through the visual stimulus; others, however, just \"pop\" out of the background.\nWe call these features that just \"pop\" without active work **preattentive** features; technically, they are detected within the first 250ms of viewing a stimulus [@treisman_preattentive_1985].\n\nTake a look at @fig-preattentive1; can you spot the point that is different?\n\n\n\n\n\n::: {#fig-preattentive1 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape](02c-good-graphics_files/figure-html/fig-preattentive1-1.png){#fig-preattentive1-1 width=1200}\n:::\n\n::: {.cell-output-display}\n![Color](02c-good-graphics_files/figure-html/fig-preattentive1-2.png){#fig-preattentive1-2 width=1200}\n:::\n\nTwo scatterplots with one point that is different. Can you easily spot the different point?\n:::\n\n\n\n\n\nColor and shape are commonly used graphical features that are processed pre-attentively. \nSome people suggest utilizing this to pack more dimensions into multivariate visualizations [@healey_high-speed_1996], but in general, knowing which features are processed more quickly (color/shape) and which are processed more slowly (combinations of preattentively processed features) allows you to design a chart that requires less cognitive effort to read.\n\nAs awesome as it is to be able to use preattentive features to process information, we cannot use combinations of preattentive features to show different variables - these combinations are no longer processed preattentively. \nTake a look at @fig-preattentive2 - part (a) shows the same grouping in color and shape, part (b) shows color and shape used to encode different variables. \n\n\n\n\n\n::: {#fig-preattentive2 .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Shape and Color (dual encoded)](02c-good-graphics_files/figure-html/fig-preattentive2-1.png){#fig-preattentive2-1 width=1200}\n:::\n\n::: {.cell-output-display}\n![Shape and Color (different variables)](02c-good-graphics_files/figure-html/fig-preattentive2-2.png){#fig-preattentive2-2 width=1200}\n:::\n\nTwo scatterplots. Can you easily spot the different point(s)?\n:::\n\n\n\n\n\nHere, it is easy to differentiate the points in @fig-preattentive2(a), because they are dual-encoded. However, it is very difficult to pick out the different groups of points in @fig-preattentive2(b) because the combination of preattentive features requires active attention to sort out.\n\n#### Takeaways {-}\n\nCareful use of preattentive features can reduce the cognitive effort required for viewers to perceive a chart. \n\nEncode only one variable using preattentive features, as combinations of preattentive features are not processed preattentively.\n\n\n### Short Term Memory\n\nWe have a limited amount of memory that we can instantaneously utilize. \nThis mental space, called **short-term memory**, holds information for active use, but only for a limited amount of time.\n\n:::: example\n#### Try it out! {-}\n\n::: {.callout collapse=true}\n##### Click here, read the information, and then click to hide it. {-}\n\n1 4 2 2 3 9 8 0 7 8\n:::\n\n::: {.callout collapse=true}\n##### Wait a few seconds, then expand this section {-}\n\nWhat was the third number?\n:::\n\n::::\n\nWithout rehearsing the information (repeating it over and over to yourself), the try it out task may have been challenging. \nShort term memory has a capacity of between 3 and 9 \"bits\" of information.\n\nIn charts and graphs, short term memory is important because we need to be able to associate information from e.g. a key, legend, or caption with information plotted on the graph. \nIf you try to plot more than \\~6 categories of information, your reader will have to shift between the legend and the graph repeatedly, increasing the amount of cognitive labor required to digest the information in the chart.\n\nWhere possible, try to keep your legends to 6 or 7 characteristics.\n\n\n#### Takeaways {-}\n\n-   Limit the number of categories in your legends to minimize the short term memory demands on your reader.\n\n    -   When using continuous color schemes, you may want to use a log scale to better show differences in value across orders of magnitude.\n\n-   Use colors and symbols which have implicit meaning to minimize the need to refer to the legend.\n\n-   Add annotations on the plot, where possible, to reduce the need to re-read captions.\n\n### Grouping and Sense-making\n\nThe catchphrase of Gestalt psychology is\n\n> The whole is greater than the sum of the parts\n\nThat is, what we perceive and the meaning we derive from the visual scene is more than the individual components of that visual scene.\n\nOur brains have to be very good at imposing order on visual chaos -- there is a *huge* amount of information being processed by the visual system all the time, and some basic heuristics (guesses/shortcuts) are important in this process. \n\nWhen we create charts, it becomes important to understand these heuristics so that we can make it easier for people to understand the data. \nWorking with the natural sense making algorithms in the brain requires less cognitive effort, which leaves more space for thinking about the data. \n\nLet's start with a few examples that show how the brain constructs meaning from ambiguous or conflicting stimuli. \n\n:::: demo\n#### Demo: Constructing Visual Meaning\n\n::: panel-tabset\n##### Ambiguous Image {.unnumbered}\n\nWhat does @fig-rabbit-duck look like to you?\n\n![Is it a rabbit, or a duck?](../images/wrangling/duckrabbit.png){#fig-rabbit-duck width=\"50%\" fig-alt=\"An ambiguous image: when viewed from the right side, it looks like a duck, and when viewed from the bottom side, it looks like a rabbit. The x and y axes are labeled as 'rabbit' and 'duck', respectively.\"}\n\nWhen faced with ambiguity, our brains use available context and past experience to try to tip the balance between alternate interpretations of an image. \nWhen there is still some ambiguity, many times the brain will just decide to interpret an image as one of the possible options.\nSometimes, the brain will even flip between the possible options, as in the [Necker cube](https://en.wikipedia.org/wiki/Necker_cube) illusion. \n\n##### Illusory Contours {.unnumbered}\n\n![Consider this image - what do you see?](../images/wrangling/IllusoryContour.png){fig-alt=\"An Illusory contour. It appears to be 3 black circles arranged in a downward-pointing triangle, with a black outline of a triangle pointing upward, and a background-colored (white) downward pointing triangle overlaid on top of the two previously described triangles. In reality, what is shown is a sequence of three pac-man shapes, with the missing pieces oriented inwards, at approximately 30, 150, and 270 degrees from the positive x-axis, with three 60 degree acute angle shapes oriented at 90, 210, and 330 degrees from the positive x-axis. The appearance of two triangles superimposed is an illusory contour that results from Gestalt heuristics.\" width=\"30%\" }\n\nDid you see something like \"3 circles, a triangle with a black outline, and a white triangle on top of that\"? \nIn reality, there are 3 angles and 3 pac-man shapes. \nBut, it's much more likely that we're seeing layers of information, where some of the information is obscured (like the \"mouth\" of the pac-man circles, or the middle segment of each side of the triangle). \nThis explanation is simpler, and more consistent with our experience.\n\nThis illusory contour image is closely related to the Gestalt concepts of closure and \"good figure\". \n\n##### Figure/Ground {.unnumbered}\n\nConsider the logo for the Pittsburgh Zoo.\n\n![](../images/wrangling/Pittsburgh_Zoo_logo.png){fig-alt=\"The logo of the Pittsburgh Zoo, which manipulates figure-ground perception. If the black portion of the image is considered the figure, the viewer sees a tree and some birds flying; if the white portion of the image is considered the figure, then the viewer sees a gorilla facing a lion, with some fish jumping above the waves at the bottom of the image. When viewed for several minutes, the figure and ground tend to 'flip' back and forth.\" width=\"50%\"}\n\nDo you see the gorilla and lionness? \nOr do you see a tree? \nHere, we're not entirely sure which part of the image is the figure and which is the background.\n\nOne of the first tasks we have when confronted with a visual scene is to separate the important part of the image (the figure) from the background. \nIn most cases this is straightforward, but occasionally, artificial images (as opposed to real world scenes) can be hard to interpret. \nThe zoo logo shown above leverages this ambiguity to capture your visual attention. \n\n:::\n\nThe ambiguous figures shown above demonstrate that our brains are actively imposing order upon the visual stimuli we encounter. \n::::\n\n\nThe Gestalt heuristics attempt to explain how our brains group and order visual stimuli to make sense of the world. \nYou can read about the gestalt rules [here](https://en.wikipedia.org/wiki/Principles_of_grouping), but they are also demonstrated in @fig-gestalt-summary.\n\n![The Gestalt Heuristics help us to impose order on ambiguous visual stimuli.](../images/wrangling/gestalt.jpg){fig-alt=\"The word GESTALT, written such that there is a white bar over the G, illustrating the principle of closure, the E is made up of black squares, indicating proximity, the S has a bar going through it such that the middle part of the S is behind the bar, illustrating continuation, the Ts are both striped, illustrating similarity, and the A and L are smushed together, with a tree appearing within the A (the bar is missing across the A) to illustrate figure/ground.\" #fig-gestalt-summary}\n\nIn graphics, we make use of the Gestalt principles of grouping to create order and meaning. \nIf we color points by another variable, we are creating groups of similar points which assist with the perception of groups instead of individual observations. \nIf we add a trend line, we create the perception that the points are moving \"with\" the line (in most cases), or occasionally, that the line is dividing up two groups of points. \nDepending on what features of the data you wish to emphasize, you might choose different aesthetics mappings, facet variables, and factor orders.\n\n:::: demo\n#### Demo: Grouping and Geometries {-}\n\nSuppose I want to emphasize the change in life expectancy between 1982 and 2007. \nFor this, we'll use the Gapminder [@gapminder] data which is found in the `gapminder` packages in R and python. \n\n::: panel-tabset\n##### R {.unnumbered}\n\n\n\n\n::: {#fig-emphasis-gapminder-r .cell layout-ncol=\"3\" lightbox='true'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nlibrary(gapminder)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ngapminder %>%\n  filter(year %in% c(1982, 2007)) %>%\n  filter(country %in% c(\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\")) %>%\n  ggplot(aes(x = country, y = lifeExp, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  ylab(\"Life Expectancy\")\n\ngapminder %>%\n  filter(year %in% c(1982, 2007)) %>%\n  filter(country %in% c(\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\")) %>%\n  ggplot(aes(x = year, y = lifeExp, color = country)) +\n  geom_line() +\n  ylab(\"Life Expectancy\")\n\ngapminder |>\n  filter(year %in% c(1982, 2007)) |>\n  ggplot(aes(x = factor(year), y = lifeExp)) + \n  geom_boxplot() + \n  ylab(\"Life Expectancy\")\n\n```\n\n::: {.cell-output-display}\n![A bar chart allows comparisons of change over time for each country as well as cross-country comparisons.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-r-1.png){#fig-emphasis-gapminder-r-1 width=1200}\n:::\n\n::: {.cell-output-display}\n![A line chart centers changes over time for each country.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-r-2.png){#fig-emphasis-gapminder-r-2 width=1200}\n:::\n\n::: {.cell-output-display}\n![A boxplot shows overall change in aggregate over time, but does not show individual country data.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-r-3.png){#fig-emphasis-gapminder-r-3 width=1200}\n:::\n\nThree different charts created from the same data. Which one best demonstrates that in every country, the life expectancy increased between 1982 and 2007?\n:::\n\n\n\n\n##### Python {.unnumbered}\n\n\n\n\n\n::: {#fig-emphasis-gapminder-py .cell layout-ncol=\"3\" lightbox='true'}\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# %pip install gapminder\nfrom gapminder import gapminder\nimport pandas as pd\nimport seaborn as sns\nimport seaborn.objects as so\nimport matplotlib.pyplot as plt # to clear plots\n\nmy_gap = gapminder.query('year.isin([1982,2007])')\nmy_gap = my_gap.query('country.isin([\"Korea, Rep.\", \"China\", \"Afghanistan\", \"India\"])')\nmy_gap = my_gap.assign(yearFactor=pd.Categorical(my_gap.year))\n\nplot = so.Plot(my_gap, x = \"country\", y = \"lifeExp\", color = \"yearFactor\").\\\n  add(so.Bar(), so.Dodge()).\\\n  label(y = \"Life Expectancy\")\nplot.show()\n```\n\n::: {.cell-output-display}\n![A bar chart allows comparisons of change over time for each country as well as cross-country comparisons.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-py-1.png){#fig-emphasis-gapminder-py-1 width=614}\n:::\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nplt.clf() # Clear plot workspace\n\nplot = so.Plot(my_gap, x = \"year\", y = \"lifeExp\", color = \"country\").\\\n  add(so.Lines()).\\\n  label(y = \"Life Expectancy\")\nplot.show()\n```\n\n::: {.cell-output-display}\n![A line chart centers changes over time for each country.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-py-2.png){#fig-emphasis-gapminder-py-2 width=614}\n:::\n\n```{.python .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nplt.clf()  # Clear plot workspace\n\nsns.boxplot(data = my_gap, x = \"year\", y = \"lifeExp\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![A boxplot shows overall change in aggregate over time, but does not show individual country data.](02c-good-graphics_files/figure-html/fig-emphasis-gapminder-py-3.png){#fig-emphasis-gapminder-py-3 width=384}\n:::\n\nThree different charts created from the same data. Which one best demonstrates that in every country, the life expectancy increased between 1982 and 2007?\n:::\n\n\n\n\n\n:::\n\n\nIf the goal is to emphasize that every single country had an increase in life expectancy over the period, the best chart is the line chart - we can see upward slopes for each country leading to the conclusion that life expectancy increased. \nThis leverages the Gestalt principles of \"similarity\" and \"common fate\". Similarity, in that all lines point in the same direction, and common fate (often used for motion, e.g. a flock of birds are a group because they move together) because the lines are all \"moving together\". \n\nWe can derive the same information from the bar chart, but we have to work a bit more for it, because we naturally group bars together by country (proximity) and by year (similarity). \nWe have to then notice that the 2007 bar is bigger for each country to come to the same conclusion -- this takes a bit more cognitive effort.\n\nWe cannot get the specifics from the box plot, because we cannot see individual country data. \nThis is a case where a summary statistic actually destroys the conclusion we might want to draw from the data and leaves us with weaker information - we can see that there is an increase in the minimum, median, and maximum life expectancy, but it is possible to have this and still have a single-country decrease in life expectancy, so we cannot draw the same conclusion from the box plot that we can from the bar or line charts. \n\n\n::::\n\nThe geometric mappings and aesthetic choices you make when creating plots have a huge impact on the conclusions that you (and others) can easily make when examining plots.\nChoosing the wrong geometry or statistic can obscure the point you want to make using the data, leading your reader to draw a conclusion that is unsupported, less important, or misleading. \n\nOn the other hand, using aesthetic mappings to highlight information can ensure that viewers see the important information you're trying to communicate [^10-graphics-4], and can even tilt the balance when two equally valid conclusions are present in a chart. \nThis power should be used responsibly. \n\n[^10-graphics-4]: See [this paper](https://doi.org/10.1080/10618600.2016.1209116) for more details. This is the last chapter of my dissertation, for what it's worth. It was a lot of fun. (no sarcasm, seriously, it was fun!)\n\n\n:::: demo\n\n#### Demo: Facets and Grouping {-}\n\nWhen creating a visualization that involves many different (usually categorical) variables, it is important to decide which variable is the **primary** comparison of interest. \nThis variable is the one which should be shown in the most easily comparable way -- usually, directly on the same plot. \n\nLet's look at the palmerpenguins data. We have several categorical variables: `species`, `island`, `year` (technically numerical, but there are only 3 years), and `sex`. \nThe most interesting part of this data set is how the morphology (measurements) of penguins changes based on their sex and species, so let's explore what different charts examining `bill_len` and `body_mass` might look like across those variables. \nFor this example, I'll drop penguins with an unidentified sex for visual simplicity. \n\n\n\n\n\n::: {#fig-palmer-penguins-facets .cell layout=\"[[-1,2,-1],[1,1]]\" lightbox='{\"group\":\"penguins-facets\"}'}\n::: {.cell-output-display}\n![This plot uses shape, color, and linetype to distinguish the different groups. It's cluttered, but it is possible to make comparisons across species and sex](02c-good-graphics_files/figure-html/fig-palmer-penguins-facets-7.png){#fig-palmer-penguins-facets-1 width=2100}\n:::\n\n::: {.cell-output-display}\n![This plot facets by species, allowing the user to make easy comparisons across sex for each species separately. Cross species comparisons are somewhat more difficult in this plot because the viewer must shift back and forth between panels.](02c-good-graphics_files/figure-html/fig-palmer-penguins-facets-8.png){#fig-palmer-penguins-facets-2 width=2100}\n:::\n\n::: {.cell-output-display}\n![This plot facets by sex, allowing the user to make easy judgments about the effect of species on measurements. Comparisons between sexes must be made across panels, and require more cognitive effort.](02c-good-graphics_files/figure-html/fig-palmer-penguins-facets-9.png){#fig-palmer-penguins-facets-3 width=2100}\n:::\n\nThree views of the palmerpenguins data comparing bill_len and body_mass across sex and species. Click on figures to enlarge.\n:::\n\n\n\n\n\nWhich plot makes it easier to answer the following questions:\n\n- Which species of penguin has the most overlap between the size of males and females?\n- Which species of penguin is the most physically different across both males and females?\n- What is the overall relationship across species for the size of males vs. females?\n\nDifferent aesthetic mappings and facets can lead to different overall conclusions from the same data. \nIt is important when you are exploring data to generate many different plots, so that you get a more comprehensive picture of your data. \nWhen you want to explain the data to others, it is equally important to carefully choose the most important findings from the data and present charts that back up those findings. \n\n::::\n\n\n## Designing Good Graphics Using the Grammar {#sec-design-process}\n\n### Representing Data Accurately\n\nIn order to read data off of a chart correctly, several things must happen in sequence:\n\n1. The data must be accurately written to the chart, that is, the transformation from data -> geometry must be accurate\n2. The geometric objects that make up the chart must be perceived accurately - the mapping from geometric object size or location to mental model of geometric object size or location must be correct.\n3. The mental model of geometric object size or location must be accurately converted to a numerical value. We know that this isn't lossless, but we hope that this is at least reasonably accurate. \n\nIf step 1 is not done correctly, the chart is misleading or inaccurate. \nHowever, steps 2 and 3 depend on our brains accurately **perceiving** and **estimating** information mentally. \nThese steps can involve a lot of effort, and as mental effort increases, we tend to take shortcuts. \nSometimes, these shortcuts work well, but not always.\n\nWhen you design a chart, it's good to consider what mental tasks viewers of your chart need to perform. \nThen, ask yourself whether there is an equivalent way to represent the data that requires fewer mental operations, or a different representation that requires **easier** mental calculations.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Which of the lines is the longest? Shortest? It is much easier to determine the relative length of the line when the ends are aligned. The three lines have the same length in both panels, but the operation is much more difficult when the lines do not start or end at the same place.](02c-good-graphics_files/figure-html/accuracy-guidelines-1.png){fig-alt='A chart with two panels. The left panel is labeled \\'Aligned scale\\' and features three lines of different lengths which all start at the bottom of the chart. The right panel is labeled \\'Unaligned scale\\' and features three lines of different lengths which start at different locations.  It is easier to compare the lengths of the lines in the left panel, since they all start in the same place.' width=75%}\n:::\n:::\n\n\n\n\n\nWhen making judgments corresponding to numerical quantities, there is an order of tasks from easiest (1) to hardest (6), with equivalent tasks at the same level. \nSee [this paper](https://www.doi.org/10.2307/2288400) for the major source of this ranking; other follow-up studies have been integrated, but the essential order is largely unchanged.\n\n\n1.  Position (common scale)\n2.  Position (non-aligned scale)\n3.  Length, Direction, Angle, Slope\n4.  Area\n5.  Volume, Density, Curvature\n6.  Shading, Color Saturation, Color Hue\n\n\nIf we compare a pie chart and a stacked bar chart, the bar chart asks readers to make judgments of position on a non-aligned scale, while a pie chart asks readers to assess angle.\nThis is one reason why pie charts tend not to be a good general option -- people must compare values using area or angle instead of position or length, which is a more difficult judgment under most circumstances. \nWhen there are a limited number of categories (2-4) and you have data that is easily compared to quarters of a circle, it may be justifiable to use a pie chart over a stacked bar chart - some studies have shown that pie charts are preferable under these conditions. \nAs a general rule, though, we have an easier time comparing position than angle or area. \n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Stacked bar chart](02c-good-graphics_files/figure-html/pie-vs-bar-1.png){fig-alt='A stacked bar chart showing the proportion of people living in North America by country' width=1200}\n:::\n\n::: {.cell-output-display}\n![Pie chart](02c-good-graphics_files/figure-html/pie-vs-bar-2.png){fig-alt='A pie chart showing the proportion of people living in North America by country' width=1200}\n:::\n\nStacked bar and pie charts showing the relative proportion of people in North America living in the US, Canada, and Mexico in 2007. Which chart is easier to read relative information (e.g. there are about 3x as many people living in Mexico as Canada) from? Which chart is easier to estimate raw proportions (e.g. the US makes up about 70% of the population of North America) from?\n:::\n\n\n\n\n\n\n\nWhen creating a chart, it is helpful to consider which variables you want to show, and how accurate reader perception needs to be to get useful information from the chart. \nIn many cases, less is more - you can easily overload someone, which may keep them from engaging with your chart at all.\nVariables which require the reader to notice small changes should be shown on position scales (x, y) rather than using color, alpha blending, etc.\n\nConsider the hierarchy of graphical tasks again.\nYou may notice a general increase in dimensionality from 1-3 to 4 (2d) to 5 (3d). \nIn general, showing information in 3 dimensions when 2 will suffice can be misleading. \nJust *how* misleading depends a lot on the type of chart you're using.\nMost of the time, the addition of an extra dimension causes an increase in chart area allocated to the item that is disproportionate to the actual numerical value being represented.\n\n\n\n\n\n\n\n\n\n\n\n![Here, the area and height both encode the same variable, leading to a far disproportionate number of pixels allocated to \"Stocks\" than \"Cash Investments\" (h/t Junk Charts). In the first chart, stocks make up 60% of the portfolio, but have 67.5% of the pixels; Cash makes up 5% of the portfolio but those investments represent 2.3% of the pixels.](../images/wrangling/3d_graphs_suck.jpg){#fig-disproportionate-pixels fig-alt=\"A three-dimensional pie chart, where each of the sections has a different height - this seems to double-encode the value represented by the angle of the pie slice. As a result, the area of the chart devoted to one sector is vastly larger than the area of the chart devoted to the other sectors, even though the true values are not nearly so different.\"}\n\nExtra dimensions and other annotations are sometimes called \"chartjunk\" and should only be used if they contribute to the overall numerical accuracy of the chart (e.g. they should not just be for decoration).\n\n::: column-margin\n\n\n\n\n\n{{< video https://youtu.be/E91bGT9BjYk title=\"Ted ED: How to spot a misleading graph - Lea Gaslowitz\" >}}\n\n\n\n\n\n\n\n\n[Business Insider: The Worst Graphs Ever](https://www.businessinsider.com/the-27-worst-charts-of-all-time-2013-6)\n\n:::\n\n### Show the Data\n\nTODO: Example showing the importance of raw data and how to add summary statistics to show model results on top of the raw data. \n\n## Evaluating Graphics: Effectiveness, Clarity, and Comprehension {#sec-checklist}\n\nWhen evaluating a chart that you hope to use for presentation, it is important to first think through what the goal of the chart is. \nThen, it can be helpful to work through the grammar of graphics to ensure that each element of the chart contributes to the overall goal. \n\n\n1. Message\n  - What is the message you hope to convey?\n  - What elements of the data are necessary for that message?\n  - What level of audience are you targeting? What education, expectations, culture, and perceptual abilities or challenges do they have?\n\n2. Mappings\n  - [ ] Are mappings appropriate for the type of variable? \n  - [ ] Do the $x$ and $y$ mappings show variables that are most important for accurate quantitative comparisons?\n  - [ ] Are aesthetic mappings carefully chosen to minimize clutter?\n  - [ ] Are aesthetic mappings chosen for accessibility? If color is used, is another aesthetic also used to dual-encode the information?\n\n3. Geometries\n  - [ ] Are appropriate geoms used for the data type and comparison goals?\n  - [ ] If there are multiple layers, \n      - [ ] Do the layers work together to show the same aspects of the data at different levels? \n      - [ ] Do layers enhance clarity, or increase clutter?\n  - [ ] Are key patterns visible?\n\n4. Scales and Transformations\n  - Location scales\n    - [ ] Is the data well distributed across the full range of the scale? \n        - If most of the data is compressed into a small part of the scale consider a scale transformation (log, sqrt) or a plot-within-a-plot (`ggpp`) to show both the compressed area and the total range. \n    - [ ] If the $x$ and $y$ axis scales show the same units, does the aspect ratio of the plot reflect this?\n  - Color scales\n    - [ ] Is the color scale used the most accessible scale for the data? \n    - [ ] If color is mapped to a continuous value, is the scale transformed to maximize the contrast across the range of the variable? Log transforms can often be useful to increase contrast between different orders of magnitude of a continuous value. \n  - Transformations\n    - [ ] Are any transformations used clearly identified? e.g. a log scale should have ticks that are not uniformly spaced to provide an additional cue that the transformation is present.\n    - [ ] Are transformed elements labeled clearly?\n    - [ ] Does the transformation improve comprehension?\n  - Coordinate Systems\n    - [ ] Is the coordinate system appropriate for the message? If polar coordinates are used, is there a clear justification for deviating from better-understood cartesian coordinates?\n\n5. Facets and Layout\n  - [ ] Does the layout support the comparisons of interest? Are facets that viewers may want to compare ordered so that they are adjacent?\n  - [ ] How much effort is required to make secondary comparisons? Consider visual distance traveled between elements in the secondary comparison, alignment of axes, etc. \n  - [ ] Are there too many facets shown? How does the number of facets required for the comparison compare to the overall increase in visual clutter?\n  - [ ] Are facet labels clear and easy to understand?\n\n6. Annotations\n  - [ ] Are key points annotated clearly?\n  - [ ] Do annotations reduce clutter?\n  - [ ] Would it be more effective to replace legends with on-plot labels, or would this increase visual clutter?\n  - [ ] Does the design support the overall message of the plot?\n  - [ ] Are artifacts in the data annotated and explained?\n  \n\n## References {#sec-good-graphics-refs}\n",
    "supporting": [
      "02c-good-graphics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}