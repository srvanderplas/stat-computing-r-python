{
  "hash": "3c75797a7d2de8dd3bbed3016cc78063",
  "result": {
    "engine": "knitr",
    "markdown": "# Working with Strings {#sec-strings}\n\nOne of the most common types of \"messy\" data involves strings. \nIf the data is input by humans, well, ... we suck at spelling [@norvigHowWriteSpelling2007], typing, and data input, so... it's going to be messy.\nBut, another type of messy data involves situations where multiple variables are stored in the same column, or where the same variable is stored across two different columns. \nUsually, when this type of messy data occurs, the data is stored in a string/character variable.\n\nThis chapter will teach you how to work with both messy spelling/data entry and multiple values in a single string, but we'll focus on the second - you'll learn the tools to handle the first case along the way.\n\n## Objectives {-}\n\n- Use functions to perform find-and-replace operations\n- Use functions to split string data into multiple columns/variables\n- Use functions to join string data from multiple columns/variables into a single column/variable\n\n![Perhaps one day you'll be able to put this knowledge to use in a practical setting!](../images/wrangling/string_processing_starbucks.jpeg){fig-alt=\"A sign at a bar/coffee shop that says '// If you can read this code, tell your bartender the secret word of the day for a free drink on us'. 'var your_drink;' 'var reverse = function(s) { return s.split('').reverse().join('');' var bartender = { str 1: 'ers', str 2: reverse('rap'), str3: 'amet', request: function(preference) {return preference + '.Secret word:' + this.str2 + this.str3 + this.str1;}};' 'bartender.request(your_drink);'\" width=\"50%\"}\n\n## Basic Operations\n\nNearly always, when multiple variables are stored in a single column, they are stored as character variables. There are many different \"levels\" of working with strings in programming, from simple find-and-replaced of fixed (constant) strings to regular expressions, which are extremely powerful (and extremely complicated).\n\n> Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems. - Jamie Zawinski\n\n![Alternately, the xkcd version of the above quote](https://imgs.xkcd.com/comics/perl_problems.png)\n\nThe [stringr cheatsheet](https://github.com/rstudio/cheatsheets/blob/main/strings.pdf) by RStudio may be helpful as you complete tasks related to this section - it may even be useful in Python as the 2nd page has a nice summary of regular expressions.\n\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Task                                                       | R                                                                                              | Python                                                                                     |\n+============================================================+================================================================================================+============================================================================================+\n| Replace `pattern` with `replacement`                       | base: `gsub(pattern, replacement, x)`                                                          | pandas: `x.str.replace(pattern, replacement)` (not vectorized over pattern or replacement) |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_replace(x, pattern, replacement)` and `str_replace_all(x, pattern, replacement)` |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Convert case                                               | base: `tolower(x)`, `toupper(x)`                                                               | pandas: `x.str.lower()`, `x.str.upper()`                                                   |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_to_lower(x)`, `str_to_upper(x)` , `str_to_title(x)`                              |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Strip whitespace from start/end                            | base: `trimws(x)`                                                                              | pandas: `x.str.strip()`                                                                    |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_trim(x)` , `str_squish(x)`                                                       |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Pad strings to a specific length                           | base: `sprintf(format, x)`                                                                     | pandas: `x.str.pad()`                                                                      |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_pad(x, â€¦)`                                                                       |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Test if the string contains a pattern                      | base: `grep(pattern, x)` or `grepl(pattern, x)`                                                | pandas: `x.str.contains(pattern)`                                                          |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_detect(x, pattern)`                                                              |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Count how many times a pattern appears in the string       | base: `gregexpr(pattern, x)` + `sapply` to count length of the returned list                   | pandas: `x.str.count(pattern)`                                                             |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringi: `stri_count(x, pattern)`                                                              |                                                                                            |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_count(x, pattern)`                                                               |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Find the first appearance of the pattern within the string | base: `regexpr(pattern, x)`                                                                    | pandas: `x.str.find(pattern)`                                                              |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_locate(x, pattern)`                                                              |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Find all appearances of the pattern within the string      | base: `gregexpr`                                                                               | pandas: `x.str.findall(pattern)`                                                           |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_locate_all(x, pattern)`                                                          |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Detect a match at the start/end of the string              | base: use regular expr.                                                                        | pandas: `x.str.startswith(pattern)` , `x.str.endswith(pattern)`                            |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_starts(x, pattern)` ,`str_ends(x, pattern)`                                      |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Subset a string from index a to b                          | base: `substr(x, a, b)`                                                                        | pandas: `x.str.slice(a, b, step)`                                                          |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_sub(x, a, b)`                                                                    |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n| Convert string encoding                                    | base: `iconv(x, encoding)`                                                                     | pandas: `x.str.encode(encoding)`                                                           |\n|                                                            |                                                                                                |                                                                                            |\n|                                                            | stringr: `str_conv(x, encoding)`                                                               |                                                                                            |\n+------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+\n\n: Table of string functions in R and python. `x` is the string or vector of strings, `pattern` is a pattern to be found within the string, `a` and `b` are indexes, and `encoding` is a string encoding, such as UTF8 or ASCII. {#tbl-string-function}\n\nIn @tbl-string-function, multiple functions are provided for e.g. common packages and situations. Pandas methods are specifically those which work in some sort of vectorized manner. Base methods (in R) do not require additional packages, where stringr methods require the `stringr` package, which is included in the tidyverse[^data-transformations-1].\n\n[^data-transformations-1]: Many functions from `stringr` have somewhat faster functional equivalents in the `stringi` package, but the `stringi` package has a less \"tidy\" API, so it may be worth the slight slowdown to use `stringr` if your data isn't huge because your code will be more readable.\n\n## Converting strings to numbers\n\nOne of the most common tasks when reading in and tidying messy data is that numeric-ish data can come in many forms that are read (by default) as strings. The data frame below provides an example of a few types of data which may be read in in unexpected ways. How do we tell R or Python that we want all of these columns to be treated as numbers?\n\n\n\n::: {#tbl-parse-numbers .cell tbl-cap='Different \"messy\" number formats'}\n      int_col    float_col  mix_col      missing_col  money_col    eu_numbers    boolean_col    custom\n--  ---------  -----------  ---------  -------------  -----------  ------------  -------------  --------\n 0          1          1.1  a                      1  Â£1,000.00    1.000.000,00  True           Y\n 1          2          1.2  2                      2  Â£2,400.00    2.000.342,00  False          Y\n 2          3          1.3  3                      3  Â£2,400.00    3.141,59      True           N\n 3          4          4.7  4                    nan  Â£2,400.00    34,25         True           N\n:::\n\n\n\n\n\n[Numbers](https://docs.oracle.com/cd/E19455-01/806-0169/overview-8/index.html), currencies, dates, and times are written differently based on what country you're in [@ashourConciseGuideNumber2022]. \nIn computer terms, this is the **locale**, and it affects everything from how your computer formats the date/time to what character set it will try to use to display things [@LocaleComputerSoftware2022].\n\nLocales are something you may want to skip if you're just starting out and you don't work with code written by people in other countries. \nIf you're collaborating internationally, however, you may want to at least skim the section below to be aware of potential issues when locale-related problems crop up.\n\n[If you've never had to deal with the complexities of working on a laptop designed for one country using another country's conventions, know that it isn't necessarily the easiest thing to do.]{.aside}\n\n::: {.callout-advanced collapse=\"true\"}\n#### Advanced: Locales {.unnumbered}\n\n##### Find your locale {.unnumbered}\n\n-   <i class=\"fa-brands fa-windows\"></i> Type [`Get-WinSystemLocale`](https://docs.microsoft.com/en-us/powershell/module/international/get-winsystemlocale?view=windowsserver2022-ps#syntax) into your CMD or powershell terminal.\n-   <i class=\"fa-brands fa-apple\"></i> (10.4 and later) and <i class=\"fa-brands fa-linux\"></i> Type `locale` into your terminal\n\n##### Get set up to work with locales {.unnumbered}\n\nWhile this isn't required, it may be useful and is definitely good practice if you're planning to work with data generated internationally.\n\n[This article](https://herrmann.tech/en/blog/2021/02/05/how-to-deal-with-international-data-formats-in-python.html) tells you how to set things up in linux <i class=\"fa-brands fa-linux\"></i>. The biggest difference in other OS is going to be how to install new locales, so here are some instructions on that for other OS.\n\n-   <i class=\"fa-brands fa-windows\"></i> [Installing languages](https://support.microsoft.com/en-us/windows/install-a-language-for-windows-ccd853d3-9ecd-7da7-9ef0-72b4a055410a)\n-   <i class=\"fa-brands fa-apple\"></i> [Change locales](https://9to5mac.com/2018/08/09/mac-how-to-change-language-and-region/). Installing or creating new locales seems to be [more complicated](https://stackoverflow.com/questions/9991603/add-a-locale-in-mac-osx), and since I do not have a mac, I can't test this out easily myself.\n:::\n\nWe'll use @tbl-parse-numbers to explore different string operations focused specifically on converting strings to numbers.\n\n::: panel-tabset\n#### Get the data: Python {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\ndf = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/stat-computing-r-python/main/data/number-formats.csv\")\n```\n:::\n\n\n\n#### R {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read.csv(\"https://raw.githubusercontent.com/srvanderplas/stat-computing-r-python/main/data/number-formats.csv\", colClasses = \"character\")\n```\n:::\n\n\n\nBy default, R tries to outsmart us and read the data in as numbers. I've disabled this behavior by setting `colClasses='character'` so that you can see how these functions work... but in general, R seems to be a bit more willing to try to guess what you want. This can be useful, but can also be frustrating when you don't know how to disable it.\n:::\n\n::: callout-caution\n#### Converting Columns Using Your Best Guess {.unnumbered}\n\nBoth R and Python have ways to \"guess\" what type a column is and read the data in as that type. When we initially read in the data above, I had to explicitly disable this behavior in R. If you're working with data that is already read in, how do you get R and Python to guess what type something is?\n\n::: panel-tabset\n##### R\n\nHere, R gets everything \"right\" except the eu_numbers, money_col, and custom cols, which makes sense - these contain information that isn't clearly numeric or doesn't match the default numeric formatting on my machine (which is using en_US.UTF-8 for almost everything). If we additionally want R to handle `mix_col`, we would have to explicitly convert to numeric, causing the a to be converted to `NA`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(readr)\ndf_guess <- type_convert(df)\nstr(df_guess)\n## 'data.frame':\t4 obs. of  8 variables:\n##  $ int_col    : int  1 2 3 4\n##  $ float_col  : num  1.1 1.2 1.3 4.7\n##  $ mix_col    : chr  \"a\" \"2\" \"3\" \"4\"\n##  $ missing_col: num  1 2 3 NA\n##  $ money_col  : chr  \"Â£1,000.00\" \"Â£2,400.00\" \"Â£2,400.00\" \"Â£2,400.00\"\n##  $ eu_numbers : chr  \"1.000.000,00\" \"2.000.342,00\" \"3.141,59\" \"34,25\"\n##  $ boolean_col: logi  TRUE FALSE TRUE TRUE\n##  $ custom     : chr  \"Y\" \"Y\" \"N\" \"N\"\n```\n:::\n\n\n\nThe `type_convert` function has a `locale` argument; `readr` includes a `locale()` function that you can pass to `type_convert` that allows you to define your own locale. Because we have numeric types structured from at least two locales in this data frame, we would have to specifically read the data in specifying which columns we wanted read with each locale.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(readr)\nfixed_df <- type_convert(df) \nfixed_df2 <- type_convert(df, locale = locale(decimal_mark = ',', grouping_mark = '.'))\n# Replace EU numbers col with the type_convert results specifying that locale\nfixed_df$eu_numbers = fixed_df$eu_numbers\nstr(fixed_df)\n## 'data.frame':\t4 obs. of  8 variables:\n##  $ int_col    : int  1 2 3 4\n##  $ float_col  : num  1.1 1.2 1.3 4.7\n##  $ mix_col    : chr  \"a\" \"2\" \"3\" \"4\"\n##  $ missing_col: num  1 2 3 NA\n##  $ money_col  : chr  \"Â£1,000.00\" \"Â£2,400.00\" \"Â£2,400.00\" \"Â£2,400.00\"\n##  $ eu_numbers : chr  \"1.000.000,00\" \"2.000.342,00\" \"3.141,59\" \"34,25\"\n##  $ boolean_col: logi  TRUE FALSE TRUE TRUE\n##  $ custom     : chr  \"Y\" \"Y\" \"N\" \"N\"\n```\n:::\n\n\n\n##### Python\n\nSimilarly, Python does basically the same thing as R: mix_col, money_col, and custom are all left as strings, while floats, integers, and logical values are handled correctly.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfixed_df = df.infer_objects()\nfixed_df.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col         object\n## missing_col    float64\n## money_col       object\n## eu_numbers      object\n## boolean_col       bool\n## custom          object\n## dtype: object\n```\n:::\n\n\n\nAs in R, we can set the locale in Python to change how things are read in.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom babel.numbers import parse_decimal\n\n# Convert eu_numbers column specifically\nfixed_df['eu_numbers'] = fixed_df['eu_numbers'].apply(lambda x: parse_decimal(x, locale = 'it'))\nfixed_df['eu_numbers'] = pd.to_numeric(fixed_df['eu_numbers'])\nfixed_df.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col         object\n## missing_col    float64\n## money_col       object\n## eu_numbers     float64\n## boolean_col       bool\n## custom          object\n## dtype: object\n```\n:::\n\n\n:::\n:::\n\n::: callout-caution\n#### Converting Columns Directly {.unnumbered}\n\nObviously, we can also convert some strings to numbers using type conversion functions that we discussed in @sec-type-conversions. This is fairly easy in R, but a bit more complex in Python, because Python has several different types of 'missing' or NA variables that are not necessarily compatible.\n\n::: panel-tabset\n##### R\n\nHere, we use the `across` helper function from `dplyr` to convert all of the columns to numeric. Note that the last 3 columns don't work here, because they contain characters R doesn't recognize as numeric characters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\ndf_numeric <- mutate(df, across(everything(), as.numeric))\nstr(df_numeric)\n## 'data.frame':\t4 obs. of  8 variables:\n##  $ int_col    : num  1 2 3 4\n##  $ float_col  : num  1.1 1.2 1.3 4.7\n##  $ mix_col    : num  NA 2 3 4\n##  $ missing_col: num  1 2 3 NA\n##  $ money_col  : num  NA NA NA NA\n##  $ eu_numbers : num  NA NA NA NA\n##  $ boolean_col: num  NA NA NA NA\n##  $ custom     : num  NA NA NA NA\n```\n:::\n\n\n\n##### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf_numeric = df.apply(pd.to_numeric, errors='coerce')\ndf_numeric.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col        float64\n## missing_col    float64\n## money_col      float64\n## eu_numbers     float64\n## boolean_col       bool\n## custom         float64\n## dtype: object\n```\n:::\n\n\n:::\n:::\n\n::: callout-caution\n#### Example: Converting Y/N data\n\nThe next thing we might want to do is convert our `custom` column so that it has 1 instead of Y and 0 instead of N. There are several ways we can handle this process:\n\n-   We could use factors/categorical variables, which have numeric values \"under the hood\", but show up as labeled.\n-   We could (in this particular case) test for equality with \"Y\", but this approach would not generalize well if we had more than 2 categories.\n-   We could take a less nuanced approach and just find-replace and then convert to a number.\n\nSome of these solutions are more kludgy than others, but I've used all 3 approaches when dealing with categorical data in the past, depending on what I wanted to do with it afterwards.\n\n::: panel-tabset\n##### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr) # work with strings easily\nfixed_df = fixed_df %>%\n  mutate(\n    # factor approach\n    custom1 = factor(custom, levels = c(\"N\", \"Y\"), labels = c(\"Y\", \"N\")),\n    # test for equality\n    custom2 = (custom == \"Y\"),\n    # string replacement\n    custom3 = str_replace_all(custom, c(\"Y\" = \"1\", \"N\" = \"0\")) %>%\n      as.numeric()\n  )\n\nstr(fixed_df)\n## 'data.frame':\t4 obs. of  11 variables:\n##  $ int_col    : int  1 2 3 4\n##  $ float_col  : num  1.1 1.2 1.3 4.7\n##  $ mix_col    : chr  \"a\" \"2\" \"3\" \"4\"\n##  $ missing_col: num  1 2 3 NA\n##  $ money_col  : chr  \"Â£1,000.00\" \"Â£2,400.00\" \"Â£2,400.00\" \"Â£2,400.00\"\n##  $ eu_numbers : chr  \"1.000.000,00\" \"2.000.342,00\" \"3.141,59\" \"34,25\"\n##  $ boolean_col: logi  TRUE FALSE TRUE TRUE\n##  $ custom     : chr  \"Y\" \"Y\" \"N\" \"N\"\n##  $ custom1    : Factor w/ 2 levels \"Y\",\"N\": 2 2 1 1\n##  $ custom2    : logi  TRUE TRUE FALSE FALSE\n##  $ custom3    : num  1 1 0 0\n```\n:::\n\n\n\n##### Python\n\nWe've already done a brief demonstration of string methods in Python when we trimmed off the Â£ character. In this situation, it's better to use the pandas `replace` method, which allows you to pass in a list of values and a list of replacements.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Categorical (factor) approach\nfixed_df['custom1'] = fixed_df['custom'].astype(\"category\") # convert to categorical variable\n# Equality/boolean approach\nfixed_df['custom2'] = fixed_df['custom'] == \"Y\"\n# string replacement\nfixed_df['custom3'] = fixed_df['custom'].replace([\"Y\", \"N\"], [\"1\", \"0\"]).astype(\"int\")\n\nfixed_df.dtypes\n## int_col           int64\n## float_col       float64\n## mix_col          object\n## missing_col     float64\n## money_col        object\n## eu_numbers      float64\n## boolean_col        bool\n## custom           object\n## custom1        category\n## custom2            bool\n## custom3           int64\n## dtype: object\n```\n:::\n\n\n:::\n:::\n\n## Find and replace\n\nAnother way to fix some issues is to just find-and-replace the problematic characters. \nThis is not always the best solution[^data-transformations-2], and may introduce bugs if you use the same code to analyze new data with characters you haven't anticipated, but in so many cases it's also the absolute easiest, fastest, simplest way forward and easily solves many different problems.\n\n[^data-transformations-2]: It's particularly hackish when you're working with locale-specific settings [@herrmannHowDealInternational2021], and in many cases you can handle locale issues much more elegantly.\n\n[I'll show you how to correct all of the issues reading in the data using solutions shown above, but please do consider reading @herrmannHowDealInternational2021 so that you know why find-and-replace isn't (necessarily) the best option for locale-specific formatting.]{.aside}\n\n::: callout-caution\n#### Example: find and replace\n\nLet's start with the money column.\n\n::: panel-tabset\n##### R\n\nIn R, `parse_number()` handles the money column just fine - the pound sign goes away and we get a numeric value. \nThis didn't work by default with `type_convert`, but as long as we `mutate` and tell R we expect a number, things work well. \nThen, as we did above, we can specify the locale settings so that decimal and grouping marks are handled correctly even for countries which use ',' for decimal and '.' for thousands separators.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfixed_df = df %>%\n  type_convert() %>% # guess everything\n  mutate(money_col = parse_number(money_col),\n         eu_numbers = parse_number(eu_numbers, \n                                   locale = locale(decimal_mark = ',', \n                                                   grouping_mark = '.')))\n```\n:::\n\n\n\n##### Python\n\nIn python, a similar approach doesn't work out, because the pound sign is not handled correctly.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom babel.numbers import parse_decimal\n\nfixed_df = df.infer_objects()\n\n# Convert eu_numbers column\nfixed_df['eu_numbers'] = fixed_df['eu_numbers'].apply(lambda x: parse_decimal(x, locale = 'it'))\nfixed_df['eu_numbers'] = pd.to_numeric(fixed_df['eu_numbers'])\n\n# Convert money_col\nfixed_df['money_col'] = fixed_df['money_col'].apply(lambda x: parse_decimal(x, locale = 'en_GB'))\n## babel.numbers.NumberFormatError: 'Â£1,000.00' is not a valid decimal number\n\nfixed_df.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col         object\n## missing_col    float64\n## money_col       object\n## eu_numbers     float64\n## boolean_col       bool\n## custom          object\n## dtype: object\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Remove Â£ from string\nfixed_df['money_col'] = fixed_df['money_col'].str.removeprefix(\"Â£\")\n# Then parse the number\nfixed_df['money_col'] = fixed_df['money_col'].apply(lambda x: parse_decimal(x))\n# Then convert to numeric\nfixed_df['money_col'] = pd.to_numeric(fixed_df['money_col'])\n\nfixed_df.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col         object\n## missing_col    float64\n## money_col      float64\n## eu_numbers     float64\n## boolean_col       bool\n## custom          object\n## dtype: object\n```\n:::\n\n\n:::\n:::\n\n::: callout-advanced\n### Example: Locale find-and-replace\n\nWe could also handle the locale issues using find-and-replace, if we wanted to...\n\n::: panel-tabset\n##### R\n\nNote that `str_remove` is shorthand for `str_replace(x, pattern, \"\")`. There is a little bit of additional complexity in switching \",\" for \".\" and vice versa - we have to change \",\" to something else first, so that we can replace \".\" with \",\". This is *not* elegant but it does work. It also doesn't generalize - it will mess up numbers formatted using the US/UK convention, and it won't handle numbers formatted using other conventions from other locales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfixed_df = df %>%\n  type_convert() %>% # guess everything\n  mutate(money_col = str_remove(money_col, \"Â£\") %>% parse_number(),\n         eu_numbers = str_replace_all(eu_numbers, \n                                      c(\",\" = \"_\", \n                                        \"\\\\.\" = \",\", \n                                        \"_\" = \".\")) %>%\n           parse_number())\n```\n:::\n\n\n\n##### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom babel.numbers import parse_decimal\n\nfixed_df = df.infer_objects()\n\n# Convert eu_numbers column: \n# Replace . with nothing (remove .), then\n# Replace , with .\nfixed_df['eu_numbers'] = fixed_df['eu_numbers'].\\\nstr.replace('\\.', '').\\\nstr.replace(',', '.')\nfixed_df['eu_numbers'] = pd.to_numeric(fixed_df['eu_numbers'])\n## ValueError: Unable to parse string \"1.000.000.00\" at position 0\n\n# Convert money_col\nfixed_df['money_col'] = fixed_df['money_col'].\\\nstr.removeprefix(\"Â£\").\\\nstr.replace(',', '')\nfixed_df['money_col'] = pd.to_numeric(fixed_df['money_col'])\n\nfixed_df.dtypes\n## int_col          int64\n## float_col      float64\n## mix_col         object\n## missing_col    float64\n## money_col      float64\n## eu_numbers      object\n## boolean_col       bool\n## custom          object\n## dtype: object\nfixed_df\n##    int_col  float_col mix_col  ...    eu_numbers  boolean_col custom\n## 0        1        1.1       a  ...  1.000.000.00         True      Y\n## 1        2        1.2       2  ...  2.000.342.00        False      Y\n## 2        3        1.3       3  ...      3.141.59         True      N\n## 3        4        4.7       4  ...         34.25         True      N\n## \n## [4 rows x 8 columns]\n```\n:::\n\n\n:::\n:::\n\n## Separating multi-variable columns\n\nAnother common situation is to have multiple variables in one column. This can happen, for instance, when conducting a factorial experiment: Instead of having separate columns for each factor, researchers sometimes combine several different factors into a single label for a condition to simplify data entry.\n\nIn pandas, we use `x.str.split()` to split columns in a DataFrame, in R we use the `tidyr` package's `separate_wider_xxx()` series of functions.\n\n::: callout-caution\n### Example: Separating columns\n\nWe'll use the `table3` object included in `dplyr` for this example. \nYou can load it in R and then load the `reticuate` package to be able to access the object in python as `r.table3`.\n\n::: panel-tabset\n#### Picture the operation\n\n![We want to separate the rate column into two new columns, cases and population.](../images/wrangling/tidyr_separate.png){fig-alt=\"An image showing table 3 from the messy data examples, with the rate column containing data formatted as xxx/yyy. The picture shows the transition to a similarly structured data with two new columns: cases, which contains the xxx data, and pop, which contains the yyy data.\"}\n\n#### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(reticulate) # so we can access table3 in python\ndata(table3)\nseparate_wider_delim(table3, rate, delim = \"/\", names = c('cases', 'pop'), cols_remove = F)\n## # A tibble: 6 Ã— 5\n##   country      year cases  pop        rate             \n##   <chr>       <dbl> <chr>  <chr>      <chr>            \n## 1 Afghanistan  1999 745    19987071   745/19987071     \n## 2 Afghanistan  2000 2666   20595360   2666/20595360    \n## 3 Brazil       1999 37737  172006362  37737/172006362  \n## 4 Brazil       2000 80488  174504898  80488/174504898  \n## 5 China        1999 212258 1272915272 212258/1272915272\n## 6 China        2000 213766 1280428583 213766/1280428583\n```\n:::\n\n\n\n#### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntable3 = r.table3\ntable3[['cases', 'pop']] = table3.rate.str.split(\"/\", expand = True)\ntable3\n##        country    year               rate   cases         pop\n## 0  Afghanistan  1999.0       745/19987071     745    19987071\n## 1  Afghanistan  2000.0      2666/20595360    2666    20595360\n## 2       Brazil  1999.0    37737/172006362   37737   172006362\n## 3       Brazil  2000.0    80488/174504898   80488   174504898\n## 4        China  1999.0  212258/1272915272  212258  1272915272\n## 5        China  2000.0  213766/1280428583  213766  1280428583\n```\n:::\n\n\n\nThis uses python's **multiassign** capability. \nPython can assign multiple things at once if those things are specified as a sequence (e.g. cases, pop). \nIn this case, we split the rate column and assign two new columns, essentially adding two columns to our data frame and labeling them at the same time.\n:::\n:::\n\n## Joining columns\n\nIt's also not uncommon to need to join information stored in two columns into one column. \nA good example of a situation in which you might need to do this is when we store first and last name separately and then need to have a 'name' column that has both pieces of information together.\n\n::: callout-caution\n### Example: Joining columns\n\nWe'll use the `table5` object included in `dplyr` for this example. \nYou can load it in R and then load the `reticuate` package to be able to access the object in python as `r.table5`.\n\n::: panel-tabset\n#### Picture the operation\n\n![We want to join the century and year columns into a new column, yyyy.](../images/wrangling/tidyr_unite.png){fig-alt=\"An image showing table 5 from the messy data examples, with century and year columns. The picture shows the transition to a similarly structured data set with a single column, year, which contains the century and the year pasted together as a single number.\"}\n\n#### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(reticulate) # so we can access table3 in python\ndata(table5)\nunite(table5, col = yyyy, c(century, year), sep = \"\", remove = F) %>%\n  # convert all columns to sensible types\n  readr::type_convert()\n## # A tibble: 6 Ã— 5\n##   country      yyyy century year  rate             \n##   <chr>       <dbl>   <dbl> <chr> <chr>            \n## 1 Afghanistan  1999      19 99    745/19987071     \n## 2 Afghanistan  2000      20 00    2666/20595360    \n## 3 Brazil       1999      19 99    37737/172006362  \n## 4 Brazil       2000      20 00    80488/174504898  \n## 5 China        1999      19 99    212258/1272915272\n## 6 China        2000      20 00    213766/1280428583\n```\n:::\n\n\n\n#### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\ntable5 = r.table5\n# Concatenate the two columns with string addition\ntable5['yyyy'] = table5.century + table5.year\n# convert to number\ntable5['yyyy'] = pd.to_numeric(table5.yyyy)\ntable5\n##        country century year               rate  yyyy\n## 0  Afghanistan      19   99       745/19987071  1999\n## 1  Afghanistan      20   00      2666/20595360  2000\n## 2       Brazil      19   99    37737/172006362  1999\n## 3       Brazil      20   00    80488/174504898  2000\n## 4        China      19   99  212258/1272915272  1999\n## 5        China      20   00  213766/1280428583  2000\n```\n:::\n\n\n:::\n:::\n\n## Regular Expressions\n\nMatching exact strings is easy - it's just like using find and replace.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhuman_talk <- \"blah, blah, blah. Do you want to go for a walk?\"\ndog_hears <- str_extract(human_talk, \"walk\")\ndog_hears\n## [1] \"walk\"\n```\n:::\n\n\n\n::: aside\n![To generate #1 albums, 'jay --help' recommends the -z flag. <br/>[XKCD comics by Randall Munroe](https://xkcd.com/1171/) CC-A-NC 2.5.](../images/wrangling/perl_problems.png){fig-alt=\"A stick figure with sunglasses says to another stick figure: 'If you're havin' perl problems I feel bad for you, son.' 'I got 99 problems,' 'So I used regular expressions.' 'Now I have 100 problems'.\"}\n:::\n\nA **regular expression** is a sequence of characters that specify a match pattern to search for in a larger text [@RegularExpression2023].\nRegular expressions may be used to specify find or find-and-replace operations on strings.\n\nRegular expressions can be extremely useful for cleaning and extracting data: they can replace misspellings, extract pieces of information from longer strings, and flexibly handle different ways people may input data. \nThey may be incredibly powerful, but they can also be complicated to create and the expressions themselves may be cryptic and nearly impossible to decode. \n\nBut, if you can master even a small amount of regular expression notation, you'll have exponentially more power to do good (or evil) when working with strings. \nYou can get by without regular expressions if you're creative, but often they're much simpler.\n\nHere are some useful regular expressions^[Note that these are written in generic regular expression text - to use them in R you will have to escape each and every `\\` with another `\\`.]:\n\n- Validate a phone number [@atwoodRegexUseVs2005]: `^\\(*\\d{3}\\)*( |-)*\\d{3}( |-)*\\d{4}$`\n- Check for first and last names [@cristianguerreroAnswerRegularExpression2017]: `^[\\w'\\-,.][^0-9_!Â¡?Ã·?Â¿/\\\\+=@#$%Ë†&*(){}|~<>;:[\\]]{2,}$`    \n(This is a tricky proposition and this regular expression does make some assumptions about what characters are valid for names.)\n- Match a 5 or 9 digit zip code: `\t(^\\d{5}$)|(^\\d{9}$)|(^\\d{5}-\\d{4}$)`\n\nThese tasks are all well-suited for regular expressions. More complicated tasks, such as validating an email address, are less suited for regular expressions, though there are regular expressions that exist [@risticValidateEmailAddresses2021] for that task.\n\n::: aside\nI've assembled a [YouTube playlist](https://www.youtube.com/embed/videoseries?list=PLSNDUuFnzc02k4fq5w63GsSW0tZ5E6z9h) of different explanations of regular expressions, if you prefer that type of tutorial.\n\n::: {.youtube-video-container}\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/videoseries?list=PLSNDUuFnzc02k4fq5w63GsSW0tZ5E6z9h\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n:::\n\n:::\n\nThe following demonstrations are intended for advanced students: if you are just learning how to program, you may want to come back to these when you need them.\n\nThere is also an excellent site which helps you learn regular expressions via interactive tutorials, @regexoneRegexOne. Another useful tool is @leaverouRegExplained2017\n\n::: {.callout-advanced collapse=\"true\"}\n### Regular Expression Basics\n\nYou may find it helpful to follow along with this section using this [web app](https://spannbaueradam.shinyapps.io/r_regex_tester/) built to test R regular expressions for R. A similar application for Perl compatible regular expressions (used by SAS and Python) can be found [here](https://regex101.com/). The subset of regular expression syntax we're going to cover here is fairly limited (and common to SAS, Python, and R, with a few adjustments), but [you can find regular expressions to do just about anything string-related](https://stackoverflow.com/questions/tagged/regex?tab=Votes). As with any tool, there are situations where it's useful, and situations where you should not use a regular expression, no matter how much you want to.\n\nHere are the basics of regular expressions:\n\n-   `[]` enclose sets of characters\\\n    Ex: `[abc]` will match any single character `a`, `b`, `c`\n    -   `-` specifies a range of characters (`A-z` matches all upper and lower case letters)\n    -   to match `-` exactly, precede with a backslash (outside of `[]`) or put the `-` last (inside `[]`)\n-   `.` matches any character (except a newline)\n-   To match special characters, escape them using `\\` (in most languages) or `\\\\` (in R). So `\\.` or `\\\\.` will match a literal `.`, `\\$` or `\\\\$` will match a literal `$`.\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_string <- \"phone: 123-456-7890, nuid: 12345678, ssn: 123-45-6789\"\n\nssn <- str_extract(num_string, \"[0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]\")\nssn\n## [1] \"123-45-6789\"\n```\n:::\n\n\n\n#### Python {.unnumbered}\n\nIn python, a regular expression is indicated by putting the character 'r' right before the quoted expression. This tells python that any backslashes in the string should be left alone -- if R had that feature, we wouldn't have to escape all the backslashes!\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport re\n\nnum_string = \"phone: 123-456-7890, nuid: 12345678, ssn: 123-45-6789\"\n\nssn = re.search(r\"[0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]\", num_string)\nssn\n## <re.Match object; span=(42, 53), match='123-45-6789'>\n```\n:::\n\n\n:::\n:::\n\n::: {.callout-advanced collapse=\"true\"}\n### Specifying repetition\n\nListing out all of those numbers can get repetitive, though. How do we specify repetition?\n\n-   `*` means repeat between 0 and inf times\n-   `+` means 1 or more times\n-   `?` means 0 or 1 times -- most useful when you're looking for something optional\n-   `{a, b}` means repeat between `a` and `b` times, where `a` and `b` are integers. `b` can be blank. So `[abc]{3,}` will match `abc`, `aaaa`, `cbbaa`, but not `ab`, `bb`, or `a`. For a single number of repeated characters, you can use `{a}`. So `{3, }` means \"3 or more times\" and `{3}` means \"exactly 3 times\"\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr)\nstr_extract(\"banana\", \"[a-z]{1,}\") # match any sequence of lowercase characters\n## [1] \"banana\"\nstr_extract(\"banana\", \"[ab]{1,}\") # Match any sequence of a and b characters\n## [1] \"ba\"\nstr_extract_all(\"banana\", \"(..)\") # Match any two characters\n## [[1]]\n## [1] \"ba\" \"na\" \"na\"\nstr_extract(\"banana\", \"(..)\\\\1\") # Match a repeated thing\n## [1] \"anan\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_string <- \"phone: 123-456-7890, nuid: 12345678, ssn: 123-45-6789, bank account balance: $50,000,000.23\"\n\nssn <- str_extract(num_string, \"[0-9]{3}-[0-9]{2}-[0-9]{4}\")\nssn\n## [1] \"123-45-6789\"\nphone <- str_extract(num_string, \"[0-9]{3}.[0-9]{3}.[0-9]{4}\")\nphone\n## [1] \"123-456-7890\"\nnuid <- str_extract(num_string, \"[0-9]{8}\")\nnuid\n## [1] \"12345678\"\nbank_balance <- str_extract(num_string, \"\\\\$[0-9,]+\\\\.[0-9]{2}\")\nbank_balance\n## [1] \"$50,000,000.23\"\n```\n:::\n\n\n\n#### Python {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport re\nre.search(r\"[a-z]{1,}\", \"banana\") # match any sequence of lowercase characters\n## <re.Match object; span=(0, 6), match='banana'>\nre.search(r\"[ab]{1,}\", \"banana\") # Match any sequence of a and b characters\n## <re.Match object; span=(0, 2), match='ba'>\nre.findall(r\"(..)\", \"banana\") # Match any two characters\n## ['ba', 'na', 'na']\nre.search(r\"(..)\\1\", \"banana\") # Match a repeated thing\n## <re.Match object; span=(1, 5), match='anan'>\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport re\n\nnum_string = \"phone: 123-456-7890, nuid: 12345678, ssn: 123-45-6789, bank account balance: $50,000,000.23\"\n\nssn = re.search(r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\", num_string)\nssn\n## <re.Match object; span=(42, 53), match='123-45-6789'>\nphone = re.search(r\"[0-9]{3}.[0-9]{3}.[0-9]{4}\", num_string)\nphone\n## <re.Match object; span=(7, 19), match='123-456-7890'>\nnuid = re.search(r\"[0-9]{8}\", num_string)\nnuid\n## <re.Match object; span=(27, 35), match='12345678'>\nbank_balance = re.search(r\"\\$[0-9,]+\\.[0-9]{2}\", num_string)\nbank_balance\n## <re.Match object; span=(77, 91), match='$50,000,000.23'>\n```\n:::\n\n\n:::\n:::\n\n::: {.callout-advanced collapse=\"true\"}\n### Matching Locations\nThere are also ways to \"anchor\" a pattern to a part of the string (e.g. the beginning or the end)\n\n-   `^` has multiple meanings:\n    -   if it's the first character in a pattern, `^` matches the beginning of a string\n    -   if it follows `[`, e.g. `[^abc]`, `^` means \"not\" - for instance, \"the collection of all characters that aren't a, b, or c\".\n-   `$` means the end of a string\n\nCombined with pre and post-processing, these let you make sense out of semi-structured string data, such as addresses.\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naddress <- \"1600 Pennsylvania Ave NW, Washington D.C., 20500\"\n\nhouse_num <- str_extract(address, \"^[0-9]{1,}\")\n\n # Match everything alphanumeric up to the comma\nstreet <- str_extract(address, \"[A-z0-9 ]{1,}\")\nstreet <- str_remove(street, house_num) %>% str_trim() # remove house number\n\ncity <- str_extract(address, \",.*,\") %>% str_remove_all(\",\") %>% str_trim()\n\nzip <- str_extract(address, \"[0-9-]{5,10}$\") # match 5 and 9 digit zip codes\n```\n:::\n\n\n\n#### Python {.unnumbered}\n\nPython match objects contain 3 things: `.span()`, which has the start and end positions of the match, `.string`, which contains the original string passed into the function, and `.group()`, which contains the actual matching portion of the string.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport re\n\naddress = \"1600 Pennsylvania Ave NW, Washington D.C., 20500\"\n\nhouse_num = re.search(r\"^[0-9]{1,}\", address).group()\n\n# Match everything alphanumeric up to the comma\nstreet = re.search(r\"[A-z0-9 ]{1,}\", address).group()\nstreet = street.replace(house_num, \"\").strip() # remove house number\n\ncity = re.search(\",.*,\", address).group().replace(\",\", \"\").strip()\n\nzip = re.search(r\"[0-9-]{5,10}$\", address).group() # match 5 and 9 digit zip codes\n```\n:::\n\n\n:::\n\n:::\n\n::: {.callout-advanced collapse=\"true\"}\n### Capturing Information\n\n-   `()` are used to capture information. So `([0-9]{4})` captures any 4-digit number\n-   `a|b` will select a or b.\n\nIf you've captured information using (), you can reference that information using **backreferences**. \n\nIn most languages, backreferences look like this: `\\1` for the first reference, `\\9` for the ninth. \nIn R, backreferences are `\\\\1` through `\\\\9`.\n\n::: panel-tabset\n#### R {.unnumbered}\n\nIn R, the `\\` character is special, so you have to escape it. So in R, `\\\\1` is the first reference, and `\\\\2` is the second, and so on.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nphone_num_variants <- c(\"(123) 456-7980\", \"123.456.7890\", \"+1 123-456-7890\")\nphone_regex <- \"\\\\+?[0-9]{0,3}? ?\\\\(?([0-9]{3})?\\\\)?.?([0-9]{3}).?([0-9]{4})\"\n# \\\\+?[0-9]{0,3} matches the country code, if specified, \n#    but won't take the first 3 digits from the area code \n#    unless a country code is also specified\n# \\\\( and \\\\) match literal parentheses if they exist\n# ([0-9]{3})? captures the area code, if it exists\n# .? matches any character\n# ([0-9]{3}) captures the exchange code\n# ([0-9]{4}) captures the 4-digit individual code\n\nstr_extract(phone_num_variants, phone_regex)\n## [1] \"(123) 456-7980\"  \"123.456.7890\"    \"+1 123-456-7890\"\nstr_replace(phone_num_variants, phone_regex, \"\\\\1\\\\2\\\\3\")\n## [1] \"1234567980\" \"1234567890\" \"1234567890\"\n# We didn't capture the country code, so it remained in the string\n\nhuman_talk <- \"blah, blah, blah. Do you want to go for a walk? I think I'm going to treat myself to some ice cream for working so hard. \"\ndog_hears <- str_extract_all(human_talk, \"walk|treat\")\ndog_hears\n## [[1]]\n## [1] \"walk\"  \"treat\"\n```\n:::\n\n\n\n#### Python {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport re\n\nphone_num_variants = pd.Series([\"(123) 456-7980\", \"123.456.7890\", \"+1 123-456-7890\"])\nphone_regex = re.compile(\"\\+?[0-9]{0,3}? ?\\(?([0-9]{3})?\\)?.?([0-9]{3}).?([0-9]{4})\")\n# \\+?[0-9]{0,3} matches the country code, if specified, \n#    but won't take the first 3 digits from the area code \n#    unless a country code is also specified\n# \\( and \\) match literal parentheses if they exist\n# ([0-9]{3})? captures the area code, if it exists\n# .? matches any character\n# ([0-9]{3}) captures the exchange code\n# ([0-9]{4}) captures the 4-digit individual code\n\nres = phone_num_variants.str.findall(phone_regex)\nres2 = phone_num_variants.str.replace(phone_regex, \"\\\\1\\\\2\\\\3\")\n## ValueError: Cannot use a compiled regex as replacement pattern with regex=False\n# We didn't capture the country code, so it remained in the string\n\nhuman_talk = \"blah, blah, blah. Do you want to go for a walk? I think I'm going to treat myself to some ice cream for working so hard. \"\ndog_hears = re.findall(r\"walk|treat\", human_talk)\ndog_hears\n## ['walk', 'treat']\n```\n:::\n\n\n:::\n\n:::\n\n\n::: {.callout-advanced collapse=\"true\"}\n### Putting it all Together\n\nWe can test our regular expressions to ensure that they are specific enough to pull out what we want, while not pulling out other similar information:\n\n::: panel-tabset\n#### R {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrings <- c(\"abcdefghijklmnopqrstuvwxyzABAB\",\n\"banana orange strawberry apple\",\n\"ana went to montana to eat a banana\",\n\"call me at 432-394-2873. Do you want to go for a walk? I'm going to treat myself to some ice cream for working so hard.\",\n\"phone: (123) 456-7890, nuid: 12345678, bank account balance: $50,000,000.23\",\n\"1600 Pennsylvania Ave NW, Washington D.C., 20500\")\n\nphone_regex <- \"\\\\+?[0-9]{0,3}? ?\\\\(?([0-9]{3})?\\\\)?.?([0-9]{3}).([0-9]{4})\"\ndog_regex <- \"(walk|treat)\"\naddr_regex <- \"([0-9]*) ([A-z0-9 ]{3,}), ([A-z\\\\. ]{3,}), ([0-9]{5})\"\nabab_regex <- \"(..)\\\\1\"\n\ntibble(\n  text = strings,\n  phone = str_detect(strings, phone_regex),\n  dog = str_detect(strings, dog_regex),\n  addr = str_detect(strings, addr_regex),\n  abab = str_detect(strings, abab_regex))\n## # A tibble: 6 Ã— 5\n##   text                                                   phone dog   addr  abab \n##   <chr>                                                  <lgl> <lgl> <lgl> <lgl>\n## 1 abcdefghijklmnopqrstuvwxyzABAB                         FALSE FALSE FALSE TRUE \n## 2 banana orange strawberry apple                         FALSE FALSE FALSE TRUE \n## 3 ana went to montana to eat a banana                    FALSE FALSE FALSE TRUE \n## 4 call me at 432-394-2873. Do you want to go for a walkâ€¦ TRUE  TRUE  FALSE FALSE\n## 5 phone: (123) 456-7890, nuid: 12345678, bank account bâ€¦ TRUE  FALSE FALSE FALSE\n## 6 1600 Pennsylvania Ave NW, Washington D.C., 20500       FALSE FALSE TRUE  FALSE\n```\n:::\n\n\n\n#### Python {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport re\n\nstrings = pd.Series([\"abcdefghijklmnopqrstuvwxyzABAB\",\n\"banana orange strawberry apple\",\n\"ana went to montana to eat a banana\",\n\"call me at 432-394-2873. Do you want to go for a walk? I'm going to treat myself to some ice cream for working so hard.\",\n\"phone: (123) 456-7890, nuid: 12345678, bank account balance: $50,000,000.23\",\n\"1600 Pennsylvania Ave NW, Washington D.C., 20500\"])\n\nphone_regex = re.compile(r\"\\(?([0-9]{3})?\\)?.?([0-9]{3}).([0-9]{4})\")\ndog_regex = re.compile(r\"(walk|treat)\")\naddr_regex = re.compile(r\"([0-9]*) ([A-z0-9 ]{3,}), ([A-z\\\\. ]{3,}), ([0-9]{5})\")\nabab_regex = re.compile(r\"(..)\\1\")\n\npd.DataFrame({\n  \"text\": strings,\n  \"phone\": strings.str.contains(phone_regex),\n  \"dog\": strings.str.contains(dog_regex),\n  \"addr\": strings.str.contains(addr_regex),\n  \"abab\": strings.str.contains(abab_regex)})\n##                                                 text  phone  ...   addr   abab\n## 0                     abcdefghijklmnopqrstuvwxyzABAB  False  ...  False   True\n## 1                     banana orange strawberry apple  False  ...  False   True\n## 2                ana went to montana to eat a banana  False  ...  False   True\n## 3  call me at 432-394-2873. Do you want to go for...   True  ...  False  False\n## 4  phone: (123) 456-7890, nuid: 12345678, bank ac...   True  ...  False  False\n## 5   1600 Pennsylvania Ave NW, Washington D.C., 20500  False  ...   True  False\n## \n## [6 rows x 5 columns]\n```\n:::\n\n\n:::\n:::\n\n\n## References {#sec-strings-refs}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}