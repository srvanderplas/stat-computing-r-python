{
  "hash": "bd3bbb4a754109ee7a649aca9cc7ade2",
  "result": {
    "engine": "knitr",
    "markdown": "# Normal Forms of Data {#sec-data-nf}\n\n## Objectives {-}\n\nThis chapter provides a bit of an 'under-the-hood' view of reshaping data and links it to some concepts in database design and data organization from the computer science view point.\n\nWhat you should get out of this material is \n\n- a better understanding of the origin of some of the (parameter) names:  for example, the parameters `key` and `value` in  python `pandas` function `melt`, or why is the  long form called `tidy`?\n\n- to be able to determine what the *key variable(s)* are in a dataset.\n\n\n\n\n## Normalforms of data\n\nNormal forms were developed in the 1970s by [E.F. Codd](https://en.wikipedia.org/wiki/Edgar_F._Codd) as a theoretical framework to describe data structures in (relational) data bases. For the purpose of the considerations here, you can think of a data base as a bundle of data sets that are loosely connected  - e.g.  the data sets describe (different) aspects of the same objects, or they share some aspects (such as the same time or the same geography).\n\nWhat we mean by a dataset here, is a spread-sheet style (rectangular) representation, with rows representing observations and columns representing variables. We will assume that the first row in the spread sheet contains the names of the variables. Siilarly, we will assume there are no row names - any existing row names can be made a column/variable in the dataset. \n\nFor the purpose of assessing the normal form of a data set. we distinguish between two types of variables: **keys** and **non-key variables**.\n\n\n::: callout-important\n#### Definition: Key and Non-Key Variables {.unnumbered}\nThe *key* of a data frame is defined as the (set of) variable(s) that uniquely identifies each row.\n\nSimilarly, any variable that is not part of the key, is a *non-key variable*.\n:::\n\nThere are various ways of recognizing key variables in a dataset: the easiest might be by their name; oftentimes a key variable is called an 'identifier', so watch out for variables with the letters `ID` in their name. Generally, the idea of a designed study and key variables are related: in a designed study, the combination of all design variables form a key. Any variables with values that are observed during the experiment, or collected after the study design is determined, are non-key variables. \n\nIn order to determine, whether a set of variables forms a key, we will need to determine that there are no duplications in their combined values. \n\n::: callout-caution\n#### Example: is it a key? {.unnumbered}\n\nLet us assume, that we have the following dataset on measuring (repeatedly) different aspects and body parts of [Wallabies](http://www.statsci.org/data/oz/wallaby.html). This data is part of the Australian data and story library [OzDASL](https://gksmyth.github.io/ozdasl/). See the [help page](http://www.statsci.org/data/oz/wallaby.html) for more information about this data set and each of its variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby <- read.csv(\"../data/wallaby.csv\") \nhead(wallaby) %>% knitr::kable(caption=\"First few lines of the wallaby data.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: First few lines of the wallaby data.\n\n| Anim| Sex|Loca | Leng| Head| Ear| Arm| Leg| Pes| Tail| Weight| Age|\n|----:|---:|:----|----:|----:|---:|---:|---:|---:|----:|------:|---:|\n|   45|   1|G    |   NA|  123|  NA|  59|  69|  59|   93|     NA|  14|\n|   45|   1|G    |   NA|  178|  54|  90| 120|  92|  185|     NA|  28|\n|   45|   1|G    |   NA|  250|  92| 130| 210| 142|  307|     NA|  49|\n|   45|   1|G    |   NA|  324| 108| 174| 284| 205|  454|    290|  69|\n|   45|   1|G    |   NA|  369| 129| 198| 340| 257|  568|    410|  83|\n|   45|   1|G    |   NA|  408| 155| 237| 411| 308|  648|    570|  97|\n\n\n:::\n:::\n\nWhen determining whether this data set has a key, we might at first consider the variable `Anim` (animal number). However, the first couple of rows already show us that this variable is not uniquely describing a row/observation in the data. What about the combination of `Anim` and `Age`?\nIn order for these two variables to be a key, their combination needs to be unique, i.e. for each animal, we can only have one set of measurements at any age. \nWe can check whether that condition is fulfilled by tallying up the combination:\n\n::: panel-tabset\n#### Check: is Anim the key? {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby %>% \n  count(Anim, sort = TRUE) %>% \n  head() %>% \n  knitr::kable(caption=\"Anim by itself is not uniquely identifying rows in the data.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Anim by itself is not uniquely identifying rows in the data.\n\n| Anim|  n|\n|----:|--:|\n|   53| 50|\n|   45| 49|\n|   47| 49|\n|   57| 49|\n|   55| 47|\n|   65| 42|\n\n\n:::\n:::\n\n\nAnim by itself is not a key variable, because for some animal ids we have multiple sets of measurements. \n\n#### Check: is the combination of Anim and Age the key? {.unnumbered}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby %>% \n  count(Anim, Age, sort = TRUE) %>% \n  head() %>% \n  knitr::kable(caption=\"All combinations of animal ID and an animal's age only refer to one set of measurements.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: All combinations of animal ID and an animal's age only refer to one set of measurements.\n\n| Anim| Age|  n|\n|----:|---:|--:|\n|   44|   8|  1|\n|   44|  22|  1|\n|   44|  43|  1|\n|   44|  63|  1|\n|   44|  77|  1|\n|   44|  91|  1|\n\n\n:::\n:::\n\n\nThe combination of `Anim` and `Age` uniquely describes each observation, and is therefore a key for the data set.\n:::\n:::\n\n\n#### Benefits of Normal forms\n\nNormalforms are used to describe the state that a particular data set is in -- lower normal forms can always be transformed into higher forms. This process is called *normalization* of data. Normalizing data has various benefits:\n\nNormalization \n\n- avoids data redundancies,\n- reveals inconsistencies, \n- simplifies the data design,\n- increases lookup speeds (in data bases),\n- and makes sets of data easier to maintain.\n\n\nMost often we are only interested in the first three normal forms. For memorization you can think of these forms as going along with \n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\n1. The key\n2. The whole key\n3.  and nothing but the key\n\n:::\n\n::: {.column width=\"10%\"}\n<!-- empty column to create gap -->\n:::\n\n::: {.column width=\"60%\"}\n\n![Image of two keys as a memorization help for the three normal forms of data.](../images/wrangling/the-key.jpeg)\n\n:::\n\n::::\n\n::: callout-important \n#### First Normal Form {.unnumbered}\n\nA table is in *first normal form* if \n\n1. every entry in the table is a single value, and\n2. the table has a key.\n:::\n\n\n:::: callout-caution\n#### Back to the wallabies {.unnumbered}\nBelow is a snapshot of a reshaped version of the previous example, where all measurements for each animal are captured in the list variable `measurements`. While `Anim` now should be a key variable (presumably it uniquely identifies each animal),  the data set is still not in first normal form, because the entries in the variable `measurements` are data sets by themselves, not just single values.\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby2 <- wallaby %>% \n  nest(.by = c(\"Anim\", \"Sex\", \"Loca\"), .key=\"measurements\") \nwallaby2 %>% head() \n## # A tibble: 6 × 4\n##    Anim   Sex Loca  measurements     \n##   <int> <int> <chr> <list>           \n## 1    45     1 G     <tibble [49 × 9]>\n## 2    47     1 G     <tibble [49 × 9]>\n## 3    53     2 G     <tibble [50 × 9]>\n## 4    57     2 G     <tibble [49 × 9]>\n## 5    65     2 G     <tibble [42 × 9]>\n## 6    79     2 K     <tibble [39 × 9]>\n```\n:::\n\nIs `Anim` the key variable of `wallaby2`? For that we check whether the `Anim` variable is unique - and find out that it is not unique! \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby2 %>% count(Anim, sort=TRUE) %>% head() %>%\n  knitr::kable(caption=\"We see in the frequency breakdown of `Anim`, that the animal ID for 125 is used twice, i.e. 125 seems to describe two different animals. This would indicate that animal numbers do not refer to an individual animal as the data description suggests.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: We see in the frequency breakdown of `Anim`, that the animal ID for 125 is used twice, i.e. 125 seems to describe two different animals. This would indicate that animal numbers do not refer to an individual animal as the data description suggests.\n\n| Anim|  n|\n|----:|--:|\n|  125|  2|\n|   44|  1|\n|   45|  1|\n|   46|  1|\n|   47|  1|\n|   48|  1|\n\n\n:::\n:::\n\nThis finding is a sign of an inconsistency in the data set - and just a first example for why we care about normal forms. Here, we identify the first entry in the results below as a completely different animal - it is male and lives in a different location. Most likely, this is a wrongly identified animal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby %>% \n  filter(Anim == 125) %>% head() %>% \n  knitr::kable(caption=\"Based on the listing for the values of animal 125, the very first entry does not fit in well with the other values.\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Based on the listing for the values of animal 125, the very first entry does not fit in well with the other values.\n\n| Anim| Sex|Loca | Leng| Head| Ear| Arm| Leg| Pes| Tail| Weight| Age|\n|----:|---:|:----|----:|----:|---:|---:|---:|---:|----:|------:|---:|\n|  125|   1|Ha   |   NA|  566| 276| 354| 766| 642| 1310|   1590| 166|\n|  125|   2|H1   |   NA|  112|  NA|  53|  62|  48|   93|     NA|  10|\n|  125|   2|H1   |   NA|  166|  54|  80| 112|  79|  156|     NA|  26|\n|  125|   2|H1   |   NA|  208|  74| 108| 157| 105|  222|     NA|  38|\n|  125|   2|H1   |   NA|  255| 104| 134| 204| 147|  326|    160|  52|\n|  125|   2|H1   |   NA|  301| 117| 160| 260| 187|  389|    240|  66|\n\n\n:::\n:::\n\n\n<details>\n\n<summary>\n\nSome detective work shows us that the additional entry for animal 125 is probably a missing entry for animal 126.\n\n</summary>\n\n\n\nWith a bit of detective work, we can identify animal 126 as the most likely candidate for the set of measurements wrongly attributed to animal 125 (see @fig-wallaby125). The orange point corresponds to the entry wrongly assigned to animal 125. Its timing (`Age`) and value (`Weight`) make it the best fit for animal 126.\n\n\n::: {.cell}\n\n```\n## Error in ggplot(., aes(x = Age, y = Weight)): could not find function \"ggplot\"\n```\n:::\n\nIn @fig-wallaby126 all measurements for wallaby 126 are shown by age (in days) when they were taken. The additional measurement wrongly assigned to animal 125 is shown in orange. All of the values are sensible within the grow curves of animal 126.\n\n\n::: {.cell}\n\n```\n## Error in ggplot(., aes(x = Age, y = Measurement)): could not find function \"ggplot\"\n```\n:::\n\n</details>\n::::\n\n::: callout-tip\n#### Cleaning the Wallaby data {.unnumbered}\nAs a direct result of the normalization step, we make a change (!!!) to the orignial data.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cleaning Step 1\nwallaby_cleaner <- wallaby %>% \n  mutate(Anim = ifelse(Anim==125 & Sex==1, 126, Anim))\n```\n:::\n\nMaking any changes to a dataset should never be done light-heartedly,  always be well argued and well-documented. For the present example, we will keep the above investigation as argument, and the code to show the exact nature of the cleaning step.\n:::\n\n::: callout-important\n#### Second Normal Form {.unnumbered}\n\nA data set is in *second normal form*, if \n\n1. it is in first normal form, and\n2. all non-key variables depend on all parts of the key (no split key).\n\nNote, that tables in 1st normal form with a single key variable are automatically in 2nd normal form.\n:::\n\nRegarding the example of the `wallaby` dataset, we see the dataset in its basic form is not in 2nd normal form, because the two non-key variables `Sex` (biological sex of the animal) and the animal's location (`Loca`) only depend on the animal number `Anim`, and not on the `Age` variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby2 %>% group_by(Anim) \n## # A tibble: 78 × 4\n## # Groups:   Anim [77]\n##     Anim   Sex Loca  measurements     \n##    <int> <int> <chr> <list>           \n##  1    45     1 G     <tibble [49 × 9]>\n##  2    47     1 G     <tibble [49 × 9]>\n##  3    53     2 G     <tibble [50 × 9]>\n##  4    57     2 G     <tibble [49 × 9]>\n##  5    65     2 G     <tibble [42 × 9]>\n##  6    79     2 K     <tibble [39 × 9]>\n##  7    81     2 K     <tibble [36 × 9]>\n##  8    87     1 G     <tibble [34 × 9]>\n##  9    92     2 G     <tibble [28 × 9]>\n## 10    93     2 W     <tibble [28 × 9]>\n## # ℹ 68 more rows\n```\n:::\n\n\n\n#### Normalization step: 1st NF to 2nd NF\n\nWe can bring any data set that is in 1st normal form into second normal form by splitting the data set into two parts: all non-key elements that only depend on a part of the key are moved into a second data set, together with a copy of the part of the key that those elements rely on. All duplicate rows in the second dataset then need to be removed. \n\nThis construction results in two tables that are in 2nd normal form. \n\n::: callout-caution\n#### Example: Getting the `wallaby` data into 2nd normal form {.unnumbered}\n\nIn the example of the `wallaby` data, we have identified the non-key variables `Sex` and `Loca` to only depend on the animal's number - i.e. the values of these variables are animal-specific demographics, that do not change over the course of their lifetime. \n\nWe separate those variables into the data set `wallaby_demographics` and reduce the number of rows by finding a tally of the number of rows we summarize. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby_demographics <- wallaby_cleaner %>% \n  select(Anim, Sex, Loca) %>%\n  count(Anim, Sex, Loca) \n# Don't need the total number\n```\n:::\n\nOnce we have verified that `Anim` is a key for `wallaby_demographics`, we know that this table is in 2nd normal form. \n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby_demographics %>% \n  count(Anim, sort=TRUE) %>% \n  head()\n##   Anim n\n## 1   44 1\n## 2   45 1\n## 3   46 1\n## 4   47 1\n## 5   48 1\n## 6   53 1\n```\n:::\n\nWith the key-splitting variables `Sex` and `Loca` being taken care of in the second dataset, we can safely remove those variables from the original data. To preserve the original, we actually create a separate copy called `wallaby_measurements`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby_measurements <- wallaby_cleaner %>% \n  select(-Sex, -Loca) \n\nwallaby_measurements %>%\n  head()\n##   Anim Leng Head Ear Arm Leg Pes Tail Weight Age\n## 1   45   NA  123  NA  59  69  59   93     NA  14\n## 2   45   NA  178  54  90 120  92  185     NA  28\n## 3   45   NA  250  92 130 210 142  307     NA  49\n## 4   45   NA  324 108 174 284 205  454    290  69\n## 5   45   NA  369 129 198 340 257  568    410  83\n## 6   45   NA  408 155 237 411 308  648    570  97\n```\n:::\n\n\nThe `wallaby_measurements` dataset has the combination of `Anim` and `Age` as a key, and all of the variables are measurement that depend on both the animal and its age. This dataset is therefore also in second normal form.\n:::\n\nIn the normalization process we spotted one inconsistency (animal 125), which we resolved earlier, and we reduced the overall size of the data has been reduced from 12 x 1463 = 17,556 to the sum of 4 x 77 = 308 and 10 x 1463 = 14,630 for the   `wallaby_demographics` and the `wallaby_measurements` data, respectively. \n\n::: callout-important\n#### Third Normal Form {.unnumbered}\n\nA table is in *third normal form*, if \n\n- the table is in 2nd normal form, and\n- no non-key variable determines the values of another non-key variable.\n:::\n\nBeing able to determine whether any (combination of) non-key variables determine(s) the values of other non-key variables, is a hard task. We would need to be the data experts in a lot of areas, and even then, we might miss some dependencies and declare a table to be in third normal form when, in fact, it is not. \n\nRather than this form of the third normal form, we often employ a stricter normal form, to only allow a single non-key variable to ensure that there are no dependencies left between non-key variables. This form is also called  *key-value pairs* \n\n::: callout-important\n#### Key-Value Pairs (KVP) {.unnumbered}\n\nA table is in *key-value representation*, if\n\n- the table is in 2nd form, and\n- there is only a single non-key column. \n:::\n\nNow we are finally at the point that we are connecting to the previous section on reshaping data. The way to bring data into key-value representation, is a transformation from a wide data form to a long form as described in @sec-pivot-operations on Pivot Operations. \n\n:::: callout-caution\n#### The wallaby data in key-value-pair form {.unnumbered}\nIn the previous section, we have separated the original `wallaby` data into two parts: the `wallaby_demographics` and `wallaby_measurements` data sets. \n\nWe demonstrate two different ways of bringing datasets into key-value pairs, using these two different datasets \n\n1. Splitting into parts\n\nFor the `wallaby_demographics`, we will split the data into two parts: `wallaby_sex` and `wallaby_location`: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby_sex <- wallaby_demographics %>% select(Anim, Sex)\nwallaby_Location <- wallaby_demographics %>% select(Anim, Loca)\n```\n:::\n\n\n2. Pivoting\n\nAnother approach to bringing a dataset into key-value pairs is to summarize the values of a set of variables by introducing a new key for the variable names:\n\n::: panel-tabset\n##### R {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwallaby_measurements_long <- wallaby_measurements %>% \n  pivot_longer(cols = 'Leng':'Weight', names_to=\"Traits\", values_to=\"Measurements\", \n               values_drop_na = TRUE)\n\ndim(wallaby_measurements_long)\n## [1] 9905    4\nhead(wallaby_measurements_long)\n## # A tibble: 6 × 4\n##    Anim   Age Traits Measurements\n##   <dbl> <int> <chr>         <int>\n## 1    45    14 Head            123\n## 2    45    14 Arm              59\n## 3    45    14 Leg              69\n## 4    45    14 Pes              59\n## 5    45    14 Tail             93\n## 6    45    28 Head            178\n```\n:::\n\nBy specifying `values_drop_na` as `TRUE` we exclude all measurements that could not be taken, such as `Weight` for about the first 50 days of age, and `Leng` for the animal until the joey is ready to leave the safety of the pouch. Note, that while this normalization step might save space, the structural nature of missing values might be further hidden.\n\n##### Python {.unnumbered}\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\nwallaby_measurements_long = pd.melt(r.wallaby_measurements, \n  id_vars=['Anim', 'Age'], \n  var_name = 'Traits',\n  value_name = 'Measurements')\n  \nwallaby_measurements_long = wallaby_measurements_long[\n    wallaby_measurements_long['Measurements'] >= 0\n  ]\n\nwallaby_measurements_long  \n##         Anim  Age  Traits  Measurements\n## 24      45.0  377    Leng           844\n## 25      45.0  405    Leng           855\n## 26      45.0  432    Leng           873\n## 27      45.0  482    Leng           902\n## 28      45.0  517    Leng           905\n## ...      ...  ...     ...           ...\n## 11699  125.0  289  Weight         19840\n## 11700  125.0  297  Weight         19330\n## 11701  125.0  310  Weight         20910\n## 11702  125.0  332  Weight         23770\n## 11703  125.0  486  Weight         25000\n## \n## [9905 rows x 4 columns]\n```\n:::\n\n\nMissing values in the R data set are interpreted as the value -2147483648 in python.\nWe need to ensure that we remove all of these values (or convert them to `NaN`)\n\n:::\n\n::::\n\n\n## Next steps\n\nUnits of measurements\n\nInvestigation of missing values: missing at random?\n\n\n::: callout-learnmore\n## Other resources\n\nFrom Decomplexify's Youtube channel: [Learn Database Normalization - 1NF, 2NF, 3NF, 4NF, 5NF](https://www.youtube.com/watch?v=GFQaEYEc8_8)\n\n:::\n\n## References\n",
    "supporting": [
      "05b-normal-forms_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}