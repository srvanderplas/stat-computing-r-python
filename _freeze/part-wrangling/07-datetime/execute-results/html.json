{
  "hash": "f7d7914604dd27a9670088a54e0ec34b",
  "result": {
    "engine": "knitr",
    "markdown": "# Dates and Times {#sec-datetime}\n\n## Objectives {-}\n\n-   Understand the complexities of working with datetime data\n-   Create datetime formatted data from character and numeric encodings\n-   Format/print datetime data in the desired format\n\n## Why Dates and Times are hard\n\nI'm going to let Tom Scott deliver this portion of the material for me, as his times and timezones video is excellent and entertaining.\n\n::: youtube-video-container\n<iframe src=\"https://www.youtube.com/embed/-5wpm-gesOY\" title=\"The Problem with Time &amp; Timezones - Computerphile\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen>\n\n</iframe>\n:::\n\nThere is also an excellent StackOverflow question @freewindWhySubtractingThese2021 and answers [@skeetAnswerWhySubtracting2011,@borgwardtAnswerWhySubtracting2011] demonstrating exactly how times and time zones can get very confusing even in relatively simple circumstances.\n\nLong story short, we will be using libraries in R and python which handle some of these complexities for us, because dates, times, and timezones are **hard** and we *really* don't want to know exactly how hard they are.\nThe libraries I've chosen for this are `datetime` in Python (used by Pandas), and `lubridate` in R.\n\n::: callout-tip\n## Try It Out - Getting Set up\n\n::: panel-tabset\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"lubridate\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\n# get current date/time\ntoday()\n## [1] \"2025-08-16\"\nnow()\n## [1] \"2025-08-16 10:48:22 CDT\"\n```\n:::\n\n\n\n\n[Lubridate cheat sheet](https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf) [Lubridate documentation](https://lubridate.tidyverse.org/)\n\n### Python\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npip install datetime\n```\n:::\n\n\n\n\nOr, if you prefer IPython magic...\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n%pip install datetime\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport datetime\n\ntoday = datetime.date.today()\ntoday\n## datetime.date(2025, 8, 16)\nprint(today)\n## 2025-08-16\n\nnow = datetime.datetime.now()\nnow\n## datetime.datetime(2025, 8, 16, 10, 48, 23, 162897)\nprint(now)\n## 2025-08-16 10:48:23.162897\n```\n:::\n\n\n\n\n[pandas datetime documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html)\n:::\n:::\n\n## Getting Started\n\nLet's differentiate between three types of data which refer to a point in time:\n\n-   a **date**\n-   a **time** within a day\n-   a **date-time** - a specific time on a specific date\n\nNow, let's think about all of the different ways we can specify dates.\nThe table below has examples along with `strptime` formats that are used in both `R` and `python` for telling the computer which date format is used.\n\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n|           | Example             | Type      | Notes                                 | `strptime` format |\n+==========:+=====================+===========+=======================================+==================:+\n| 1         | January 12, 2023    | date      | Common in US/N. America               | %B %d, %Y         |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 2         | 12 January 2023     | date      | Common in Europe                      | %d %B %Y          |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 3         | 01/12/2023          | date      | Common in US                          | %m/%d/%Y          |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 4         | 1/12/23             | date      | Common in US                          | %m/%d/%y          |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 5         | 12/01/2023          | date      | Common in Europe/Asia                 | %d/%m/%Y          |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 6         | 2023-01-12          | date      | ISO 8601 standard\\                    | %Y-%m-%d\\         |\n|           |                     |           | (automatically sorts chronologically) | or %F             |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 7         | 12 2023             | date      | day of year + year                    | %j %Y             |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 8         | 9:23 PM             | time      | 12h time                              | %I:%M %p          |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 9         | 21:23               | time      | 24h time (military time)              | %H:%M\\            |\n|           |                     |           |                                       | or %R             |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 10        | 21:23:05            | time      | 24h time (with seconds)               | %H:%M:%S\\         |\n|           |                     |           |                                       | or %T             |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n| 11        | 2023-01-12T21:23:05 | datetime  | ISO 8601 international standard       | %FT%T             |\n+-----------+---------------------+-----------+---------------------------------------+-------------------+\n\n: Different ways to specify dates and times. {#tbl-formats}\n\nNote that rows 4 and 5 of @tbl-formats are ambiguous if you don't know what location your data comes from - the dates could refer to December 1, 2023 or January 12, 2023.\nThis only gets worse if you use 2-digit years.\n\nThere are three main ways that you might want to create a date/time @grolemundDatesTimes:\n\n-   From a string\n-   From individual date/time components\n-   From an existing date/time object\n\n## Creating Dates and Times\n\n### Creation from Strings\n\nDates and times are often stored in tabular formats as strings.\nIn some cases, these are read in and automatically formatted as date-times, but in other situations, you have to specify the format yourself.\n\n::: callout-demo\n#### Demo: Datetimes from Strings\n\nLet's use some data from the US Geological Service with records of earthquakes with magnitude greater than 6 on the Richter scale that occurred between January 1, 2000 and January 1, 2023.\nYou can pull this data yourself using https://earthquake.usgs.gov/earthquakes/map/, but you can also access a CSV of the data [here](https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv).\n\n::: panel-tabset\n##### R + lubridate\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nquake <- read.csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake)\n## 'data.frame':\t3484 obs. of  13 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n```\n:::\n\n\n\n\nBy default, `read.csv` reads the time information in as a character variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nquake2 <- read_csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake2)\n## spc_tbl_ [3,484 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ #EventID         : chr [1:3484] \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : POSIXct[1:3484], format: \"2022-12-28 16:34:20\" \"2022-12-20 10:34:24\" ...\n##  $ Latitude         : num [1:3484] -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num [1:3484] 171 -124 179 -101 -173 ...\n##  $ Depth/km         : num [1:3484] 10 17.9 73 18 38 ...\n##  $ Author           : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr [1:3484] \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr [1:3484] \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num [1:3484] 6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr [1:3484] \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr [1:3484] \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   `#EventID` = col_character(),\n##   ..   Time = col_datetime(format = \"\"),\n##   ..   Latitude = col_double(),\n##   ..   Longitude = col_double(),\n##   ..   `Depth/km` = col_double(),\n##   ..   Author = col_character(),\n##   ..   Catalog = col_character(),\n##   ..   Contributor = col_character(),\n##   ..   ContributorID = col_character(),\n##   ..   MagType = col_character(),\n##   ..   Magnitude = col_double(),\n##   ..   MagAuthor = col_character(),\n##   ..   EventLocationName = col_character()\n##   .. )\n##  - attr(*, \"problems\")=<externalptr>\n```\n:::\n\n\n\n\nHowever, if we use `readr::read_csv`, the data is correctly read in as a `POSIXct` format, which is how R indicates that something is a datetime object.\n\nIf we want to directly convert the Time column in `quake` to a datetime, we can use the `lubridate` package, which has helper functions `ymd_hms`, `ymd`, and more.\nOur data is formatted in ISO 8601 standard format, which means we can easily read it in with `ymd_hms()` .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(dplyr)\nquake <- quake %>% \n  mutate(dateTime = ymd_hms(Time))\nstr(quake)\n## 'data.frame':\t3484 obs. of  14 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\n##  $ dateTime         : POSIXct, format: \"2022-12-28 16:34:20\" \"2022-12-20 10:34:24\" ...\n```\n:::\n\n\n\n\nWe can then test whether `quake$dateTime` is the same as `quake2$Time` :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall.equal(quake2$Time, quake$dateTime)\n## [1] TRUE\n```\n:::\n\n\n\n\nSo in the case that your data is not automatically read in as a date-time, you can use the helper functions from lubridate (`ymd_hms`, `ymd`, `mdy`, ...) to convert strings to date-time data.\n\n##### Base R\n\nAs lovely as the lubridate package is, there are some situations where using the tidyverse may not be desirable or even allowed.\nIt is helpful to know how to solve this problem in base R, even if 99% of the time we can use the much easier-to-remember lubridate package.\n\nIn this case, we would use the `as.POSIXct` function, and we probably want to have the reference page up (run `?strptime` in the R console to pull up the help page).\n\nWe'll need to get the codes that tell R what format our datetimes use - you can use @tbl-formats, if you like, or read the `as.POSIXct` help page to see all possible format codes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquake <- read.csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nstr(quake)\n## 'data.frame':\t3484 obs. of  13 variables:\n##  $ X.EventID        : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ Time             : chr  \"2022-12-28T16:34:20Z\" \"2022-12-20T10:34:24Z\" \"2022-12-14T18:40:26Z\" \"2022-12-11T14:31:29Z\" ...\n##  $ Latitude         : num  -21.3 40.5 51.6 17.2 -15.3 ...\n##  $ Longitude        : num  171 -124 179 -101 -173 ...\n##  $ Depth.km         : num  10 17.9 73 18 38 ...\n##  $ Author           : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Catalog          : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ Contributor      : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ ContributorID    : chr  \"us7000j0n4\" \"nc73821036\" \"us6000j985\" \"us6000j8lp\" ...\n##  $ MagType          : chr  \"mww\" \"mw\" \"mww\" \"mww\" ...\n##  $ Magnitude        : num  6.1 6.4 6.3 6 6.8 6.1 6.2 6 7 6.9 ...\n##  $ MagAuthor        : chr  \"us\" \"nc\" \"us\" \"us\" ...\n##  $ EventLocationName: chr  \"southeast of the Loyalty Islands\" \"15km WSW of Ferndale, CA\" \"Rat Islands, Aleutian Islands, Alaska\" \"8 km E of Técpan de Galeana, Mexico\" ...\nquake$dateTime2 <- as.POSIXct(quake$Time, \"%Y-%m-%dT%H:%M:%S\")\nall.equal(quake$dateTime, quake$dateTime2)\n## [1] TRUE\n```\n:::\n\n\n\n\nSo using `as.POSIXct` we do not get the convenient handling of time zones that we got using `ymd_hms`, but we can set the time zone explicitly if we want to do so.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquake$dateTime2 <- as.POSIXct(quake$Time, tz = \"UTC\", \"%Y-%m-%dT%H:%M:%S\")\nall.equal(quake$dateTime, quake$dateTime2)\n## [1] TRUE\n```\n:::\n\n\n\n\n##### Pandas\n\nIn pandas, we can use the `to_datetime` method.\nIf the format is not specified, pandas will try to guess the date-time format; in this case, the guess works, but if not, you can provide a `format = …` argument that works the same way as R.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nquake = pd.read_csv(\"https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv\")\nquake.dtypes\n## #EventID              object\n## Time                  object\n## Latitude             float64\n## Longitude            float64\n## Depth/km             float64\n## Author                object\n## Catalog               object\n## Contributor           object\n## ContributorID         object\n## MagType               object\n## Magnitude            float64\n## MagAuthor             object\n## EventLocationName     object\n## dtype: object\n\nquake.Time[0:10]\n## 0    2022-12-28T16:34:20Z\n## 1    2022-12-20T10:34:24Z\n## 2    2022-12-14T18:40:26Z\n## 3    2022-12-11T14:31:29Z\n## 4    2022-12-04T19:24:15Z\n## 5    2022-11-23T01:08:15Z\n## 6    2022-11-22T16:39:05Z\n## 7    2022-11-22T02:37:57Z\n## 8    2022-11-22T02:03:06Z\n## 9    2022-11-18T13:37:08Z\n## Name: Time, dtype: object\n\n# Convert to datetime\nquake['dateTime'] = pd.to_datetime(quake.Time)\nquake.dtypes\n## #EventID                          object\n## Time                              object\n## Latitude                         float64\n## Longitude                        float64\n## Depth/km                         float64\n## Author                            object\n## Catalog                           object\n## Contributor                       object\n## ContributorID                     object\n## MagType                           object\n## Magnitude                        float64\n## MagAuthor                         object\n## EventLocationName                 object\n## dateTime             datetime64[ns, UTC]\n## dtype: object\nquake.dateTime[0:10]\n## 0   2022-12-28 16:34:20+00:00\n## 1   2022-12-20 10:34:24+00:00\n## 2   2022-12-14 18:40:26+00:00\n## 3   2022-12-11 14:31:29+00:00\n## 4   2022-12-04 19:24:15+00:00\n## 5   2022-11-23 01:08:15+00:00\n## 6   2022-11-22 16:39:05+00:00\n## 7   2022-11-22 02:37:57+00:00\n## 8   2022-11-22 02:03:06+00:00\n## 9   2022-11-18 13:37:08+00:00\n## Name: dateTime, dtype: datetime64[ns, UTC]\n\n# Convert to datetime\nquake['dateTime2'] = pd.to_datetime(quake.Time, format = \"%Y-%m-%dT%H:%M:%S\")\n## ValueError: unconverted data remains when parsing with format \"%Y-%m-%dT%H:%M:%S\": \"Z\", at position 0. You might want to try:\n##     - passing `format` if your strings have a consistent format;\n##     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n##     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\nquake.dtypes\n## #EventID                          object\n## Time                              object\n## Latitude                         float64\n## Longitude                        float64\n## Depth/km                         float64\n## Author                            object\n## Catalog                           object\n## Contributor                       object\n## ContributorID                     object\n## MagType                           object\n## Magnitude                        float64\n## MagAuthor                         object\n## EventLocationName                 object\n## dateTime             datetime64[ns, UTC]\n## dtype: object\nquake.dateTime2[0:10]\n## AttributeError: 'DataFrame' object has no attribute 'dateTime2'\n```\n:::\n\n\n\n:::\n:::\n\n::: callout-tip\n#### Try it Out - Datetimes from Strings\n\nIt's usually important for new parents to keep a log of the new baby's feeds, to ensure that the baby is getting enough liquids and isn't getting dehydrated.\nI used an app to keep track of my daughter's feeds from birth (though here, we'll only work with [the first 3 months of data](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv)), and it used a reasonable, if not standard way to store dates and times.\n\n::: panel-tabset\n##### Problem\n\nTake a look at the [first month of feeds](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv).\nNote that these data are from August 7, 2021 to November 4, 2021 -- roughly baby's first 90 days.\n\n1.  Convert Start and End to datetime variables\n2.  Can you plot the feeds somehow?\n3.  Can you do arithmetic with datetimes to see if there are any user entry errors?\\\n    This data was created by a *highly* unreliable and error prone couple of individuals -- specifically, sleep-deprived new parents.\n\nTo do this, you may need to figure out how to specify a non-standard date format in R and/or python.\nThe `parse_date_time` function is useful in R, and `pd.to_datetime()` takes a format argument in python.\n\n##### R solution\n\nFirst, let's read the data in and explore a bit.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nlibrary(readr)\nfeeds <- read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv\")\nhead(feeds)\n## # A tibble: 6 × 6\n##      id Start               End       Type  `Quantity (oz)` `Quantity (ml or g)`\n##   <dbl> <chr>               <chr>     <chr>           <dbl>                <dbl>\n## 1  1368 20:03:30 11-04-2021 20:45:21… Brea…              NA                   NA\n## 2  1366 18:00:29 11-04-2021 18:18:29… Brea…              NA                   NA\n## 3  1365 16:27:29 11-04-2021 17:03:26… Brea…              NA                   NA\n## 4  1364 14:30:01 11-04-2021 14:42:05… Brea…              NA                   NA\n## 5  1367 12:48:29 11-04-2021 13:50:29… Bott…               3                   88\n## 6  1363 10:59:18 11-04-2021 11:15:18… Bott…               3                   88\n\n# Looks like %H:%M:%S %m-%d-%Y format.\n```\n:::\n\n\n\n\nIt looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second.\nWe can use the `parse_date_time` function in lubridate\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeeds <- feeds %>%\n  mutate(Start = parse_date_time(Start, orders = c(\"%H:%M:%S %m-%d-%Y\")),\n         End = parse_date_time(End, orders = c(\"%H:%M:%S %m-%d-%Y\")))\n```\n:::\n\n\n\n\nLet's then explore how we might plot this data:\n\n\n\n\n::: {.cell fig-caption='Feeds in the first 90 days of an infant\\'s life.'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(feeds, aes(xmin = Start, xmax = End, fill = Type)) + \n  geom_rect(aes(ymin = 1, ymax = 2)) + # Specify default aes\n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  theme_bw() + theme(legend.position = \"bottom\") + \n  scale_y_continuous(breaks = NULL)\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-15-1.png){width=1800}\n:::\n:::\n\n::: {.cell fig-caption='Feeds in the first 90 days of an infant\\'s life, by hour of the day.'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nfeeds %>%\n  mutate(day = floor_date(Start, \"day\"),\n         hour_start = Start - day,\n         hour_end = End - day) %>%\n  mutate(across(starts_with(\"hour\"), ~as.numeric(., units = \"hours\"))) %>%\n  mutate(doy = yday(day)) %>%\nggplot(aes(ymin = day, ymax = day+days(1), xmin = hour_start, xmax = hour_end, fill = Type)) + \n  geom_rect() + # Specify default aes\n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  scale_x_continuous(\"Hour of the day\") + \n  theme_bw() + theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-16-1.png){width=1800}\n:::\n:::\n\n\n\n\nWe can also calculate the duration of each feed and look at the distributions for each type of feed.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfeeds <- feeds %>%\n  mutate(duration = End - Start)\n\nggplot(feeds, aes(x = duration, fill = Type)) + geom_histogram(color = \"black\") + \n  scale_fill_manual(values = c(\"Bottle\" = \"cornflowerblue\", \"Breast\" = \"pink\")) + \n  theme_bw() + theme(legend.position = \"none\") + \n  xlab(\"Feed duration, in seconds\") + facet_wrap(~Type)\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-17-1.png){width=2100}\n:::\n:::\n\n\n\n\nWe can see a few suspiciously long feeds - 9000 seconds is 2.5 hours, which is not unheard of for a baby to breastfeed, but would be an exceptionally long bottle feed (unless a parent fell asleep before hitting \"stop\" on the feed, which is much more likely).\n\n##### Python solution\n\nFirst, let's read the data in and explore a bit.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\nfeeds = pd.read_csv(\"https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv\")\nfeeds.head()\n##      id                Start  ... Quantity (oz) Quantity (ml or g)\n## 0  1368  20:03:30 11-04-2021  ...           NaN                NaN\n## 1  1366  18:00:29 11-04-2021  ...           NaN                NaN\n## 2  1365  16:27:29 11-04-2021  ...           NaN                NaN\n## 3  1364  14:30:01 11-04-2021  ...           NaN                NaN\n## 4  1367  12:48:29 11-04-2021  ...           3.0               88.0\n## \n## [5 rows x 6 columns]\n\n# Looks like %H:%M:%S %m-%d-%Y format.\n```\n:::\n\n\n\n\nIt looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second.\nWe can use the format argument to `pd.to_datetime` to specify this:\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfeeds[\"Start\"] = pd.to_datetime(feeds.Start, format = \"%H:%M:%S %m-%d-%Y\")\nfeeds[\"End\"] = pd.to_datetime(feeds.End, format = \"%H:%M:%S %m-%d-%Y\")\nfeeds.head()\n##      id               Start  ... Quantity (oz) Quantity (ml or g)\n## 0  1368 2021-11-04 20:03:30  ...           NaN                NaN\n## 1  1366 2021-11-04 18:00:29  ...           NaN                NaN\n## 2  1365 2021-11-04 16:27:29  ...           NaN                NaN\n## 3  1364 2021-11-04 14:30:01  ...           NaN                NaN\n## 4  1367 2021-11-04 12:48:29  ...           3.0               88.0\n## \n## [5 rows x 6 columns]\n```\n:::\n\n\n\n\nIn Python, it is helpful to do a bit of transformation first - this is partly because I'm not as good with Python plotting systems.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport datetime as dt\nfeeds[\"day\"] = feeds.Start.dt.strftime(\"%Y-%m-%d\")\nfeeds[\"day\"] = pd.to_datetime(feeds.day, format = \"%Y-%m-%d\")\nfeeds[\"day_end\"] = feeds.day + dt.timedelta(days = 1)\n\nfeeds[\"time_start\"] = feeds.Start - feeds.day\nfeeds[\"time_end\"] = feeds.End - feeds.day\nfeeds[\"duration\"] = feeds.time_end - feeds.time_start\n```\n:::\n\n\n\n\nNote that as of January 2023, RStudio does not correctly display timedelta data types in python.\nThey show up as NAs in the table, but are printed fine in the console.\nDon't spend hours trying to figure out why it isn't working -- it's bad enough that I did.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n(\n  ggplot(feeds, aes(xmin = \"Start\", xmax = \"End\", fill = \"Type\")) + \n  geom_rect(aes(ymin = 1, ymax = 2)) + \n  scale_fill_manual(values = [\"cornflowerblue\", \"pink\"]) + \n  theme_bw() + scale_y_continuous(breaks = [])\n)\n## <plotnine.ggplot.ggplot object at 0x7f7dd489b390>\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom plotnine import *\n\n(\n  ggplot(feeds, aes(xmin = \"time_start\", xmax = \"time_end\", ymin = \"day\", ymax = \"day_end\", fill = \"Type\")) + \n  geom_rect() + \n  scale_fill_manual(values = [\"cornflowerblue\", \"pink\"]) + \n  theme_bw()\n)\n## <plotnine.ggplot.ggplot object at 0x7f7dc67dd150>\n```\n:::\n\n\n\n:::\n:::\n\n### Creation from Components\n\nSometimes, instead of a single string, you'll have the individual components of the date-time spread across columns.\nThe `nycflights13` data is a good example of this.\n\n::: callout-demo\n#### Demo: Datetimes from Components\n\n::: panel-tabset\n##### R + lubridate\n\nIn `lubridate`, the `make_date()` and `make_datetime()` functions can be used to create date-times from component pieces.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nycflights13)\n\nflights %>%\n  select(year, month, day, hour, minute) %>% \n  head()\n## # A tibble: 6 × 5\n##    year month   day  hour minute\n##   <int> <int> <int> <dbl>  <dbl>\n## 1  2013     1     1     5     15\n## 2  2013     1     1     5     29\n## 3  2013     1     1     5     40\n## 4  2013     1     1     5     45\n## 5  2013     1     1     6      0\n## 6  2013     1     1     5     58\n\nflights <- flights %>%\n  mutate(date = make_date(year, month, day),\n         datetime = make_datetime(year, month, day, hour, minute))\n\nflights %>% select(date, datetime, year, month, day, hour, minute)\n## # A tibble: 336,776 × 7\n##    date       datetime             year month   day  hour minute\n##    <date>     <dttm>              <int> <int> <int> <dbl>  <dbl>\n##  1 2013-01-01 2013-01-01 05:15:00  2013     1     1     5     15\n##  2 2013-01-01 2013-01-01 05:29:00  2013     1     1     5     29\n##  3 2013-01-01 2013-01-01 05:40:00  2013     1     1     5     40\n##  4 2013-01-01 2013-01-01 05:45:00  2013     1     1     5     45\n##  5 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  6 2013-01-01 2013-01-01 05:58:00  2013     1     1     5     58\n##  7 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  8 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n##  9 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n## 10 2013-01-01 2013-01-01 06:00:00  2013     1     1     6      0\n## # ℹ 336,766 more rows\n```\n:::\n\n\n\n\n##### Base R\n\nIn base R, we can use the `ISOdate` function to create date times.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$datetime_base = with(flights, ISOdatetime(year, month, day, hour, minute, sec= 0, tz=\"UTC\"))\nall.equal(flights$datetime, flights$datetime_base)\n## [1] TRUE\n```\n:::\n\n\n\n\n##### Python\n\nIn pandas, we can pass multiple columns to `pd.to_datetime()` and as long as they are named reasonably, pandas will handle the conversion.\nIf we want to have the date but not the time for some reason, we just pass fewer columns to pandas.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom nycflights13 import flights\n\nflights[[\"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n##         year  month  day  hour  minute\n## 0       2013      1    1     5      15\n## 1       2013      1    1     5      29\n## 2       2013      1    1     5      40\n## 3       2013      1    1     5      45\n## 4       2013      1    1     6       0\n## ...      ...    ...  ...   ...     ...\n## 336771  2013      9   30    14      55\n## 336772  2013      9   30    22       0\n## 336773  2013      9   30    12      10\n## 336774  2013      9   30    11      59\n## 336775  2013      9   30     8      40\n## \n## [336776 rows x 5 columns]\n\nflights[\"date\"] = pd.to_datetime(flights[[\"year\", \"month\", \"day\"]])\nflights[\"datetime\"] = pd.to_datetime(flights[[\"year\", \"month\", \"day\", \"hour\", \"minute\"]])\n\n\nflights[[\"date\", \"datetime\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]]\n##              date            datetime  year  month  day  hour  minute\n## 0      2013-01-01 2013-01-01 05:15:00  2013      1    1     5      15\n## 1      2013-01-01 2013-01-01 05:29:00  2013      1    1     5      29\n## 2      2013-01-01 2013-01-01 05:40:00  2013      1    1     5      40\n## 3      2013-01-01 2013-01-01 05:45:00  2013      1    1     5      45\n## 4      2013-01-01 2013-01-01 06:00:00  2013      1    1     6       0\n## ...           ...                 ...   ...    ...  ...   ...     ...\n## 336771 2013-09-30 2013-09-30 14:55:00  2013      9   30    14      55\n## 336772 2013-09-30 2013-09-30 22:00:00  2013      9   30    22       0\n## 336773 2013-09-30 2013-09-30 12:10:00  2013      9   30    12      10\n## 336774 2013-09-30 2013-09-30 11:59:00  2013      9   30    11      59\n## 336775 2013-09-30 2013-09-30 08:40:00  2013      9   30     8      40\n## \n## [336776 rows x 7 columns]\n```\n:::\n\n\n\n:::\n:::\n\n<!-- ## Creation from other objects -->\n\n### Creation from Other Objects\n\nSometimes, you may have information in one type of variable (e.g. a datetime) and want to split it into a date and a time, separately.\n\nSome systems store datetimes as the number of seconds from a specific point (commonly, the **Unix Epoch**, midnight on 1970-01-01).\nYou may have to convert from seconds since this epoch (or some other epoch [@wikipediacontributorsEpochComputing2023]) to an actual date-time that is human readable.\n\nIf you ever have to convert dates and times that were stored in Microsoft Excel, it can be helpful to know that Microsoft stores dates as the number of days since January 1, 1900 [@microsoftsupportDATEVALUEFunctionMicrosoft2023] (or if the spreadsheet was created on a Mac, January 1, 1904) [@elizabethmottWhyDatesCome2013].\nYes, this is as confusing as it sounds.\nDon't use MS Excel for handling dates [@caudillExcelHellCautionary2018; @chris88888888ExcelStillSucks2020] (or really, at all, now that you know better tools).\nGeneticists have actually renamed genes because Microsoft won't fix Excel to handle dates properly [@vincentScientistsRenameHuman2020].\n\n::: callout-demo\n#### Demo: Creation from Other Objects\n\n::: panel-tabset\n##### R + lubridate\n\nIn `lubridate`, the `as_date()` and `as_datetime()` functions can be used to create date-times from other objects.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp <- flights %>%\n  mutate(date2 = as_date(datetime))\n\n# Check that date and date2 are the same\nall.equal(flights$date, flights$date2)\n## [1] \"Modes: numeric, NULL\"                                \n## [2] \"Lengths: 336776, 0\"                                  \n## [3] \"Attributes: < Modes: list, NULL >\"                   \n## [4] \"Attributes: < Lengths: 1, 0 >\"                       \n## [5] \"Attributes: < names for target but not for current >\"\n## [6] \"Attributes: < current is not list-like >\"            \n## [7] \"target is Date, current is NULL\"\n```\n:::\n\n\n\n\nHere's a demonstration of epoch timekeeping.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncurrent_time <- now(tzone = \"UTC\")\n# This converts to the number of seconds since the Unix epoch\nseconds_since_epoch <- current_time %>% seconds()\n# Now let's convert back to a datetime\n(current_time2 <- as_datetime(seconds_since_epoch))\n## [1] \"2025-08-16 15:48:31 UTC\"\n# Check to see that they're equal\nall.equal(current_time, current_time2)\n## [1] TRUE\n```\n:::\n\n\n\n\n##### Base R\n\nIn base R, we can use the `as.Date` function to create dates from datetimes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$date2 = as.Date(flights$date)\nall.equal(flights$date, flights$date2)\n## [1] TRUE\n```\n:::\n\n\n\n\nWe can handle epochs as well:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's see what was 10000 days after the UNIX epoch\nas.Date(1e4, origin = \"1970-01-01\")\n## [1] \"1997-05-19\"\n\n# If we use as.POSIXct, we are counting in seconds from midnight\nas.POSIXct(1e4, origin = as.POSIXct(\"1970-01-01 00:00:00\"))\n## [1] \"1970-01-01 02:46:40 CST\"\n```\n:::\n\n\n\n\nBy default, `as.POSIXct` will use the system's time zone, which may not be desirable; you can always set the time zone yourself if you would like to do so.\n\n##### Python\n\nIn pandas, we can pass multiple columns to `pd.to_datetime()` and as long as they are named reasonably, pandas will handle the conversion.\nIf we want to have the date but not the time for some reason, we just pass fewer columns to pandas.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom nycflights13 import flights\n\nflights[\"date2\"] = flights.date.dt.date # Convert datetime to date\n\n# They look the same\nflights[[\"date\", \"date2\"]]\n##              date       date2\n## 0      2013-01-01  2013-01-01\n## 1      2013-01-01  2013-01-01\n## 2      2013-01-01  2013-01-01\n## 3      2013-01-01  2013-01-01\n## 4      2013-01-01  2013-01-01\n## ...           ...         ...\n## 336771 2013-09-30  2013-09-30\n## 336772 2013-09-30  2013-09-30\n## 336773 2013-09-30  2013-09-30\n## 336774 2013-09-30  2013-09-30\n## 336775 2013-09-30  2013-09-30\n## \n## [336776 rows x 2 columns]\n\nflights.dtypes\n## year                       int64\n## month                      int64\n## day                        int64\n## dep_time                 float64\n## sched_dep_time             int64\n## dep_delay                float64\n## arr_time                 float64\n## sched_arr_time             int64\n## arr_delay                float64\n## carrier                   object\n## flight                     int64\n## tailnum                   object\n## origin                    object\n## dest                      object\n## air_time                 float64\n## distance                   int64\n## hour                       int64\n## minute                     int64\n## time_hour                 object\n## date              datetime64[ns]\n## datetime          datetime64[ns]\n## date2                     object\n## dtype: object\n# date2 is an object, date is a datetime64.\n```\n:::\n\n\n\n\nWe created `flights.date` using `pd.to_datetime()`.\nGiven this comparison, it may be better to use to.datetime() and append `.dt.date` on the end if you do not want to keep the time information that is provided by default.\n:::\n:::\n\n## Working with Dates and Times\n\nIn this section, we'll work with comments by famous Reddit artist `Shitty_Watercolour`, who responds to people's comments with a quickly created watercolor-style painting.\n\n::: aside\nHere's one of Shitty Watercolour's works: ![[Reddit context.](https://www.reddit.com/r/AnimalsBeingDerps/comments/12bah0e/when_you_really_miss_your_bff/) [Image source](https://imgur.com/tpDBs4j)](../images/wrangling/watercolor_example.jpeg){fig-alt=\"A watercolor painting of a dog imagining touching a different dog through a laptop screen. The dogs apparently see each other once a month and facetime once a week.\"}\n:::\n\n::: callout-demo\n### Getting the Data\n\n::: panel-tabset\n#### R\n\nNote: The textbook caches data, so your results may differ from those shown here because `RedditExtractoR` only acquires the last \\~1000 comments from a user. In addition, in July 2003, reddit removed their API that allowed `RedditExtractoR` to function, so any future updates are sadly unlikely. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# remotes::install_github(\"ivan-rivera/RedditExtractor\")\nlibrary(RedditExtractoR)\n\ncomment_list <- get_user_content(\"Shitty_Watercolour\")\nwatercolour <- comment_list$Shitty_Watercolour$comments\n```\n:::\n\n\n\n\n\n\n#### Python\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Get data from R directly, since redditExtractor package is in R\nwatercolour = r.watercolour\n```\n:::\n\n\n\n:::\n:::\n\n### Time Zones\n\nWe often store data in UTC[^07-datetime-1], but we may want to represent the data in a more familiar time zone for interpretation's purposes.\n\n[^07-datetime-1]: Coordinated Universal Time, but the acronym is in a different language and the words are thus in a different order.\n\n| Task | Language | Function | \n| ---- | ---- | -------------------------------------------------------------| \n| Set the time zone | R | `as_datetime(time, tz = \"GMT\")` |\n| | Python | `time.apply(lambda x: pd.Timestamp(x).tz_localize(\"GMT\"))` |\n| Display the time in a diff TZ | R | `with_tz(time, tz = \"America/Chicago\")` | \n| | Python | `time.apply(lambda x: pd.Timestamp(x).tz_convert(\"America/Chicago\"))` |\n\n: Working with Time Zones. Here, `time` is a placeholder for whatever variable is being converted.\n\n::: callout-tip\n#### Try it Out - Formatting Dates\n\n::: panel-tabset\n##### Problem\n\nThe `watercolour` dataset above contains 959 comments from `Shitty_Watercolour`, with the UTC date and timestamp of the comment.\n\nFigure out how to format these data into a proper date type and timestamp that is user-readable.\nMake sure you inform R or python that the timestamp is provided in UTC.\n\n![Hovering over the time on a reddit comment will produce a popup showing the full time that the comment was posted.](../images/wrangling/reddit-timestamp-mouseover.png) Compare a couple of your timestamps to the timestamps provided by Reddit when you mouse over a comment.\n\nCan you get R or Python to output the date in your timezone?\n\n##### R Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwatercolour <- watercolour %>%\n  mutate(date = ymd(date_utc, tz = \"UTC\"),\n         time = as_datetime(timestamp),\n         time_cst = with_tz(time, tzone_out = \"CST\"))\n\nwatercolour[,c(\"date\", \"time\", \"time_cst\")]\n## # A tibble: 959 × 3\n##    date                time                time_cst           \n##    <dttm>              <dttm>              <dttm>             \n##  1 2017-12-19 00:00:00 2017-12-19 22:08:19 2017-12-19 16:08:19\n##  2 2017-12-19 00:00:00 2017-12-19 22:07:03 2017-12-19 16:07:03\n##  3 2017-12-19 00:00:00 2017-12-19 20:47:55 2017-12-19 14:47:55\n##  4 2017-12-19 00:00:00 2017-12-19 20:01:19 2017-12-19 14:01:19\n##  5 2017-12-17 00:00:00 2017-12-17 19:58:51 2017-12-17 13:58:51\n##  6 2017-12-15 00:00:00 2017-12-15 02:53:23 2017-12-14 20:53:23\n##  7 2017-12-12 00:00:00 2017-12-12 16:56:23 2017-12-12 10:56:23\n##  8 2017-12-08 00:00:00 2017-12-08 17:48:05 2017-12-08 11:48:05\n##  9 2017-12-08 00:00:00 2017-12-08 03:50:17 2017-12-07 21:50:17\n## 10 2017-12-07 00:00:00 2017-12-07 18:00:58 2017-12-07 12:00:58\n## # ℹ 949 more rows\n```\n:::\n\n\n\n\n##### Python Solution\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom datetime import datetime\n\nwatercolour[\"date\"] = pd.to_datetime(watercolour.date_utc).dt.date\nwatercolour[\"time\"] = pd.to_datetime(watercolour.timestamp, unit = 's')\n\n# Tell Python the time is in UTC \nwatercolour[\"time\"] = watercolour.time.apply(lambda x: pd.Timestamp(x).tz_localize(\"UTC\"))\n\nwatercolour[\"time_cst\"] = watercolour.time.apply(lambda x: pd.Timestamp(x).tz_convert(\"US/Central\"))\n\nwatercolour[[\"date\", \"time\", \"time_cst\"]]\n##            date                      time                  time_cst\n## 0    2017-12-19 2017-12-19 22:08:19+00:00 2017-12-19 16:08:19-06:00\n## 1    2017-12-19 2017-12-19 22:07:03+00:00 2017-12-19 16:07:03-06:00\n## 2    2017-12-19 2017-12-19 20:47:55+00:00 2017-12-19 14:47:55-06:00\n## 3    2017-12-19 2017-12-19 20:01:19+00:00 2017-12-19 14:01:19-06:00\n## 4    2017-12-17 2017-12-17 19:58:51+00:00 2017-12-17 13:58:51-06:00\n## ..          ...                       ...                       ...\n## 954  2023-02-21 2023-02-21 16:55:03+00:00 2023-02-21 10:55:03-06:00\n## 955  2023-02-21 2023-02-21 15:59:51+00:00 2023-02-21 09:59:51-06:00\n## 956  2023-02-21 2023-02-21 15:09:19+00:00 2023-02-21 09:09:19-06:00\n## 957  2023-02-21 2023-02-21 14:45:10+00:00 2023-02-21 08:45:10-06:00\n## 958  2023-02-21 2023-02-21 11:27:52+00:00 2023-02-21 05:27:52-06:00\n## \n## [959 rows x 3 columns]\n```\n:::\n\n\n\n:::\n:::\n\n### Time Spans\n\nDates and times can be added and subtracted - after all, underneath, they're usually implemented as a number of XXX from the reference time point, where XXX is usually seconds for datetimes and days for dates.\n\nIn R, the difference between two timestamps is called a **duration** and is implemented in the **duration** class [See @r4ds Chapter 16.4.1 for more info]. In Python, a similar class exists and is called a **timedelta** [@pythonfoundationDatetimeBasicDate2023].\n\n::: callout-tip\n#### Try it Out - Datetime Math\n\n::: panel-tabset\n##### Problem\n\nUse the `watercolour` data and plot the interval between successive `Shitty_Watercolour` posts in minutes. What can you conclude?\n\n\n##### R Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwatercolour <- watercolour %>%\n  arrange(time) %>%\n  mutate(diff = as.duration(time - lag(time, 1)),\n         diffmin = as.numeric(diff, \"minutes\"))\n\nlibrary(ggplot2)\nggplot(watercolour, aes(x = diffmin)) + \n  geom_histogram() + \n  xlab(\"Time between posts (minutes)\") + \n  ylab(\"# Posts\") + \n  scale_x_log10(breaks = c(1, 15, 30, 60, 1440, 10080))\n```\n\n::: {.cell-output-display}\n![](07-datetime_files/figure-html/unnamed-chunk-34-1.png){width=2100}\n:::\n:::\n\n\n\n\nMost of the time, `Shitty_Watercolour` takes at least 15 minutes to generate a new comment. There is also a noticable peak just before 1440 minutes, indicating that as with most users, `Shitty_Watercolour` is active at approximately the same time each day for a few hours. The final break shown, 10080, is the number of minutes in a week, indicating that occasionally, `Shitty_Watercolour` goes more than a week between posts.\n\n##### Python Solution\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom datetime import datetime\n\nwatercolour = watercolour.sort_values(by = 'time')\nwatercolour[\"diff\"] = watercolour.time.diff().astype('timedelta64')\n## ValueError: Cannot convert from timedelta64[ns] to timedelta64. Supported resolutions are 's', 'ms', 'us', 'ns'\n# This formats in minutes\nwatercolour[\"diffmin\"] = watercolour.time.diff().astype('timedelta64[m]')\n## ValueError: Cannot convert from timedelta64[ns] to timedelta64[m]. Supported resolutions are 's', 'ms', 'us', 'ns'\n# Remove negative minutes - something funky there?\nwatercolour = watercolour.query(\"diffmin > 0\")\n## pandas.errors.UndefinedVariableError: name 'diffmin' is not defined\n\nimport seaborn.objects as so\np = (\n  so.\n  Plot(watercolour, watercolour[\"diffmin\"]).\n  add(so.Bars(width=.95), so.Hist(bins = 30)).\n  scale(x = so.Continuous(trans = \"log\").\n    tick(at = [1, 15, 30, 60, 1440, 10080]).\n    label(like=\"{x:d}\")).\n  label(x = \"Time between posts (minutes)\", y = \"# Posts\")\n)\n## KeyError: 'diffmin'\np.show()\n## NameError: name 'p' is not defined\n```\n:::\n\n\n\n:::\n:::\n\n## References\n",
    "supporting": [
      "07-datetime_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}