# Dates and Times {#sec-datetime}

## Objectives {-}

-   Understand the complexities of working with datetime data
-   Create datetime formatted data from character and numeric encodings
-   Format/print datetime data in the desired format

## Why Dates and Times are hard

I'm going to let Tom Scott deliver this portion of the material for me, as his times and timezones video is excellent and entertaining.

::: youtube-video-container
<iframe src="https://www.youtube.com/embed/-5wpm-gesOY" title="The Problem with Time &amp; Timezones - Computerphile" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>

</iframe>
:::

There is also an excellent StackOverflow question @freewindWhySubtractingThese2021 and answers [@skeetAnswerWhySubtracting2011,@borgwardtAnswerWhySubtracting2011] demonstrating exactly how times and time zones can get very confusing even in relatively simple circumstances.

Long story short, we will be using libraries in R and python which handle some of these complexities for us, because dates, times, and timezones are **hard** and we *really* don't want to know exactly how hard they are.
The libraries I've chosen for this are `datetime` in Python (used by Pandas), and `lubridate` in R.

::: callout-tip
## Try It Out - Getting Set up

::: panel-tabset
### R

```{r}
#| eval: !expr '-1'
install.packages("lubridate")
library(lubridate)

# get current date/time
today()
now()
```

[Lubridate cheat sheet](https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf) [Lubridate documentation](https://lubridate.tidyverse.org/)

### Python

```{bash}
#| eval: !expr F
pip install datetime
```

```{python}
#| eval: !expr T
import datetime

today = datetime.date.today()
today
print(today)

now = datetime.datetime.now()
now
print(now)
```

[pandas datetime documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html)
:::
:::

## Getting Started

Let's differentiate between three types of data which refer to a point in time:

-   a **date**
-   a **time** within a day
-   a **date-time** - a specific time on a specific date

Now, let's think about all of the different ways we can specify dates.
The table below has examples along with `strptime` formats that are used in both `R` and `python` for telling the computer which date format is used.

+-----------+---------------------+-----------+---------------------------------------+-------------------+
|           | Example             | Type      | Notes                                 | `strptime` format |
+==========:+=====================+===========+=======================================+==================:+
| 1         | January 12, 2023    | date      | Common in US/N. America               | %B %d, %Y         |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 2         | 12 January 2023     | date      | Common in Europe                      | %d %B %Y          |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 3         | 01/12/2023          | date      | Common in US                          | %m/%d/%Y          |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 4         | 1/12/23             | date      | Common in US                          | %m/%d/%y          |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 5         | 12/01/2023          | date      | Common in Europe/Asia                 | %d/%m/%Y          |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 6         | 2023-01-12          | date      | ISO 8601 standard\                    | %Y-%m-%d\         |
|           |                     |           | (automatically sorts chronologically) | or %F             |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 7         | 12 2023             | date      | day of year + year                    | %j %Y             |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 8         | 9:23 PM             | time      | 12h time                              | %I:%M %p          |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 9         | 21:23               | time      | 24h time (military time)              | %H:%M\            |
|           |                     |           |                                       | or %R             |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 10        | 21:23:05            | time      | 24h time (with seconds)               | %H:%M:%S\         |
|           |                     |           |                                       | or %T             |
+-----------+---------------------+-----------+---------------------------------------+-------------------+
| 11        | 2023-01-12T21:23:05 | datetime  | ISO 8601 international standard       | %FT%T             |
+-----------+---------------------+-----------+---------------------------------------+-------------------+

: Different ways to specify dates and times. {#tbl-formats}

Note that rows 4 and 5 of @tbl-formats are ambiguous if you don't know what location your data comes from - the dates could refer to December 1, 2023 or January 12, 2023.
This only gets worse if you use 2-digit years.

There are three main ways that you might want to create a date/time @grolemundDatesTimes:

-   From a string
-   From individual date/time components
-   From an existing date/time object

## Creating Dates and Times

### Creation from Strings

Dates and times are often stored in tabular formats as strings.
In some cases, these are read in and automatically formatted as date-times, but in other situations, you have to specify the format yourself.

::: callout-demo
#### Demo: Datetimes from Strings

Let's use some data from the US Geological Service with records of earthquakes with magnitude greater than 6 on the Richter scale that occurred between January 1, 2000 and January 1, 2023.
You can pull this data yourself using https://earthquake.usgs.gov/earthquakes/map/, but you can also access a CSV of the data [here](https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv).

::: panel-tabset
##### R + lubridate

```{r}
library(lubridate)
quake <- read.csv("https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv")
str(quake)
```

By default, `read.csv` reads the time information in as a character variable.

```{r}
#| message: !expr F
#| warning: !expr F
library(readr)
quake2 <- read_csv("https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv")
str(quake2)
```

However, if we use `readr::read_csv`, the data is correctly read in as a `POSIXct` format, which is how R indicates that something is a datetime object.

If we want to directly convert the Time column in `quake` to a datetime, we can use the `lubridate` package, which has helper functions `ymd_hms`, `ymd`, and more.
Our data is formatted in ISO 8601 standard format, which means we can easily read it in with `ymd_hms()` .

```{r}
library(lubridate)
library(dplyr)
quake <- quake %>% 
  mutate(dateTime = ymd_hms(Time))
str(quake)
```

We can then test whether `quake$dateTime` is the same as `quake2$Time` :

```{r}
all.equal(quake2$Time, quake$dateTime)
```

So in the case that your data is not automatically read in as a date-time, you can use the helper functions from lubridate (`ymd_hms`, `ymd`, `mdy`, ...) to convert strings to date-time data.

##### Base R

As lovely as the lubridate package is, there are some situations where using the tidyverse may not be desirable or even allowed.
It is helpful to know how to solve this problem in base R, even if 99% of the time we can use the much easier-to-remember lubridate package.

In this case, we would use the `as.POSIXct` function, and we probably want to have the reference page up (run `?strptime` in the R console to pull up the help page).

We'll need to get the codes that tell R what format our datetimes use - you can use @tbl-formats, if you like, or read the `as.POSIXct` help page to see all possible format codes.

```{r}
quake <- read.csv("https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv")
str(quake)
quake$dateTime2 <- as.POSIXct(quake$Time, "%Y-%m-%dT%H:%M:%S")
all.equal(quake$dateTime, quake$dateTime2)
```

So using `as.POSIXct` we do not get the convenient handling of time zones that we got using `ymd_hms`, but we can set the time zone explicitly if we want to do so.

```{r}
quake$dateTime2 <- as.POSIXct(quake$Time, tz = "UTC", "%Y-%m-%dT%H:%M:%S")
all.equal(quake$dateTime, quake$dateTime2)
```

##### Pandas

In pandas, we can use the `to_datetime` method.
If the format is not specified, pandas will try to guess the date-time format; in this case, the guess works, but if not, you can provide a `format = â€¦` argument that works the same way as R.

```{python}
import pandas as pd
quake = pd.read_csv("https://github.com/srvanderplas/datasets/raw/main/raw/earthquakes2000.csv")
quake.dtypes

quake.Time[0:10]

# Convert to datetime
quake['dateTime'] = pd.to_datetime(quake.Time)
quake.dtypes
quake.dateTime[0:10]

# Convert to datetime
quake['dateTime2'] = pd.to_datetime(quake.Time, format = "%Y-%m-%dT%H:%M:%S")
quake.dtypes
quake.dateTime2[0:10]
```
:::
:::

::: callout-tip
#### Try it Out - Datetimes from Strings

It's usually important for new parents to keep a log of the new baby's feeds, to ensure that the baby is getting enough liquids and isn't getting dehydrated.
I used an app to keep track of my daughter's feeds from birth (though here, we'll only work with [the first 3 months of data](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv)), and it used a reasonable, if not standard way to store dates and times.

::: panel-tabset
##### Problem

Take a look at the [first month of feeds](https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv).
Note that these data are from August 7, 2021 to November 4, 2021 -- roughly baby's first 90 days.

1.  Convert Start and End to datetime variables
2.  Can you plot the feeds somehow?
3.  Can you do arithmetic with datetimes to see if there are any user entry errors?\
    This data was created by a *highly* unreliable and error prone couple of individuals -- specifically, sleep-deprived new parents.

To do this, you may need to figure out how to specify a non-standard date format in R and/or python.
The `parse_date_time` function is useful in R, and `pd.to_datetime()` takes a format argument in python.

##### R solution

First, let's read the data in and explore a bit.

```{r}
library(lubridate)
library(readr)
feeds <- read_csv("https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv")
head(feeds)

# Looks like %H:%M:%S %m-%d-%Y format.
```

It looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second.
We can use the `parse_date_time` function in lubridate

```{r}
feeds <- feeds %>%
  mutate(Start = parse_date_time(Start, orders = c("%H:%M:%S %m-%d-%Y")),
         End = parse_date_time(End, orders = c("%H:%M:%S %m-%d-%Y")))
```

Let's then explore how we might plot this data:

```{r}
#| fig-width: 6
#| fig-height: 1.5
#| fig-caption: "Feeds in the first 90 days of an infant's life."
library(ggplot2)
ggplot(feeds, aes(xmin = Start, xmax = End, fill = Type)) + 
  geom_rect(aes(ymin = 1, ymax = 2)) + # Specify default aes
  scale_fill_manual(values = c("Bottle" = "cornflowerblue", "Breast" = "pink")) + 
  theme_bw() + theme(legend.position = "bottom") + 
  scale_y_continuous(breaks = NULL)
```

```{r}
#| fig-width: 6
#| fig-height: 4
#| fig-caption: "Feeds in the first 90 days of an infant's life, by hour of the day."
library(ggplot2)
feeds %>%
  mutate(day = floor_date(Start, "day"),
         hour_start = Start - day,
         hour_end = End - day) %>%
  mutate(across(starts_with("hour"), ~as.numeric(., units = "hours"))) %>%
  mutate(doy = yday(day)) %>%
ggplot(aes(ymin = day, ymax = day+days(1), xmin = hour_start, xmax = hour_end, fill = Type)) + 
  geom_rect() + # Specify default aes
  scale_fill_manual(values = c("Bottle" = "cornflowerblue", "Breast" = "pink")) + 
  scale_x_continuous("Hour of the day") + 
  theme_bw() + theme(legend.position = "bottom")
```

We can also calculate the duration of each feed and look at the distributions for each type of feed.

```{r}
feeds <- feeds %>%
  mutate(duration = End - Start)

ggplot(feeds, aes(x = duration, fill = Type)) + geom_histogram(color = "black") + 
  scale_fill_manual(values = c("Bottle" = "cornflowerblue", "Breast" = "pink")) + 
  theme_bw() + theme(legend.position = "none") + 
  xlab("Feed duration, in seconds") + facet_wrap(~Type)
```

We can see a few suspiciously long feeds - 9000 seconds is 2.5 hours, which is not unheard of for a baby to breastfeed, but would be an exceptionally long bottle feed (unless a parent fell asleep before hitting "stop" on the feed, which is much more likely).

##### Python solution

First, let's read the data in and explore a bit.

```{python}
import pandas as pd

feeds = pd.read_csv("https://raw.githubusercontent.com/srvanderplas/datasets/main/raw/feeds_initial.csv")
feeds.head()

# Looks like %H:%M:%S %m-%d-%Y format.
```

It looks like the data is stored in a format where the time (`%H:%M:%S`) is first and the date (`%m-%d-%Y`) is second.
We can use the format argument to `pd.to_datetime` to specify this:

```{python}
feeds["Start"] = pd.to_datetime(feeds.Start, format = "%H:%M:%S %m-%d-%Y")
feeds["End"] = pd.to_datetime(feeds.End, format = "%H:%M:%S %m-%d-%Y")
feeds.head()
```

In Python, it is helpful to do a bit of transformation first - this is partly because I'm not as good with Python plotting systems.

```{python}
import datetime as dt
feeds["day"] = feeds.Start.dt.strftime("%Y-%m-%d")
feeds["day"] = pd.to_datetime(feeds.day, format = "%Y-%m-%d")
feeds["day_end"] = feeds.day + dt.timedelta(days = 1)

feeds["time_start"] = feeds.Start - feeds.day
feeds["time_end"] = feeds.End - feeds.day
feeds["duration"] = feeds.time_end - feeds.time_start
```

Note that as of January 2023, RStudio does not correctly display timedelta data types in python.
They show up as NAs in the table, but are printed fine in the console.
Don't spend hours trying to figure out why it isn't working -- it's bad enough that I did.

```{python}
from plotnine import *

(
  ggplot(feeds, aes(xmin = "Start", xmax = "End", fill = "Type")) + 
  geom_rect(aes(ymin = 1, ymax = 2)) + 
  scale_fill_manual(values = ["cornflowerblue", "pink"]) + 
  theme_bw() + scale_y_continuous(breaks = [])
)

```

```{python}
from plotnine import *

(
  ggplot(feeds, aes(xmin = "time_start", xmax = "time_end", ymin = "day", ymax = "day_end", fill = "Type")) + 
  geom_rect() + 
  scale_fill_manual(values = ["cornflowerblue", "pink"]) + 
  theme_bw()
)

```
:::
:::

### Creation from Components

Sometimes, instead of a single string, you'll have the individual components of the date-time spread across columns.
The `nycflights13` data is a good example of this.

::: callout-demo
#### Demo: Datetimes from Components

::: panel-tabset
##### R + lubridate

In `lubridate`, the `make_date()` and `make_datetime()` functions can be used to create date-times from component pieces.

```{r}
library(nycflights13)

flights %>%
  select(year, month, day, hour, minute) %>% 
  head()

flights <- flights %>%
  mutate(date = make_date(year, month, day),
         datetime = make_datetime(year, month, day, hour, minute))

flights %>% select(date, datetime, year, month, day, hour, minute)
```

##### Base R

In base R, we can use the `ISOdate` function to create date times.

```{r}
flights$datetime_base = with(flights, ISOdatetime(year, month, day, hour, minute, sec= 0, tz="UTC"))
all.equal(flights$datetime, flights$datetime_base)
```

##### Python

In pandas, we can pass multiple columns to `pd.to_datetime()` and as long as they are named reasonably, pandas will handle the conversion.
If we want to have the date but not the time for some reason, we just pass fewer columns to pandas.

```{python}
from nycflights13 import flights

flights[["year", "month", "day", "hour", "minute"]]

flights["date"] = pd.to_datetime(flights[["year", "month", "day"]])
flights["datetime"] = pd.to_datetime(flights[["year", "month", "day", "hour", "minute"]])


flights[["date", "datetime", "year", "month", "day", "hour", "minute"]]
```
:::
:::

<!-- ## Creation from other objects -->

### Creation from Other Objects

Sometimes, you may have information in one type of variable (e.g. a datetime) and want to split it into a date and a time, separately.

Some systems store datetimes as the number of seconds from a specific point (commonly, the **Unix Epoch**, midnight on 1970-01-01).
You may have to convert from seconds since this epoch (or some other epoch [@wikipediacontributorsEpochComputing2023]) to an actual date-time that is human readable.

If you ever have to convert dates and times that were stored in Microsoft Excel, it can be helpful to know that Microsoft stores dates as the number of days since January 1, 1900 [@microsoftsupportDATEVALUEFunctionMicrosoft2023] (or if the spreadsheet was created on a Mac, January 1, 1904) [@elizabethmottWhyDatesCome2013].
Yes, this is as confusing as it sounds.
Don't use MS Excel for handling dates [@caudillExcelHellCautionary2018; @chris88888888ExcelStillSucks2020] (or really, at all, now that you know better tools).
Geneticists have actually renamed genes because Microsoft won't fix Excel to handle dates properly [@vincentScientistsRenameHuman2020].

::: callout-demo
#### Demo: Creation from Other Objects

::: panel-tabset
##### R + lubridate

In `lubridate`, the `as_date()` and `as_datetime()` functions can be used to create date-times from other objects.

```{r}
tmp <- flights %>%
  mutate(date2 = as_date(datetime))

# Check that date and date2 are the same
all.equal(flights$date, flights$date2)
```

Here's a demonstration of epoch timekeeping.

```{r}
current_time <- now(tzone = "UTC")
# This converts to the number of seconds since the Unix epoch
seconds_since_epoch <- current_time %>% seconds()
# Now let's convert back to a datetime
(current_time2 <- as_datetime(seconds_since_epoch))
# Check to see that they're equal
all.equal(current_time, current_time2)
```

##### Base R

In base R, we can use the `as.Date` function to create dates from datetimes.

```{r}
flights$date2 = as.Date(flights$date)
all.equal(flights$date, flights$date2)
```

We can handle epochs as well:

```{r}
# Let's see what was 10000 days after the UNIX epoch
as.Date(1e4, origin = "1970-01-01")

# If we use as.POSIXct, we are counting in seconds from midnight
as.POSIXct(1e4, origin = as.POSIXct("1970-01-01 00:00:00"))
```

By default, `as.POSIXct` will use the system's time zone, which may not be desirable; you can always set the time zone yourself if you would like to do so.

##### Python

In pandas, we can pass multiple columns to `pd.to_datetime()` and as long as they are named reasonably, pandas will handle the conversion.
If we want to have the date but not the time for some reason, we just pass fewer columns to pandas.

```{python}
from nycflights13 import flights

flights["date2"] = flights.date.dt.date # Convert datetime to date

# They look the same
flights[["date", "date2"]]

flights.dtypes
# date2 is an object, date is a datetime64.
```

We created `flights.date` using `pd.to_datetime()`.
Given this comparison, it may be better to use to.datetime() and append `.dt.date` on the end if you do not want to keep the time information that is provided by default.
:::
:::

## Working with Dates and Times

In this section, we'll work with comments by famous Reddit artist `Shitty_Watercolour`, who responds to people's comments with a quickly created watercolor-style painting.

::: aside
Here's one of Shitty Watercolour's works: ![[Reddit context.](https://www.reddit.com/r/AnimalsBeingDerps/comments/12bah0e/when_you_really_miss_your_bff/) [Image source](https://imgur.com/tpDBs4j)](../images/wrangling/watercolor_example.jpeg){fig-alt="A watercolor painting of a dog imagining touching a different dog through a laptop screen. The dogs apparently see each other once a month and facetime once a week."}
:::

::: callout-demo
### Getting the Data

::: panel-tabset
#### R

Note: The textbook caches data, so your results may differ from those shown here because `RedditExtractoR` only acquires the last \~1000 comments from a user. In addition, in July 2003, reddit removed their API that allowed `RedditExtractoR` to function, so any future updates are sadly unlikely. 

```{r}
#| label: reddit-poems-dl
#| eval: !expr F
# remotes::install_github("ivan-rivera/RedditExtractor")
library(RedditExtractoR)

comment_list <- get_user_content("Shitty_Watercolour")
watercolour <- comment_list$Shitty_Watercolour$comments
```

```{r}
#| label: reddit-poems
#| include: !expr F
# remotes::install_github("ivan-rivera/RedditExtractor")
library(RedditExtractoR)

if (!file.exists("../data/watercolour.csv")) {
  comment_list <- get_user_content("Shitty_Watercolour")
  watercolour <- comment_list$Shitty_Watercolour$comments
  readr::write_csv(watercolour, "../data/watercolour.csv")
} else {
  watercolour <- readr::read_csv("../data/watercolour.csv")
}
```

#### Python

```{python}
# Get data from R directly, since redditExtractor package is in R
watercolour = r.watercolour
```
:::
:::

### Time Zones

We often store data in UTC[^07-datetime-1], but we may want to represent the data in a more familiar time zone for interpretation's purposes.

[^07-datetime-1]: Coordinated Universal Time, but the acronym is in a different language and the words are thus in a different order.

| Task | Language | Function | 
| ---- | ---- | -------------------------------------------------------------| 
| Set the time zone | R | `as_datetime(time, tz = "GMT")` |
| | Python | `time.apply(lambda x: pd.Timestamp(x).tz_localize("GMT"))` |
| Display the time in a diff TZ | R | `with_tz(time, tz = "America/Chicago")` | 
| | Python | `time.apply(lambda x: pd.Timestamp(x).tz_convert("America/Chicago"))` |

: Working with Time Zones. Here, `time` is a placeholder for whatever variable is being converted.

::: callout-tip
#### Try it Out - Formatting Dates

::: panel-tabset
##### Problem

The `watercolour` dataset above contains 959 comments from `Shitty_Watercolour`, with the UTC date and timestamp of the comment.

Figure out how to format these data into a proper date type and timestamp that is user-readable.
Make sure you inform R or python that the timestamp is provided in UTC.

![Hovering over the time on a reddit comment will produce a popup showing the full time that the comment was posted.](../images/wrangling/reddit-timestamp-mouseover.png) Compare a couple of your timestamps to the timestamps provided by Reddit when you mouse over a comment.

Can you get R or Python to output the date in your timezone?

##### R Solution

```{r}
watercolour <- watercolour %>%
  mutate(date = ymd(date_utc, tz = "UTC"),
         time = as_datetime(timestamp),
         time_cst = with_tz(time, tzone_out = "CST"))

watercolour[,c("date", "time", "time_cst")]
```

##### Python Solution

```{python}
from datetime import datetime

watercolour["date"] = pd.to_datetime(watercolour.date_utc).dt.date
watercolour["time"] = pd.to_datetime(watercolour.timestamp, unit = 's')

# Tell Python the time is in UTC 
watercolour["time"] = watercolour.time.apply(lambda x: pd.Timestamp(x).tz_localize("UTC"))

watercolour["time_cst"] = watercolour.time.apply(lambda x: pd.Timestamp(x).tz_convert("US/Central"))

watercolour[["date", "time", "time_cst"]]
```
:::
:::

### Time Spans

Dates and times can be added and subtracted - after all, underneath, they're usually implemented as a number of XXX from the reference time point, where XXX is usually seconds for datetimes and days for dates.

In R, the difference between two timestamps is called a **duration** and is implemented in the **duration** class [See @r4ds Chapter 16.4.1 for more info]. In Python, a similar class exists and is called a **timedelta** [@pythonfoundationDatetimeBasicDate2023].

::: callout-tip
#### Try it Out - Datetime Math

::: panel-tabset
##### Problem

Use the `watercolour` data and plot the interval between successive `Shitty_Watercolour` posts in minutes. What can you conclude?


##### R Solution

```{r}
watercolour <- watercolour %>%
  arrange(time) %>%
  mutate(diff = as.duration(time - lag(time, 1)),
         diffmin = as.numeric(diff, "minutes"))

library(ggplot2)
ggplot(watercolour, aes(x = diffmin)) + 
  geom_histogram() + 
  xlab("Time between posts (minutes)") + 
  ylab("# Posts") + 
  scale_x_log10(breaks = c(1, 15, 30, 60, 1440, 10080))
```

Most of the time, `Shitty_Watercolour` takes at least 15 minutes to generate a new comment. There is also a noticable peak just before 1440 minutes, indicating that as with most users, `Shitty_Watercolour` is active at approximately the same time each day for a few hours. The final break shown, 10080, is the number of minutes in a week, indicating that occasionally, `Shitty_Watercolour` goes more than a week between posts.

##### Python Solution

```{python}
from datetime import datetime

watercolour = watercolour.sort_values(by = 'time')
watercolour["diff"] = watercolour.time.diff().astype('timedelta64')
# This formats in minutes
watercolour["diffmin"] = watercolour.time.diff().astype('timedelta64[m]')
# Remove negative minutes - something funky there?
watercolour = watercolour.query("diffmin > 0")

import seaborn.objects as so
p = (
  so.
  Plot(watercolour, watercolour["diffmin"]).
  add(so.Bars(width=.95), so.Hist(bins = 30)).
  scale(x = so.Continuous(trans = "log").
    tick(at = [1, 15, 30, 60, 1440, 10080]).
    label(like="{x:d}")).
  label(x = "Time between posts (minutes)", y = "# Posts")
)
p.show()
```
:::
:::

## References
